{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedGroupKFold"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "sgkfold = StratifiedKFold(n_splits=4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for trn_idx , val_idx in sgkfold.split(X=train_df['overview'].values,y=train_df['cat3'].values):\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 1512,  1552,  1705, ..., 16983, 16984, 16985])"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "splitter = StratifiedKFold(n_splits=4, shuffle=True, random_state=0)\n",
    "\n",
    "splits = []\n",
    "for train_idx, test_idx in splitter.split(train_df['overview'], train_df['cat3']):\n",
    "    splits.append((train_idx, test_idx))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "[(array([    0,     1,     2, ..., 16982, 16984, 16985]),\n  array([    4,     5,    12, ..., 16978, 16980, 16983])),\n (array([    0,     3,     4, ..., 16982, 16983, 16984]),\n  array([    1,     2,     6, ..., 16963, 16972, 16985])),\n (array([    1,     2,     3, ..., 16980, 16983, 16985]),\n  array([    0,    10,    11, ..., 16981, 16982, 16984])),\n (array([    0,     1,     2, ..., 16983, 16984, 16985]),\n  array([    3,     7,     8, ..., 16973, 16975, 16979]))]"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "from torch.utils.data import Sampler\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import BatchSampler"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "                id                       img_path  \\\n0      TRAIN_00000  ./image/train/TRAIN_00000.jpg   \n1      TRAIN_00001  ./image/train/TRAIN_00001.jpg   \n2      TRAIN_00002  ./image/train/TRAIN_00002.jpg   \n3      TRAIN_00003  ./image/train/TRAIN_00003.jpg   \n4      TRAIN_00004  ./image/train/TRAIN_00004.jpg   \n...            ...                            ...   \n16981  TRAIN_16981  ./image/train/TRAIN_16981.jpg   \n16982  TRAIN_16982  ./image/train/TRAIN_16982.jpg   \n16983  TRAIN_16983  ./image/train/TRAIN_16983.jpg   \n16984  TRAIN_16984  ./image/train/TRAIN_16984.jpg   \n16985  TRAIN_16985  ./image/train/TRAIN_16985.jpg   \n\n                                                overview          cat1  \\\n0      소안항은 조용한 섬으로 인근해안이 청정해역으로 일찍이 김 양식을 해서 높은 소득을 ...            자연   \n1      경기도 이천시 모가면에 있는 골프장으로 대중제 18홀이다. 회원제로 개장을 했다가 ...           레포츠   \n2      금오산성숯불갈비는 한우고기만을 전문적으로 취급하고 사용하는 부식 자재 또한 유기농법...            음식   \n3      철판 위에서 요리하는 안동찜닭을 맛볼 수 있는 곳이다. 경상북도 안동시에 있는 한식...            음식   \n4      ※ 영업시간 10:30 ~ 20:30\\n\\n3대에 걸쳐 아귀만을 전문으로 취급하는 ...            음식   \n...                                                  ...           ...   \n16981  해발 12000m에 자리한 식담겸 카페점문점이다.<br>곤드레밥과 감자전을 판매하고...            음식   \n16982  설악힐호텔은 동해고속도로 속초톨게이트에서 멀지 않은 관광로 변에 있다. 속초의 대표...            숙박   \n16983  충남 서산시 중심가에 위치한 줌모텔은 프라이버스가 보장되는 조용한 공간으로 가치가 ...            숙박   \n16984  토토큰바위캠핑장은 경기도 가평지역 내에서도 청정지역으로 손꼽히는 지역으로 주변에 화...           레포츠   \n16985  포천의 진산으로 불리우는 왕방산(王訪山)에는 천년의 역사를 간직하고 있는 왕산사(王...  인문(문화/예술/역사)   \n\n         cat2       cat3  cat3_enc  \n0       자연관광지      항구/포구       120  \n1      육상 레포츠         골프         8  \n2         음식점         한식       118  \n3         음식점         한식       118  \n4         음식점         한식       118  \n...       ...        ...       ...  \n16981     음식점         한식       118  \n16982    숙박시설         모텔        31  \n16983    숙박시설         모텔        31  \n16984  육상 레포츠  야영장,오토캠핑장        73  \n16985   역사관광지         사찰        52  \n\n[16986 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>img_path</th>\n      <th>overview</th>\n      <th>cat1</th>\n      <th>cat2</th>\n      <th>cat3</th>\n      <th>cat3_enc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>TRAIN_00000</td>\n      <td>./image/train/TRAIN_00000.jpg</td>\n      <td>소안항은 조용한 섬으로 인근해안이 청정해역으로 일찍이 김 양식을 해서 높은 소득을 ...</td>\n      <td>자연</td>\n      <td>자연관광지</td>\n      <td>항구/포구</td>\n      <td>120</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>TRAIN_00001</td>\n      <td>./image/train/TRAIN_00001.jpg</td>\n      <td>경기도 이천시 모가면에 있는 골프장으로 대중제 18홀이다. 회원제로 개장을 했다가 ...</td>\n      <td>레포츠</td>\n      <td>육상 레포츠</td>\n      <td>골프</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>TRAIN_00002</td>\n      <td>./image/train/TRAIN_00002.jpg</td>\n      <td>금오산성숯불갈비는 한우고기만을 전문적으로 취급하고 사용하는 부식 자재 또한 유기농법...</td>\n      <td>음식</td>\n      <td>음식점</td>\n      <td>한식</td>\n      <td>118</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>TRAIN_00003</td>\n      <td>./image/train/TRAIN_00003.jpg</td>\n      <td>철판 위에서 요리하는 안동찜닭을 맛볼 수 있는 곳이다. 경상북도 안동시에 있는 한식...</td>\n      <td>음식</td>\n      <td>음식점</td>\n      <td>한식</td>\n      <td>118</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>TRAIN_00004</td>\n      <td>./image/train/TRAIN_00004.jpg</td>\n      <td>※ 영업시간 10:30 ~ 20:30\\n\\n3대에 걸쳐 아귀만을 전문으로 취급하는 ...</td>\n      <td>음식</td>\n      <td>음식점</td>\n      <td>한식</td>\n      <td>118</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>16981</th>\n      <td>TRAIN_16981</td>\n      <td>./image/train/TRAIN_16981.jpg</td>\n      <td>해발 12000m에 자리한 식담겸 카페점문점이다.&lt;br&gt;곤드레밥과 감자전을 판매하고...</td>\n      <td>음식</td>\n      <td>음식점</td>\n      <td>한식</td>\n      <td>118</td>\n    </tr>\n    <tr>\n      <th>16982</th>\n      <td>TRAIN_16982</td>\n      <td>./image/train/TRAIN_16982.jpg</td>\n      <td>설악힐호텔은 동해고속도로 속초톨게이트에서 멀지 않은 관광로 변에 있다. 속초의 대표...</td>\n      <td>숙박</td>\n      <td>숙박시설</td>\n      <td>모텔</td>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>16983</th>\n      <td>TRAIN_16983</td>\n      <td>./image/train/TRAIN_16983.jpg</td>\n      <td>충남 서산시 중심가에 위치한 줌모텔은 프라이버스가 보장되는 조용한 공간으로 가치가 ...</td>\n      <td>숙박</td>\n      <td>숙박시설</td>\n      <td>모텔</td>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>16984</th>\n      <td>TRAIN_16984</td>\n      <td>./image/train/TRAIN_16984.jpg</td>\n      <td>토토큰바위캠핑장은 경기도 가평지역 내에서도 청정지역으로 손꼽히는 지역으로 주변에 화...</td>\n      <td>레포츠</td>\n      <td>육상 레포츠</td>\n      <td>야영장,오토캠핑장</td>\n      <td>73</td>\n    </tr>\n    <tr>\n      <th>16985</th>\n      <td>TRAIN_16985</td>\n      <td>./image/train/TRAIN_16985.jpg</td>\n      <td>포천의 진산으로 불리우는 왕방산(王訪山)에는 천년의 역사를 간직하고 있는 왕산사(王...</td>\n      <td>인문(문화/예술/역사)</td>\n      <td>역사관광지</td>\n      <td>사찰</td>\n      <td>52</td>\n    </tr>\n  </tbody>\n</table>\n<p>16986 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "outputs": [],
   "source": [
    "# sampler image id를 가지고 가져온다 dataloader 에 넣으면\n",
    "class TextSampler(Sampler):\n",
    "    def __init__(self,\n",
    "                 # sample_idx,\n",
    "                 data_source='./input/train.csv'):\n",
    "        super().__init__(data_source)\n",
    "        # self.sample_idx = sample_idx\n",
    "        self.df = pd.read_csv(data_source)\n",
    "        self.skf = StratifiedKFold(n_splits=4, shuffle=False)\n",
    "    def __iter__(self):\n",
    "         # overviews = self.df_images['id'].loc[self.sample_idx]\n",
    "         for train_idx, test_idx in self.skf.split(self.df['overview'], self.df['cat3']):\n",
    "            yield test_idx\n",
    "        # return self.sample_idx\n",
    "        # for idx in self.sample_idx:\n",
    "            # yield idx\n",
    "        # return iter(overviews)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "class StratifiedBatchSampler:\n",
    "    \"\"\"Stratified batch sampling\n",
    "    Provides equal representation of target classes in each batch\n",
    "    \"\"\"\n",
    "    def __init__(self, y, batch_size, shuffle=True):\n",
    "        if torch.is_tensor(y):\n",
    "            y = y.numpy()\n",
    "        assert len(y.shape) == 1, 'label array must be 1D'\n",
    "        n_batches = int(len(y) / batch_size)\n",
    "        self.X = torch.randn(len(y),1).numpy()\n",
    "        self.y = y\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    def __iter__(self):\n",
    "        if self.shuffle:\n",
    "            self.skf.random_state = torch.randint(0,int(1e8),size=()).item()\n",
    "        for train_idx, test_idx in self.skf.split(self.X, self.y):\n",
    "            yield test_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "outputs": [],
   "source": [
    "class CateDataset(Dataset):\n",
    "    \"\"\"\n",
    "    데이터셋에서 학습에 필요한 형태로 변환된 샘플 하나를 반환\n",
    "    \"\"\"\n",
    "    def __init__(self, df_data,   tokens_max_len=64, type_vocab_size=30):\n",
    "        \"\"\"\n",
    "        :param df_data: 상품 타이틀 , 카테고리 등의 정보를 가지는 데이터프레임\n",
    "        :param img_h5_path:  img_feat가 저장돼 있는 h5파일의 경로\n",
    "        :param tokens_max_len: tokens 의 최대 길이 , 상품명의 tokens 가 이 이상이면 잘라서 버림\n",
    "        :param type_vocab_size: 타입 사전의 크기\n",
    "        \"\"\"\n",
    "        # 작문 평가방법처럼 해보기 , 카카오 개선사항과 작문평가 kaggle 참조\n",
    "        self.tokens = df_data['overview'].values # 전처리된 상품명\n",
    "        self.tokens_max_len = tokens_max_len\n",
    "        self.df_data = df_data\n",
    "        self.labels = df_data[['cat3']].values\n",
    "        self.p = re.compile('▁[^▁]+') #  기호를 기준으로 나누기 위한 컴파일 정규식 _ 기호와 다름 ▁ 이것으로 사용\n",
    "        self.type_vocab_size = type_vocab_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        데이터셋에서 idx에 대응되는 샘플을 변환하여 반환\n",
    "\n",
    "        :param item:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # if idx >= len(self.tokens):\n",
    "        #     raise StopIteration\n",
    "\n",
    "        # idx 에 해당하는 상품명 가져오기 , 상품명은 문자열로 저장돼 있음\n",
    "\n",
    "\n",
    "        tokens = self.tokens[idx]\n",
    "        return tokens\n",
    "        # if not isinstance(tokens, str):\n",
    "        #     tokens = ''\n",
    "        # # 상품명을 _기호를 기준으로 분리하여 파이썬 리스트로 저장\n",
    "        # # \"_직소퍼즐 _1000 조각 _바다 거북 의 _여행 _pl 12 75\" =>\n",
    "        # # [\"_직소퍼즐\" , \"_1000조각\", \"_바다 거북 의\", \"_여행\",\"_pl 12 75\"]\n",
    "        # tokens = self.p.findall(tokens)\n",
    "        #\n",
    "        # token_types = [type_id for type_id , word in enumerate(tokens) for _ in word.split()]\n",
    "        # tokens=  \" \".join(tokens) # _기호로 분리되기 전의 원래의 tokens로 되돌림\n",
    "        #\n",
    "        # token_ids = [self.token2id[tok] if tok in self.token2id else 0 for tok in tokens.split()]\n",
    "        #\n",
    "        # # token_ids 의 길이가 max_len보다 길다면 잘라서 버린다\n",
    "        # if len(token_ids) > self.tokens_max_len:\n",
    "        #     token_ids = token_ids[:self.tokens_max_len]\n",
    "        #     token_types = token_types[:self.tokens_max_len]\n",
    "        #\n",
    "        # # token_ids의 길이가 max_len보다 짧으면 짧은 만큼 PAD 값을 0으로 채워 넣음\n",
    "        # # token_ids 중 값이 있는 곳은 1, 그 외는 0으로 채운 token_mask 생성\n",
    "        # token_mask = [1] * len(token_ids)\n",
    "        # token_pad = [0] * (self.tokens_max_len - len(token_ids))\n",
    "        # token_ids += token_pad\n",
    "        # token_mask += token_pad\n",
    "        # token_types += token_pad # max_len 보다 짧은 만큼 PAD 추가\n",
    "        #\n",
    "        #\n",
    "        # token_ids = torch.LongTensor(token_ids)\n",
    "        # token_mask = torch.LongTensor(token_mask)\n",
    "        # token_types = torch.LongTensor(token_types)\n",
    "        #\n",
    "        # # 카카오에서 진행한 개선 과정도 포함시키기\n",
    "        # # token_type의 타입 인덱스의 숫자 크기가 type_vocab_size보다 작도록 바꿈\n",
    "        # token_types[token_types >= self.type_vocab_size] = self.type_vocab_size-1\n",
    "        #\n",
    "        # # 안정적으로 img_feat를 가져오려면 아래처럼 매번 h5py.File 호출필요\n",
    "        # with h5py.File(self.img_h5_path, 'r') as img_feats:\n",
    "        #     img_feat = img_feats['img_feat'][self.img_indices[idx]]\n",
    "        # #print(self.df_data.iloc[idx])\n",
    "        # #print(self.df_data.iloc[0])\n",
    "        # #print(self.img_indices[0])\n",
    "        #\n",
    "        # #img_feat = img_feat.view(1,-1)\n",
    "        # # 대/중/소/세 레이블 준비\n",
    "        # label = self.labels[idx]\n",
    "        # label = torch.LongTensor(label )\n",
    "        # #\n",
    "        #\n",
    "        # # 갑자기 batched index가 들어오는 경우가 있다 그건 문제안됨\n",
    "        # # 크게 3가지 텍스트 입력, 이미지 입력 , 레이블을 반환\n",
    "        # return token_ids , token_mask , token_types, img_feat, label\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "          tokens의 개수를 반환한다. 즉, 상품명 문장의 개수를 반환한다.\n",
    "        \"\"\"\n",
    "        return len(self.tokens)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#bertmodel, vocab = get_pytorch_kobert_model()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer()\n",
    "tok = nlp.data.BERTSPTokenizer(tokenizer,vocab,lower=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/375 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d46ec32b53894853a75b49ee4ddce373"
      },
      "application/json": {
       "n": 0,
       "total": 375,
       "elapsed": 0.01795029640197754,
       "ncols": null,
       "nrows": null,
       "prefix": "Downloading",
       "ascii": false,
       "unit": "B",
       "unit_scale": true,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/248k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a0ce9f7627d04a2790e526889073c682"
      },
      "application/json": {
       "n": 0,
       "total": 248477,
       "elapsed": 0.00997304916381836,
       "ncols": null,
       "nrows": null,
       "prefix": "Downloading",
       "ascii": false,
       "unit": "B",
       "unit_scale": true,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/752k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "47e1ac764050426a880f44e56b583b68"
      },
      "application/json": {
       "n": 0,
       "total": 751504,
       "elapsed": 0.014961957931518555,
       "ncols": null,
       "nrows": null,
       "prefix": "Downloading",
       "ascii": false,
       "unit": "B",
       "unit_scale": true,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/173 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b16761ea94ee4ea696affe184da0794b"
      },
      "application/json": {
       "n": 0,
       "total": 173,
       "elapsed": 0.01296544075012207,
       "ncols": null,
       "nrows": null,
       "prefix": "Downloading",
       "ascii": false,
       "unit": "B",
       "unit_scale": true,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tok = AutoTokenizer.from_pretrained('klue/roberta-large')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "outputs": [],
   "source": [
    "class BERTDataset(Dataset):\n",
    "  def __init__(self, dataset, sent_idx , label_idx, bert_tokenizer, max_len):\n",
    "    # transform = nlp.data.BERTSentenceTransform(\n",
    "    #     bert_tokenizer, max_seq_length=max_len, pad=pad,pair=pair\n",
    "  # bert_tokenizer 로 transform\n",
    "    self.sentences = [bert_tokenizer.encode_plus(i[sent_idx],max_length=max_len,padding='max_length',truncation=True) for i in dataset.values]\n",
    "    self.labels = [np.int32(i[label_idx]) for i in dataset.values]\n",
    "  def __getitem__(self, i):\n",
    "    # output,output2,output3 = self.sentences[0]['input_ids'],self.sentences[0]['token_type_ids'],self.sentences[0]['attention_mask']\n",
    "\n",
    "    return self.sentences[i]['input_ids']\n",
    "    # print(self.sentences[i] + (self.labels[i]))\n",
    "    # return (self.sentences[i] + (self.labels[i],))\n",
    "  def __len__(self):\n",
    "    return (len(self.labels))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "outputs": [],
   "source": [
    "def create_split_loaders(dataset, split,   batch_size):\n",
    "    train_folds_idx = split[0]\n",
    "    valid_folds_idx = split[1]\n",
    "    train_sampler = ImageSampler(train_folds_idx)\n",
    "    valid_sampler = ImageSampler(valid_folds_idx)\n",
    "    train_loader = DataLoader(dataset, batch_sampler=train_sampler)\n",
    "    valid_loader = DataLoader(dataset, batch_sampler=valid_sampler)\n",
    "    return (train_loader, valid_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "outputs": [],
   "source": [
    "train_folds_idx = trn_idx\n",
    "valid_folds_idx = val_idx"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 1512,  1552,  1705, ..., 16983, 16984, 16985])"
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_folds_idx"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "outputs": [],
   "source": [
    "train_sampler = TextSampler()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "outputs": [
    {
     "data": {
      "text/plain": "<__main__.TextSampler at 0x1a621ec7160>"
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for tr_idx ,va_idx in train_sampler.skf.split(train_df['overview'], train_df['cat3']):\n",
    "    train_df.iloc[tr_idx]\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "outputs": [],
   "source": [
    "bert_df = BERTDataset(input_df, 0,1 , tok ,64)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "outputs": [],
   "source": [
    "train_loader = DataLoader(bert_df, batch_sampler=train_sampler,batch_size=1,shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for data in train_loader:\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "outputs": [
    {
     "data": {
      "text/plain": "[tensor([0, 0, 0,  ..., 0, 0, 0]),\n tensor([ 1282,  4619, 23236,  ...,  4041, 14900, 10427]),\n tensor([ 2283, 16781, 14908,  ..., 14223,   879, 29047]),\n tensor([2421, 2067, 3271,  ..., 2079, 2199, 2053]),\n tensor([2073, 1078, 2588,  ..., 3824, 2154, 2376]),\n tensor([ 5574,  2116, 12799,  ...,  3877,  2073,  2021]),\n tensor([ 2470,  2460,  2259,  ..., 10697,  6273,  2259]),\n tensor([1264, 2170, 8680,  ..., 3751, 2470, 4407]),\n tensor([ 6233,  1513,  5129,  ...,  6233, 16842,  7271]),\n tensor([ 4973,  2259,  2154,  ..., 12325,  2145, 14659]),\n tensor([ 2097,  7802,  2069,  ..., 11830,  6701,    11]),\n tensor([ 2283,  6233,  3752,  ...,  7138,  2470, 21512]),\n tensor([ 2052,  4672, 11187,  ...,  2069,  5008,  1381]),\n tensor([8808, 2021, 7045,  ..., 3691, 8185, 2318]),\n tensor([ 2097,  3801, 19521,  ..., 31302,  2069,  2057]),\n tensor([2331, 2827, 3704,  ..., 5418, 7492, 2052]),\n tensor([ 6233, 28674,  2205,  ...,  2173,  5008,  2203]),\n tensor([12168,    18,  2259,  ...,  4584,  2189,  4193]),\n tensor([  648,  4789, 20401,  ...,  2496,  9595,  2725]),\n tensor([ 6277,  2021, 11075,  ...,  2359,  4474,    11]),\n tensor([2069, 2200, 3819,  ..., 2062, 2138, 3604]),\n tensor([ 3689,  8886, 11835,  ...,    18,  5916,   114]),\n tensor([ 772, 2069, 2520,  ..., 5764, 1295, 4501]),\n tensor([2073, 1902, 6233,  ..., 2440, 1513, 2079]),\n tensor([4429, 4795, 7362,  ..., 1041, 2259, 1521]),\n tensor([2069, 5217, 2470,  ..., 2170, 3841, 2128]),\n tensor([ 4705,  2440,  8808,  ...,  8484,  2079, 12121]),\n tensor([2088, 4672, 2275,  ..., 7488, 4318, 7805]),\n tensor([1513, 2021, 2327,  ..., 5125, 2200,  115]),\n tensor([4007, 2200, 2154,  ..., 2440, 3777, 5763]),\n tensor([4822, 4561, 2069,  ..., 3710, 2757, 2088]),\n tensor([3080, 7488, 7045,  ..., 2429, 2088, 4348]),\n tensor([ 2067,  7355, 19521,  ...,  2170,  1513,  2470]),\n tensor([2115, 2121, 1513,  ..., 7744, 2062, 4501]),\n tensor([ 2200,  2371,  4683,  ...,  2205,    18, 27135]),\n tensor([2119, 2062, 3605,  ..., 2507, 4441, 3676]),\n tensor([4455,   18,   18,  ..., 4007, 2170, 6640]),\n tensor([2205, 1668, 4182,  ...,   16, 3744, 1513]),\n tensor([2062, 5208, 2069,  ..., 4898, 8886, 2088]),\n tensor([  18, 1397,  818,  ..., 2440, 2470, 4392]),\n tensor([ 1896, 29846,  2073,  ...,    24, 14900,  3777]),\n tensor([4240,   16, 7169,  ..., 2429, 2151, 2496]),\n tensor([2170,   16, 2119,  ..., 4041, 2126, 2259]),\n tensor([ 4198,  5058,  3702,  ...,  2210, 12736,  3845]),\n tensor([2897, 3389, 4289,  ..., 9244, 2075, 2053]),\n tensor([25014,  2170,     3,  ...,  2205,  2259,  2376]),\n tensor([ 2031, 12552,  4702,  ...,  2507, 16941,  2021]),\n tensor([ 2073,    26,  2205,  ...,  2062, 10171,  1570]),\n tensor([1264,   16, 2507,  ...,   18, 4056, 3657]),\n tensor([11336,  4343,  2088,  ...,  4670,  2020, 28674]),\n tensor([ 2031,  2254, 18664,  ...,    21,  2055,    18]),\n tensor([2079, 2037, 3819,  ..., 2624,   16, 6819]),\n tensor([11807,  2170,  5949,  ...,  5377,  5993,  2440]),\n tensor([ 2470,  3801, 19521,  ...,    24, 17975,    11]),\n tensor([29223,  2827,  7833,  ...,  2624,    16,  1492]),\n tensor([ 2069,  1826,  1295,  ...,  2170,  6751, 18164]),\n tensor([8318, 6503, 2874,  ..., 4056, 2328, 4152]),\n tensor([  944, 28674,  2027,  ...,  2019,    16,  2079]),\n tensor([2468,   18, 2170,  ..., 2079, 8941, 1126]),\n tensor([  818, 20140,   751,  ...,  3752,  2125,    11]),\n tensor([2088, 8010, 2051,  ..., 7288, 2225,  604]),\n tensor([1513, 4658, 2112,  ..., 2477, 2121, 4470]),\n tensor([4007, 2522, 3853,  ...,  886, 3749, 2440]),\n tensor([2, 2, 2,  ..., 2, 2, 2])]"
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "outputs": [],
   "source": [
    "# sentences = [tok.encode_plus(i[0],max_length=64) for i in input_df.values]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "outputs": [
    {
     "data": {
      "text/plain": "64"
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(train_loader.dataset.sentences[4]['input_ids'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# [tok.encode_plus(i[0],max_length=64,padding='max_length',truncation=True) for i in input_df.values]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "outputs": [],
   "source": [
    "# [tok.encode_plus(i[0],max_length=64,padding='max_length',truncation=True) for i in input_df.values]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([0, 0, 0,  ..., 0, 0, 0]), tensor([ 1282,  4619, 23236,  ...,  4041, 14900, 10427]), tensor([ 2283, 16781, 14908,  ..., 14223,   879, 29047]), tensor([2421, 2067, 3271,  ..., 2079, 2199, 2053]), tensor([2073, 1078, 2588,  ..., 3824, 2154, 2376]), tensor([ 5574,  2116, 12799,  ...,  3877,  2073,  2021]), tensor([ 2470,  2460,  2259,  ..., 10697,  6273,  2259]), tensor([1264, 2170, 8680,  ..., 3751, 2470, 4407]), tensor([ 6233,  1513,  5129,  ...,  6233, 16842,  7271]), tensor([ 4973,  2259,  2154,  ..., 12325,  2145, 14659]), tensor([ 2097,  7802,  2069,  ..., 11830,  6701,    11]), tensor([ 2283,  6233,  3752,  ...,  7138,  2470, 21512]), tensor([ 2052,  4672, 11187,  ...,  2069,  5008,  1381]), tensor([8808, 2021, 7045,  ..., 3691, 8185, 2318]), tensor([ 2097,  3801, 19521,  ..., 31302,  2069,  2057]), tensor([2331, 2827, 3704,  ..., 5418, 7492, 2052]), tensor([ 6233, 28674,  2205,  ...,  2173,  5008,  2203]), tensor([12168,    18,  2259,  ...,  4584,  2189,  4193]), tensor([  648,  4789, 20401,  ...,  2496,  9595,  2725]), tensor([ 6277,  2021, 11075,  ...,  2359,  4474,    11]), tensor([2069, 2200, 3819,  ..., 2062, 2138, 3604]), tensor([ 3689,  8886, 11835,  ...,    18,  5916,   114]), tensor([ 772, 2069, 2520,  ..., 5764, 1295, 4501]), tensor([2073, 1902, 6233,  ..., 2440, 1513, 2079]), tensor([4429, 4795, 7362,  ..., 1041, 2259, 1521]), tensor([2069, 5217, 2470,  ..., 2170, 3841, 2128]), tensor([ 4705,  2440,  8808,  ...,  8484,  2079, 12121]), tensor([2088, 4672, 2275,  ..., 7488, 4318, 7805]), tensor([1513, 2021, 2327,  ..., 5125, 2200,  115]), tensor([4007, 2200, 2154,  ..., 2440, 3777, 5763]), tensor([4822, 4561, 2069,  ..., 3710, 2757, 2088]), tensor([3080, 7488, 7045,  ..., 2429, 2088, 4348]), tensor([ 2067,  7355, 19521,  ...,  2170,  1513,  2470]), tensor([2115, 2121, 1513,  ..., 7744, 2062, 4501]), tensor([ 2200,  2371,  4683,  ...,  2205,    18, 27135]), tensor([2119, 2062, 3605,  ..., 2507, 4441, 3676]), tensor([4455,   18,   18,  ..., 4007, 2170, 6640]), tensor([2205, 1668, 4182,  ...,   16, 3744, 1513]), tensor([2062, 5208, 2069,  ..., 4898, 8886, 2088]), tensor([  18, 1397,  818,  ..., 2440, 2470, 4392]), tensor([ 1896, 29846,  2073,  ...,    24, 14900,  3777]), tensor([4240,   16, 7169,  ..., 2429, 2151, 2496]), tensor([2170,   16, 2119,  ..., 4041, 2126, 2259]), tensor([ 4198,  5058,  3702,  ...,  2210, 12736,  3845]), tensor([2897, 3389, 4289,  ..., 9244, 2075, 2053]), tensor([25014,  2170,     3,  ...,  2205,  2259,  2376]), tensor([ 2031, 12552,  4702,  ...,  2507, 16941,  2021]), tensor([ 2073,    26,  2205,  ...,  2062, 10171,  1570]), tensor([1264,   16, 2507,  ...,   18, 4056, 3657]), tensor([11336,  4343,  2088,  ...,  4670,  2020, 28674]), tensor([ 2031,  2254, 18664,  ...,    21,  2055,    18]), tensor([2079, 2037, 3819,  ..., 2624,   16, 6819]), tensor([11807,  2170,  5949,  ...,  5377,  5993,  2440]), tensor([ 2470,  3801, 19521,  ...,    24, 17975,    11]), tensor([29223,  2827,  7833,  ...,  2624,    16,  1492]), tensor([ 2069,  1826,  1295,  ...,  2170,  6751, 18164]), tensor([8318, 6503, 2874,  ..., 4056, 2328, 4152]), tensor([  944, 28674,  2027,  ...,  2019,    16,  2079]), tensor([2468,   18, 2170,  ..., 2079, 8941, 1126]), tensor([  818, 20140,   751,  ...,  3752,  2125,    11]), tensor([2088, 8010, 2051,  ..., 7288, 2225,  604]), tensor([1513, 4658, 2112,  ..., 2477, 2121, 4470]), tensor([4007, 2522, 3853,  ...,  886, 3749, 2440]), tensor([2, 2, 2,  ..., 2, 2, 2])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# # for data in train_loader:\n",
    "#     print(data)\n",
    "#     break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "outputs": [],
   "source": [
    "train_sampler = TextSampler(trn_idx)\n",
    "valid_sampler = TextSampler(val_idx)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "outputs": [],
   "source": [
    "# import re\n",
    "# train_data = CateDataset(train_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "outputs": [],
   "source": [
    "# train_loader = DataLoader(train_data, batch_sampler=train_sampler)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [201]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m data \u001B[38;5;129;01min\u001B[39;00m train_loader:\n\u001B[0;32m      2\u001B[0m     \u001B[38;5;28mprint\u001B[39m(data)\n\u001B[0;32m      3\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[1;32mc:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:521\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    519\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    520\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()\n\u001B[1;32m--> 521\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    522\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    523\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    524\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    525\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32mc:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:561\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    559\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    560\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 561\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    562\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    563\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data)\n",
      "File \u001B[1;32mc:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfetch\u001B[39m(\u001B[38;5;28mself\u001B[39m, possibly_batched_index):\n\u001B[0;32m     48\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_collation:\n\u001B[1;32m---> 49\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     51\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32mc:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfetch\u001B[39m(\u001B[38;5;28mself\u001B[39m, possibly_batched_index):\n\u001B[0;32m     48\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_collation:\n\u001B[1;32m---> 49\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     51\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "Input \u001B[1;32mIn [197]\u001B[0m, in \u001B[0;36mCateDataset.__getitem__\u001B[1;34m(self, idx)\u001B[0m\n\u001B[0;32m     27\u001B[0m \u001B[38;5;66;03m# if idx >= len(self.tokens):\u001B[39;00m\n\u001B[0;32m     28\u001B[0m \u001B[38;5;66;03m#     raise StopIteration\u001B[39;00m\n\u001B[0;32m     29\u001B[0m \n\u001B[0;32m     30\u001B[0m \u001B[38;5;66;03m# idx 에 해당하는 상품명 가져오기 , 상품명은 문자열로 저장돼 있음\u001B[39;00m\n\u001B[0;32m     31\u001B[0m \u001B[38;5;28mprint\u001B[39m(idx)\n\u001B[1;32m---> 33\u001B[0m tokens \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtokens\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m     34\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m tokens\n",
      "\u001B[1;31mIndexError\u001B[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "# for data in train_loader:\n",
    "#     print(data)\n",
    "#     break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'T'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\indexes\\base.py:3803\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3802\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3803\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3804\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\_libs\\index.pyx:138\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\_libs\\index.pyx:165\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'T'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Input \u001B[1;32mIn [169]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m data \u001B[38;5;129;01min\u001B[39;00m train_loader:\n\u001B[0;32m      2\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[1;32mc:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:521\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    519\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    520\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()\n\u001B[1;32m--> 521\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    522\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    523\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    524\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    525\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32mc:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:561\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    559\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    560\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 561\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    562\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    563\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data)\n",
      "File \u001B[1;32mc:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfetch\u001B[39m(\u001B[38;5;28mself\u001B[39m, possibly_batched_index):\n\u001B[0;32m     48\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_collation:\n\u001B[1;32m---> 49\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     51\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32mc:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfetch\u001B[39m(\u001B[38;5;28mself\u001B[39m, possibly_batched_index):\n\u001B[0;32m     48\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_collation:\n\u001B[1;32m---> 49\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     51\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\frame.py:3804\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3802\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   3803\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[1;32m-> 3804\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3805\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[0;32m   3806\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3803\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[0;32m   3804\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m-> 3805\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m   3806\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m   3807\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[0;32m   3808\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[0;32m   3809\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[0;32m   3810\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[1;31mKeyError\u001B[0m: 'T'"
     ]
    }
   ],
   "source": [
    "for data in train_loader:\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "valid_loader = DataLoader(dataset, batch_sampler=valid_sampler)\n",
    "return (train_loader, valid_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_01512\n"
     ]
    }
   ],
   "source": [
    "for d in iter(train_df['id'].loc[trn_idx]):\n",
    "    print(d)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [],
   "source": [
    "for data in train_sampler:\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [
    {
     "data": {
      "text/plain": "'T'"
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'T'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\indexes\\base.py:3803\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3802\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3803\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3804\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\_libs\\index.pyx:138\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\_libs\\index.pyx:165\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'T'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Input \u001B[1;32mIn [86]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m data \u001B[38;5;129;01min\u001B[39;00m train_loader:\n\u001B[0;32m      2\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[1;32mc:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:521\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    519\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    520\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()\n\u001B[1;32m--> 521\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    522\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    523\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    524\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    525\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32mc:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:561\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    559\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    560\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 561\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    562\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    563\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data)\n",
      "File \u001B[1;32mc:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfetch\u001B[39m(\u001B[38;5;28mself\u001B[39m, possibly_batched_index):\n\u001B[0;32m     48\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_collation:\n\u001B[1;32m---> 49\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     51\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32mc:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfetch\u001B[39m(\u001B[38;5;28mself\u001B[39m, possibly_batched_index):\n\u001B[0;32m     48\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_collation:\n\u001B[1;32m---> 49\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     51\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\frame.py:3804\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3802\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   3803\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[1;32m-> 3804\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3805\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[0;32m   3806\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3803\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[0;32m   3804\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m-> 3805\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m   3806\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m   3807\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[0;32m   3808\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[0;32m   3809\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[0;32m   3810\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[1;31mKeyError\u001B[0m: 'T'"
     ]
    }
   ],
   "source": [
    "for data in train_loader:\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "valid_loader = DataLoader(train, batch_sampler=valid_sampler)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "train_sampler = ImageSampler(trn_idx)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "\n",
    "train_loader = DataLoader(train_df, batch_sampler=train_sampler)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'경'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\indexes\\base.py:3803\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3802\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3803\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3804\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\_libs\\index.pyx:138\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\_libs\\index.pyx:165\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: '경'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Input \u001B[1;32mIn [71]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m data \u001B[38;5;129;01min\u001B[39;00m train_loader:\n\u001B[0;32m      2\u001B[0m     \u001B[38;5;28mprint\u001B[39m(train_loader)\n",
      "File \u001B[1;32mc:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:521\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    519\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    520\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()\n\u001B[1;32m--> 521\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    522\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    523\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    524\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    525\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32mc:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:561\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    559\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    560\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 561\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    562\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    563\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data)\n",
      "File \u001B[1;32mc:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfetch\u001B[39m(\u001B[38;5;28mself\u001B[39m, possibly_batched_index):\n\u001B[0;32m     48\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_collation:\n\u001B[1;32m---> 49\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     51\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32mc:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfetch\u001B[39m(\u001B[38;5;28mself\u001B[39m, possibly_batched_index):\n\u001B[0;32m     48\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_collation:\n\u001B[1;32m---> 49\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     51\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\frame.py:3804\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3802\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   3803\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[1;32m-> 3804\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3805\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[0;32m   3806\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3803\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[0;32m   3804\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m-> 3805\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m   3806\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m   3807\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[0;32m   3808\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[0;32m   3809\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[0;32m   3810\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[1;31mKeyError\u001B[0m: '경'"
     ]
    }
   ],
   "source": [
    "for data in train_loader:\n",
    "    print(train_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "data": {
      "text/plain": "                id                       img_path  \\\n0      TRAIN_00000  ./image/train/TRAIN_00000.jpg   \n1      TRAIN_00001  ./image/train/TRAIN_00001.jpg   \n2      TRAIN_00002  ./image/train/TRAIN_00002.jpg   \n3      TRAIN_00003  ./image/train/TRAIN_00003.jpg   \n4      TRAIN_00004  ./image/train/TRAIN_00004.jpg   \n...            ...                            ...   \n16981  TRAIN_16981  ./image/train/TRAIN_16981.jpg   \n16982  TRAIN_16982  ./image/train/TRAIN_16982.jpg   \n16983  TRAIN_16983  ./image/train/TRAIN_16983.jpg   \n16984  TRAIN_16984  ./image/train/TRAIN_16984.jpg   \n16985  TRAIN_16985  ./image/train/TRAIN_16985.jpg   \n\n                                                overview          cat1  \\\n0      소안항은 조용한 섬으로 인근해안이 청정해역으로 일찍이 김 양식을 해서 높은 소득을 ...            자연   \n1      경기도 이천시 모가면에 있는 골프장으로 대중제 18홀이다. 회원제로 개장을 했다가 ...           레포츠   \n2      금오산성숯불갈비는 한우고기만을 전문적으로 취급하고 사용하는 부식 자재 또한 유기농법...            음식   \n3      철판 위에서 요리하는 안동찜닭을 맛볼 수 있는 곳이다. 경상북도 안동시에 있는 한식...            음식   \n4      ※ 영업시간 10:30 ~ 20:30\\n\\n3대에 걸쳐 아귀만을 전문으로 취급하는 ...            음식   \n...                                                  ...           ...   \n16981  해발 12000m에 자리한 식담겸 카페점문점이다.<br>곤드레밥과 감자전을 판매하고...            음식   \n16982  설악힐호텔은 동해고속도로 속초톨게이트에서 멀지 않은 관광로 변에 있다. 속초의 대표...            숙박   \n16983  충남 서산시 중심가에 위치한 줌모텔은 프라이버스가 보장되는 조용한 공간으로 가치가 ...            숙박   \n16984  토토큰바위캠핑장은 경기도 가평지역 내에서도 청정지역으로 손꼽히는 지역으로 주변에 화...           레포츠   \n16985  포천의 진산으로 불리우는 왕방산(王訪山)에는 천년의 역사를 간직하고 있는 왕산사(王...  인문(문화/예술/역사)   \n\n         cat2       cat3  cat3_enc  \n0       자연관광지      항구/포구       120  \n1      육상 레포츠         골프         8  \n2         음식점         한식       118  \n3         음식점         한식       118  \n4         음식점         한식       118  \n...       ...        ...       ...  \n16981     음식점         한식       118  \n16982    숙박시설         모텔        31  \n16983    숙박시설         모텔        31  \n16984  육상 레포츠  야영장,오토캠핑장        73  \n16985   역사관광지         사찰        52  \n\n[16986 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>img_path</th>\n      <th>overview</th>\n      <th>cat1</th>\n      <th>cat2</th>\n      <th>cat3</th>\n      <th>cat3_enc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>TRAIN_00000</td>\n      <td>./image/train/TRAIN_00000.jpg</td>\n      <td>소안항은 조용한 섬으로 인근해안이 청정해역으로 일찍이 김 양식을 해서 높은 소득을 ...</td>\n      <td>자연</td>\n      <td>자연관광지</td>\n      <td>항구/포구</td>\n      <td>120</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>TRAIN_00001</td>\n      <td>./image/train/TRAIN_00001.jpg</td>\n      <td>경기도 이천시 모가면에 있는 골프장으로 대중제 18홀이다. 회원제로 개장을 했다가 ...</td>\n      <td>레포츠</td>\n      <td>육상 레포츠</td>\n      <td>골프</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>TRAIN_00002</td>\n      <td>./image/train/TRAIN_00002.jpg</td>\n      <td>금오산성숯불갈비는 한우고기만을 전문적으로 취급하고 사용하는 부식 자재 또한 유기농법...</td>\n      <td>음식</td>\n      <td>음식점</td>\n      <td>한식</td>\n      <td>118</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>TRAIN_00003</td>\n      <td>./image/train/TRAIN_00003.jpg</td>\n      <td>철판 위에서 요리하는 안동찜닭을 맛볼 수 있는 곳이다. 경상북도 안동시에 있는 한식...</td>\n      <td>음식</td>\n      <td>음식점</td>\n      <td>한식</td>\n      <td>118</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>TRAIN_00004</td>\n      <td>./image/train/TRAIN_00004.jpg</td>\n      <td>※ 영업시간 10:30 ~ 20:30\\n\\n3대에 걸쳐 아귀만을 전문으로 취급하는 ...</td>\n      <td>음식</td>\n      <td>음식점</td>\n      <td>한식</td>\n      <td>118</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>16981</th>\n      <td>TRAIN_16981</td>\n      <td>./image/train/TRAIN_16981.jpg</td>\n      <td>해발 12000m에 자리한 식담겸 카페점문점이다.&lt;br&gt;곤드레밥과 감자전을 판매하고...</td>\n      <td>음식</td>\n      <td>음식점</td>\n      <td>한식</td>\n      <td>118</td>\n    </tr>\n    <tr>\n      <th>16982</th>\n      <td>TRAIN_16982</td>\n      <td>./image/train/TRAIN_16982.jpg</td>\n      <td>설악힐호텔은 동해고속도로 속초톨게이트에서 멀지 않은 관광로 변에 있다. 속초의 대표...</td>\n      <td>숙박</td>\n      <td>숙박시설</td>\n      <td>모텔</td>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>16983</th>\n      <td>TRAIN_16983</td>\n      <td>./image/train/TRAIN_16983.jpg</td>\n      <td>충남 서산시 중심가에 위치한 줌모텔은 프라이버스가 보장되는 조용한 공간으로 가치가 ...</td>\n      <td>숙박</td>\n      <td>숙박시설</td>\n      <td>모텔</td>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>16984</th>\n      <td>TRAIN_16984</td>\n      <td>./image/train/TRAIN_16984.jpg</td>\n      <td>토토큰바위캠핑장은 경기도 가평지역 내에서도 청정지역으로 손꼽히는 지역으로 주변에 화...</td>\n      <td>레포츠</td>\n      <td>육상 레포츠</td>\n      <td>야영장,오토캠핑장</td>\n      <td>73</td>\n    </tr>\n    <tr>\n      <th>16985</th>\n      <td>TRAIN_16985</td>\n      <td>./image/train/TRAIN_16985.jpg</td>\n      <td>포천의 진산으로 불리우는 왕방산(王訪山)에는 천년의 역사를 간직하고 있는 왕산사(王...</td>\n      <td>인문(문화/예술/역사)</td>\n      <td>역사관광지</td>\n      <td>사찰</td>\n      <td>52</td>\n    </tr>\n  </tbody>\n</table>\n<p>16986 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "'경기도 이천시 모가면에 있는 골프장으로 대중제 18홀이다. 회원제로 개장을 했다가 2016년 대중제로 전환하여 재개장했다. 총 부지 약 980,,000㎡에 전장 6,607m에 18홀 파 72이다. Lake 코스와 Mountain 코스가 있다. 미국 100대 골프 코스 설계자인 짐 파지오가 아마추어에게는 쉽고 프로골퍼에게는 어렵게 설계했다고 한다. 가까이에 뉴스프링빌CC, 써닝포인트CC, 비에이비스타CC, 덕평CC 등의 골프장이 있다.'"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "def get_all_split_loaders(dataset, cv_splits, aug_count=5, batch_size=30):\n",
    "    \"\"\"Create DataLoaders for each split.\n",
    "\n",
    "    Keyword arguments:\n",
    "    dataset -- Dataset to sample from.\n",
    "    cv_splits -- Array containing indices of samples to\n",
    "                 be used in each fold for each split.\n",
    "    aug_count -- Number of variations for each sample in dataset.\n",
    "    batch_size -- batch size.\n",
    "\n",
    "    \"\"\"\n",
    "    split_samplers = []\n",
    "\n",
    "    for i in range(len(cv_splits)):\n",
    "        split_samplers.append(\n",
    "            create_split_loaders(dataset,\n",
    "                                 cv_splits[i],\n",
    "                                 aug_count,\n",
    "                                 batch_size)\n",
    "        )\n",
    "    return split_samplers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "dataset = Dataset(transform=transform, device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataloaders = get_all_split_loaders(dataset, splits, aug_count=5, batch_size=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "[(array([    0,     1,     2, ..., 16982, 16984, 16985]),\n  array([    4,     5,    12, ..., 16978, 16980, 16983])),\n (array([    0,     3,     4, ..., 16982, 16983, 16984]),\n  array([    1,     2,     6, ..., 16963, 16972, 16985])),\n (array([    1,     2,     3, ..., 16980, 16983, 16985]),\n  array([    0,    10,    11, ..., 16981, 16982, 16984])),\n (array([    0,     1,     2, ..., 16983, 16984, 16985]),\n  array([    3,     7,     8, ..., 16973, 16975, 16979]))]"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0])"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_idx"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 1512,  1552,  1705, ..., 16983, 16984, 16985])"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_idx"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}