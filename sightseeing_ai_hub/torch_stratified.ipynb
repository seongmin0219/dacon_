{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, BertConfig,PreTrainedTokenizer\n",
    "import unicodedata"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./input/train.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "'소안항은 조용한 섬으로 인근해안이 청정해역으로 일찍이 김 양식을 해서 높은 소득을 올리고 있으며 바다낚시터로도 유명하다. 항 주변에 설치된 양식장들은 섬사람들의 부지런한 생활상을 고스 란히 담고 있으며 일몰 때 섬의 정경은 바다의 아름다움을 그대로 품고 있는 듯하다. 또한, 섬에는 각시여 전설, 도둑바위 등의 설화가 전해 내려오고 있으며, 매년 정월 풍어제 풍속이 이어지고 있다.<br>'"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df.cat3 =='항구/포구'].iloc[0]['overview']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "'* 바다낚시와 자연산 회를 즐길 수 있는 곳, 홍원항 *\\n\\n홍원항은 춘장대해수욕장으로 가는 길목에 있으며, 바다낚시와 자연산 회를 즐길 수 있는 곳으로 바다로 뻗은 방파재와 희고 빨간 등대가 있어 아름다운 곳이다. 서해에서 안면도와 대천 다음으로 명성을 날리는 지역이 서천 마량이다. 연인들이 호젓하게 떠나고 싶어하는 선호지역 순으로는 안면도와 대천을 앞선다. 일출과 일몰을 함께 볼 수 있는 마량 포구가 있고, 동백정과 춘장대해수욕장이 지척이다. 동백정에서 동백이 한창일 때는 주꾸미가 홍원항에서 나고, 해돋이와 해넘이를 보려는 사람들로 붐빌 때는 전어가 홍원항으로 사람을 이끈다. 홍원항은 마량포구보다 규모도 크고 배도 많다. 해변가에는 그 자리에서 회를 떠주는 가게들이 있어서 저렴한 가격에 싱싱한 회를 맛볼 수 있다.\\n\\n수산물시장과 낚시가게 춘장대 해수욕장과 동백정 사이 움푹 들어간 만속에 홍원항이 자리잡고 있다. 이름난 항구들에 비해 규모는 작지만 서해안 항구 가운데 유독 조수간만의 차이가 적어 어선들이 많이 출입하는 곳이다. 홍원항을 가장 유명케 하는 것은 아무래도 가을에 나는 전어다. 돈먹는 생선이라 해서 \\'전어\\'라 불리는 이 생선은 예부터 \\'가을전어 대가리엔 참깨가 서말’이라는 말이 문헌에 나오고, ‘집 나간 며느리도 전어 굽는 냄새를 맡으면 집에 돌아온다.’라는 말이 있을 정도로 서해안에서 나는 생선 중 최고로 꼽힌다. 전어는 사철 나지만 9월 말부터 11월 초 사이에 맛이 가장 좋기로 소문나 있으며 홍원항은 전남 광양항과 함께 전어가 가장 많이 잡히는 곳이다. 홍원항에서는 해마다 9월 말부터 2주일에 걸쳐 \\'전어축제\\'를 연다. 홍원항에는 전어를 주로 회나 구이로 먹는다. 홍원항에서 전어나 주꾸미를 맛보고 나서 가볼만한 곳은 단연 동백정이다. 중간에 만나는 해양박물관도 빼놓을 수 없는 곳이다. 바다생물들을 박재로 전시해 놓은 것도 볼거리지만 박물관 위층에서 내려다보이는 마량포구의 전경 또한 일품이다. \\n\\n* 홍원항의 대표적인 축제, 전어축제 D(9월 말~11월 초) *\\n\\n충남 서천에서는 전어를 주로회덮밥, 회무침, 구이를 하여 상에 올린다. 전어회는 내장과 두부를 제거하고 뼈를 발라낸 뒤, 가늘게 썰어 회로 올리거나 그렇게 썰어낸 전어와 온갖 야채에 초고추장을 얹어 회덮밥으로 손님상에 올리는 것이다. 때로는 뼈째 두툼하게 썰어 낸 전어에 된장과 마늘을 곁들여 상추에 싸먹는 \"뼈꼬시\"를 찾는 이들도 많다. 더불어 그 내장은 따로 젓을 담가 단골손님 상에 올리기도 하는데, 그것이 바로 \"전어젓\"이다. 전어젓은 예로부터 젓갈 중 으뜸으로 여겼다. 전어회는 숙취를 제거하고, 피부미용에도 효과가 있는 것으로 알려져 있다.\\n\\n세종실록지리지에서도 충청도, 경상도, 함경도에서 전어가 많이 나는 것으로 되어있다. 또한, 맛이 좋아 사먹는 사람이 돈을 생각하지 않기 때문에 전어(錢魚)라고 하였고 서유구의 \\'임원경제지\\'에서는 \"가을전어 대가리엔 참깨가 서말\"이라는 문헌이 있으니 가을에 잡히는 전어의 맛이 일품이라는 것을 입증하는 것이 된다. 그리고 옛부터 구전되어온 말을 빌리자면「집나간 며느리도 전어 굽는 냄새를 맡으면 집에 돌아온다」 라는 말이 있듯이 그 냄새 또한 잃었던 입맛을 되찾게 한다. 주요 성분은 전어 100g중 수분 71g, 단백질 25g, 지방 2g, 회분 2g으로 이루어져 있고 120㎉의 열량을 내며, 지방이 2% 밖에 되지않아 식이요법은 물론 다이어트 음식으로 각광을 받고 있다. \\n\\n몸통은 측편하고 빛깔은 푸른 빛이 짙으며 누런 빛을 띠고 있으며 등에는 갈색반점으로 된 세로줄이 여러 줄 이며 옆구리에는 큰 흑색반점이 있고, 배쪽은 희며 주둥이는 아래 턱의 끝보다 좀 나와 있다. 비늘은 크고 둥글며 후부 및 배쪽에는 예맥린이 줄지어 있고, 몸 높이는 몸 길이의 약 2/7에 해당하고, 전장은 150∼310㎜정도이다. 고대 중국의 화폐모양과 유사하다하여 \\'전어(錢魚)\\'라 불리운다. 전어(錢魚)의 참맛은 9월 말부터 11월 초까지가 최고의 맛을 자랑하며 회, 회무침, 구이 등의 다양한 요리방법이 있다. 그 동안 부산전어(錢魚)가 전국 최고로 알려졌지만 현재는 부산에서 서천 전어를 수입해가고 있는 등 맛과 품질에서 전국최고로 자리매김하고 있다.'"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df.cat3 =='항구/포구'].iloc[1]['overview']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import gluonnlp as nlp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "MAX_LEN = 64"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'kobert'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Input \u001B[1;32mIn [17]\u001B[0m, in \u001B[0;36m<cell line: 4>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mre\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mgluonnlp\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnlp\u001B[39;00m\n\u001B[1;32m----> 4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkobert\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m download, get_tokenizer\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkobert\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpytorch_kobert\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m get_pytorch_kobert_model\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkobert\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmxnet_kobert\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m get_mxnet_kobert_model\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'kobert'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import gluonnlp as nlp\n",
    "\n",
    "from kobert.utils.utils import download, get_tokenizer\n",
    "from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
    "from kobert.mxnet_kobert import get_mxnet_kobert_model\n",
    "from kobert.onnx_kobert import get_onnx_kobert_model\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import re\n",
    "from sklearn.model_selection import StratifiedGroupKFold,StratifiedKFold"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_pytorch_kobert_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [18]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m bertmodel, vocab \u001B[38;5;241m=\u001B[39m \u001B[43mget_pytorch_kobert_model\u001B[49m()\n",
      "\u001B[1;31mNameError\u001B[0m: name 'get_pytorch_kobert_model' is not defined"
     ]
    }
   ],
   "source": [
    "bertmodel, vocab = get_pytorch_kobert_model()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bertmodel, vocab = get_pytorch_kobert_model()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer()\n",
    "tok = nlp.data.BERTSPTokenizer(tokenizer,vocab,lower=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nlp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [13]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m transform \u001B[38;5;241m=\u001B[39m \u001B[43mnlp\u001B[49m\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mBERTSentenceTransform(\n\u001B[0;32m      2\u001B[0m       tok, max_seq_length\u001B[38;5;241m=\u001B[39mMAX_LEN, pad\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,pair\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'nlp' is not defined"
     ]
    }
   ],
   "source": [
    "transform = nlp.data.BERTSentenceTransform(\n",
    "      tok, max_seq_length=MAX_LEN, pad=True,pair=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "'소안항은 조용한 섬으로 인근해안이 청정해역으로 일찍이 김 양식을 해서 높은 소득을 올리고 있으며 바다낚시터로도 유명하다. 항 주변에 설치된 양식장들은 섬사람들의 부지런한 생활상을 고스 란히 담고 있으며 일몰 때 섬의 정경은 바다의 아름다움을 그대로 품고 있는 듯하다. 또한, 섬에는 각시여 전설, 도둑바위 등의 설화가 전해 내려오고 있으며, 매년 정월 풍어제 풍속이 이어지고 있다.<br>'"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['overview'].values[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "\n",
    "VOCAB_FILES_NAMES = {\"vocab_file\": \"tokenizer_78b3253a26.model\",\n",
    "                     \"vocab_txt\": \"vocab.txt\"}\n",
    "\n",
    "PRETRAINED_VOCAB_FILES_MAP = {\n",
    "    \"vocab_file\": {\n",
    "        \"monologg/kobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert/tokenizer_78b3253a26.model\",\n",
    "        \"monologg/kobert-lm\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert-lm/tokenizer_78b3253a26.model\",\n",
    "        \"monologg/distilkobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/distilkobert/tokenizer_78b3253a26.model\"\n",
    "    },\n",
    "    \"vocab_txt\": {\n",
    "        \"monologg/kobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert/vocab.txt\",\n",
    "        \"monologg/kobert-lm\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert-lm/vocab.txt\",\n",
    "        \"monologg/distilkobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/distilkobert/vocab.txt\"\n",
    "    }\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "\n",
    "PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES = {\n",
    "    \"monologg/kobert\": 512,\n",
    "    \"monologg/kobert-lm\": 512,\n",
    "    \"monologg/distilkobert\": 512\n",
    "}\n",
    "\n",
    "PRETRAINED_INIT_CONFIGURATION = {\n",
    "    \"monologg/kobert\": {\"do_lower_case\": False},\n",
    "    \"monologg/kobert-lm\": {\"do_lower_case\": False},\n",
    "    \"monologg/distilkobert\": {\"do_lower_case\": False}\n",
    "}\n",
    "\n",
    "SPIECE_UNDERLINE = u'▁'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "class args:\n",
    "    pt = 'monologg/kobert'\n",
    "    MAX_LEN = 64"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pt = args.pt\n",
    "tokenizer = KoBertTokenizer.from_pretrained(pt,  cache_dir='bert_ckpt', do_lower_case=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained(pt)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df['overview'].values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "MAX_LEN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokenizer.special_tokens_map"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokenizer.token2idx['[SEP]']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df['overview'].values[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from eunjeon import Mecab\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mecab = Mecab()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tags = ['JK', 'JKS', 'JKC', 'JKG', 'JKO', 'JKB', 'JKV', 'JKQ', 'JX', 'JC', 'EP', 'EF', 'EC', 'ETN', 'ETM']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def remove_josa_mecab(df, tags):\n",
    "    for idx ,row in tqdm(df.iterrows() , desc='removing josa', total=len(df)):\n",
    "        josa_removed = [x[0] for x in mecab.pos(row['overview']) if x[1] not in tags]\n",
    "        df.loc[idx,'overview'] = ' '.join(josa_removed)\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "remove_df = remove_josa_mecab(train_df,tags)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "remove_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "MAX_LEN = args.MAX_LEN\n",
    "tokenizer.encode_plus( text = remove_df['overview'].values[0],\n",
    "    add_special_tokens=True,\n",
    "    max_length=225,\n",
    "    pad_to_max_length=True,\n",
    "    return_attention_mask=True,\n",
    "    truncation = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "MAX_LEN = args.MAX_LEN\n",
    "tokenizer.encode_plus( text = train_df['overview'].values[0],\n",
    "    add_special_tokens=True,\n",
    "    max_length=225,\n",
    "    pad_to_max_length=True,\n",
    "    return_attention_mask=True,\n",
    "    truncation = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from KoBERT import kobert"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}