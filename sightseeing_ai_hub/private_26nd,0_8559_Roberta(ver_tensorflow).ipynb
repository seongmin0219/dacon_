{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "'소안항은 조용한 섬으로 인근해안이 청정해역으로 일찍이 김 양식을 해서 높은 소득을 올리고 있으며 바다낚시터로도 유명하다 항 주변에 설치된 양식장들은 섬사람들의 부지런한 생활상을 고스 란히 담고 있으며 일몰 때 섬의 정경은 바다의 아름다움을 그대로 품고 있는 듯하다 또한 섬에는 각시여 전설 도둑바위 등의 설화가 전해 내려오고 있으며 매년 정월 풍어제 풍속이 이어지고 있다'"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# %matplotlib inline\n",
    "\n",
    "plt.rc('font',  family='Malgun Gothic')\n",
    "plt.rc('axes', unicode_minus=False)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import TFAutoModel\n",
    "transformers.logging.set_verbosity_error()\n",
    "\n",
    "import re\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "import argparse\n",
    "\n",
    "# import wandb\n",
    "# from wandb.keras import WandbCallback\n",
    "# wandb.init(project='DACON_235978' , name='gnoeyheat')\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description='gnoeyheat')\n",
    "parser.add_argument('--text_pretrained_model', default='roberta', type=str)\n",
    "parser.add_argument('--text_len', default=300 , type=int)\n",
    "parser.add_argument('--optimizer' , default='sgd' , type=str) # sgd or adam\n",
    "parser.add_argument('--learning_rate', default=0.002, type=float)\n",
    "parser.add_argument('--loss', default='cc', type=str) # cc or fl\n",
    "parser.add_argument('--label_smoothing' ,default=0.1 , type=float)\n",
    "parser.add_argument('--batch_size' , default=1 ,type=int )\n",
    "parser.add_argument('--epochs', default=30, type=int)\n",
    "parser.add_argument('--validation_split' , default=0.1 , type=float)\n",
    "parser.add_argument('--seed', default=1011, type=int)\n",
    "args = parser.parse_args('')\n",
    "\n",
    "# wandb.config.update(args)\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "\n",
    "text_pretrained_model = args.text_pretrained_model\n",
    "text_len = args.text_len\n",
    "BATCH_SIZE = args.batch_size\n",
    "EPOCHS = args.epochs\n",
    "VALIDATION_SPLIT=args.validation_split\n",
    "SEED=args.seed\n",
    "\n",
    "def set_seeds(seed=SEED):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "\n",
    "set_seeds()\n",
    "\n",
    "\n",
    "if args.text_pretrained_model == \"roberta\":\n",
    "    text_pretrained_model = \"klue/roberta-large\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(text_pretrained_model)\n",
    "\n",
    "# tokenizer.truncation_size = 'left'\n",
    "\n",
    "train = pd.read_csv('./input/train.csv')\n",
    "test = pd.read_csv('./input/test.csv')\n",
    "\n",
    "X_txt = train['overview']\n",
    "X_test_txt = test['overview']\n",
    "\n",
    "y = train['cat3']\n",
    "y_encoder = {key: value for key, value in zip(np.unique(y), range(len(np.unique(y))))}\n",
    "y = np.array([y_encoder[k] for k in y ])\n",
    "\n",
    "X_txt.shape,  X_test_txt.shape, y.shape\n",
    "\n",
    "def text_cleaning(df):\n",
    "    df = df.apply(lambda x : re.sub('[^ ㄱ-ㅣ가-힣]+','',x))\n",
    "    df = df.apply(lambda x : ' '.join(x.split()))\n",
    "    return df\n",
    "\n",
    "X_txt = text_cleaning(X_txt)\n",
    "X_test_txt = text_cleaning(X_test_txt)\n",
    "\n",
    "X_txt.iloc[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from hanspell import spell_checker\n",
    "\n",
    "def text_correcting(df):\n",
    "    correct = []\n",
    "    for text in tqdm(df):\n",
    "        if len(text) < 500:\n",
    "            correct.append(spell_checker.check(text).checked)\n",
    "        else:\n",
    "            temp = []\n",
    "            for i in range(0, len(text) , 500):\n",
    "                temp.append(spell_checker.check(text[i:i+500]).checked)\n",
    "            correct.append(''.join(temp))\n",
    "    return pd.Series(correct, name='overview')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "Checked(result=True, original='이문장의맞추법을계산해보시오', checked='이 문장의 맞춤법을 계산해보시오', errors=1, words=OrderedDict([('이', 1), ('문장의', 1), ('맞춤법을', 1), ('계산해보시오', 1)]), time=0.024933576583862305)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spell_checker.check('이문장의맞추법을계산해보시오')#  생각보다 성능좋다 일일이 안해도 될만큼 , 역시나\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "Checked(result=True, original='이문장의맞추법을계산해보시오', checked='이 문장의 맞춤법을 계산해보시오', errors=1, words=OrderedDict([('이', 1), ('문장의', 1), ('맞춤법을', 1), ('계산해보시오', 1)]), time=0.024933815002441406)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spell_checker.check('이문장의맞추법을계산해보시오')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "Checked(result=True, original='점문점이다', checked='전문점이다', errors=1, words=OrderedDict([('전문점이다', 1)]), time=0.015956878662109375)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 생각보다 성능 좋다\n",
    "spell_checker.check('점문점이다')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "#X_txt = text_correcting(X_txt)\n",
    "#77%|███████▋  | 13113/16986 [3:11:20<56:30,  1.14it/s]\n",
    "#JSONDecodeError: Expecting value: line 1 column 1 (char 0) ... ?\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "0        소안항은 조용한 섬으로 인근해안이 청정해역으로 일찍이 김 양식을 해서 높은 소득을 ...\n1        경기도 이천시 모가면에 있는 골프장으로 대중제 홀이다 회원제로 개장을 했다가 년 대...\n2        금오산성숯불갈비는 한우고기만을 전문적으로 취급하고 사용하는 부식 자재 또한 유기농법...\n3        철판 위에서 요리하는 안동찜닭을 맛볼 수 있는 곳이다 경상북도 안동시에 있는 한식 ...\n4             영업시간 대에 걸쳐 아귀만을 전문으로 취급하는 전통과 역사를 자랑하는 음식점이다\n                               ...                        \n16981               해발 에 자리한 식담겸 카페점문점이다곤드레밥과 감자전을 판매하고 있다\n16982    설악힐호텔은 동해고속도로 속초톨게이트에서 멀지 않은 관광로 변에 있다 속초의 대표 ...\n16983    충남 서산시 중심가에 위치한 줌모텔은 프라이버스가 보장되는 조용한 공간으로 가치가 ...\n16984    토토큰바위캠핑장은 경기도 가평지역 내에서도 청정지역으로 손꼽히는 지역으로 주변에 화...\n16985    포천의 진산으로 불리우는 왕방산에는 천년의 역사를 간직하고 있는 왕산사가 자리하고 ...\nName: overview, Length: 16986, dtype: object"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_txt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "#train['overview_correcting'] =  X_txt\n",
    "#train.to_csv('train_overview_correcting.csv', index=False)\n",
    "#X_test_txt = text_correcting(X_test_txt)\n",
    "#test['overview_correcting'].to_csv('test _overview_correcting.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "train.to_csv('data/pp_train.csv', index=False)\n",
    "test.to_csv('data/pp_test.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "'소안항은 조용한 섬으로 인근해안이 청정해역으로 일찍이 김 양식을 해서 높은 소득을 올리고 있으며 바다낚시터로도 유명하다 항 주변에 설치된 양식장들은 섬사람들의 부지런한 생활상을 고스 란히 담고 있으며 일몰 때 섬의 정경은 바다의 아름다움을 그대로 품고 있는 듯하다 또한 섬에는 각시여 전설 도둑바위 등의 설화가 전해 내려오고 있으며 매년 정월 풍어제 풍속이 이어지고 있다'"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_txt.iloc[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "(144.0, 144.0)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['len'] = train['overview'].apply(tokenizer.tokenize).apply(len)\n",
    "test['len'] = test['overview'].apply(tokenizer.tokenize).apply(len)\n",
    "train['len'].median() , test['len'].median()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# tf.keras.utils.Sequence == torch.utils.data.Dataset\n",
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        sentence,\n",
    "        labels,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        include_targets=True\n",
    "    ):\n",
    "        self.sentence = sentence\n",
    "        self.labels = labels\n",
    "        self.shuffle = shuffle\n",
    "        self.batch_size = batch_size\n",
    "        self.include_targets = include_targets\n",
    "        self.tokenizer = tokenizer\n",
    "        self.indexes = np.arange(len(self.sentence))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentence) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        indexes = self.indexes[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "        sentence = self.sentence[indexes]\n",
    "\n",
    "        encoded = self.tokenizer.batch_encode_plus(\n",
    "            sentence.tolist(),\n",
    "            add_special_tokens=True,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length =text_len,\n",
    "            return_tensors='tf',\n",
    "            return_token_type_ids=True,\n",
    "            return_attention_mask=True\n",
    "        )\n",
    "\n",
    "        input_ids = np.array(encoded['input_ids'] , dtype='int32')\n",
    "        attention_masks = np.array(encoded['attention_mask'], dtype='int32')\n",
    "        token_type_ids = np.array(encoded['token_type_ids'],dtype='int32')\n",
    "\n",
    "        if self.include_targets:\n",
    "            labels = np.array(self.labels[indexes], dtype='int32')\n",
    "            return [input_ids, attention_masks, token_type_ids], labels\n",
    "        else:\n",
    "            return [input_ids , attention_masks, token_type_ids]\n",
    "    #on_epoch_end로 인해 epoch이 끈날때마다 shuffle 되는 듯하다\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.RandomState(SEED).shuffle(self.indexes)\n",
    "\n",
    "X_train, X_val , y_train, y_val = train_test_split(X_txt, y , test_size=VALIDATION_SPLIT , random_state=SEED, stratify=y)\n",
    "\n",
    "\n",
    "# to_categorical == one-hot encoding\n",
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "y_val = tf.keras.utils.to_categorical(y_val)\n",
    "\n",
    "X_train.shape, X_val.shape , y_train.shape  , y_val.shape\n",
    "\n",
    "\n",
    "train_ds = DataGenerator(\n",
    "    X_train.values,y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_ds = DataGenerator(\n",
    "    X_val.values, y_val,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Modeling"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "lr = 2e-2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)         [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " attention_masks (InputLayer)   [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " token_type_ids (InputLayer)    [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " tf_roberta_model_1 (TFRobertaM  TFBaseModelOutputWi  336656384  ['input_ids[0][0]',              \n",
      " odel)                          thPooling(last_hidd               'attention_masks[0][0]',        \n",
      "                                en_state=(None, 300               'token_type_ids[0][0]']         \n",
      "                                , 1024),                                                          \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 1024),                                                         \n",
      "                                 hidden_states=None                                               \n",
      "                                , attentions=None)                                                \n",
      "                                                                                                  \n",
      " global_average_pooling1d_1 (Gl  (None, 1024)        0           ['tf_roberta_model_1[0][0]']     \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dropout_147 (Dropout)          (None, 1024)         0           ['global_average_pooling1d_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 128)          131200      ['dropout_147[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 336,787,584\n",
      "Trainable params: 336,787,584\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_ids = tf.keras.layers.Input(\n",
    "    shape=(text_len,), dtype=tf.int32, name='input_ids'\n",
    ")\n",
    "\n",
    "attention_masks = tf.keras.layers.Input(\n",
    "    shape=(text_len,) , dtype=tf.int32, name='attention_masks'\n",
    ")\n",
    "\n",
    "token_type_ids = tf.keras.layers.Input(\n",
    "    shape=(text_len,), dtype=tf.int32, name='token_type_ids'\n",
    ")\n",
    "\n",
    "\n",
    "bert_model = TFAutoModel.from_pretrained(text_pretrained_model, from_pt=True)\n",
    "bert_model.trainable =True\n",
    "\n",
    "bert_output = bert_model(\n",
    "    input_ids, attention_mask=attention_masks, token_type_ids=token_type_ids\n",
    ")\n",
    "\n",
    "\n",
    "x = bert_output.last_hidden_state\n",
    "# GlobalAveragePooling1D 해당 레이어에서는 각 예시에 대해 sequence 차원을 평균하여 고정된 길이의 벡터를 출력한다.\n",
    "# 이를 통해 가변적인 길이의 입력을 간단하게 처리할 수 있다.\n",
    "x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "# y_train.shape[1] one-hot encoding 된 차원을 따르는 것을 의미 y_\n",
    "output = layers.Dense(y_train.shape[1], activation='softmax')(x)\n",
    "\n",
    "\n",
    "# 그래프 생성\n",
    "model = tf.keras.models.Model(\n",
    "    inputs=[input_ids, attention_masks, token_type_ids] , outputs=output\n",
    ")\n",
    "\n",
    "\n",
    "if args.optimizer == 'sgd':\n",
    "    optim = tf.keras.optimizers.SGD(\n",
    "        learning_rate=lr, momentum=0.9\n",
    "    )\n",
    "if args.loss == 'cc':\n",
    "    # categorical 이므로 원-핫 인코딩 문제\n",
    "    loss_function = tf.keras.losses.CategoricalCrossentropy(\n",
    "        label_smoothing=args.label_smoothing\n",
    "    )\n",
    "\n",
    "model.compile(\n",
    "\n",
    "    optimizer=optim,\n",
    "    loss= loss_function,\n",
    "    metrics= tfa.metrics.F1Score(num_classes=y_train.shape[1], average='weighted')\n",
    ")\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "checkpoint_path = f\"load_model/{parser.description}\"\n",
    "\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 20:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "\n",
    "\n",
    "\n",
    "callback = [\n",
    "    tf.keras.callbacks.LearningRateScheduler(scheduler),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        checkpoint_path,\n",
    "        monitor='val_f1_score',\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "        mode='max',\n",
    "    )\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model_1/roberta/pooler/dense/kernel:0', 'tf_roberta_model_1/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model_1/roberta/pooler/dense/kernel:0', 'tf_roberta_model_1/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "15287/15287 [==============================] - ETA: 0s - loss: 4.4376 - f1_score: 0.0797WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "15287/15287 [==============================] - 2874s 187ms/step - loss: 4.4376 - f1_score: 0.0797 - val_loss: 4.0755 - val_f1_score: 0.0682 - lr: 0.0200\n",
      "Epoch 2/30\n",
      "15287/15287 [==============================] - 2822s 185ms/step - loss: 4.2109 - f1_score: 0.0793 - val_loss: 4.0376 - val_f1_score: 0.0682 - lr: 0.0200\n",
      "Epoch 3/30\n",
      "15287/15287 [==============================] - 2829s 185ms/step - loss: 4.1968 - f1_score: 0.0798 - val_loss: 4.1564 - val_f1_score: 0.0041 - lr: 0.0200\n",
      "Epoch 4/30\n",
      "15287/15287 [==============================] - 2824s 185ms/step - loss: 4.1964 - f1_score: 0.0792 - val_loss: 4.1189 - val_f1_score: 0.0682 - lr: 0.0200\n",
      "Epoch 5/30\n",
      "15287/15287 [==============================] - 2839s 186ms/step - loss: 4.1927 - f1_score: 0.0802 - val_loss: 4.0865 - val_f1_score: 0.0682 - lr: 0.0200\n",
      "Epoch 6/30\n",
      "15287/15287 [==============================] - 2812s 184ms/step - loss: 4.1913 - f1_score: 0.0794 - val_loss: 4.1428 - val_f1_score: 0.0020 - lr: 0.0200\n",
      "Epoch 7/30\n",
      "15287/15287 [==============================] - 2804s 183ms/step - loss: 4.1939 - f1_score: 0.0793 - val_loss: 4.1104 - val_f1_score: 0.0682 - lr: 0.0200\n",
      "Epoch 8/30\n",
      " 3559/15287 [=====>........................] - ETA: 34:41 - loss: 4.2047 - f1_score: 0.0712"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [23]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_ds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mEPOCHS\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43mcallback\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_ds\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m)\u001B[49m\n\u001B[0;32m      8\u001B[0m acc \u001B[38;5;241m=\u001B[39m history\u001B[38;5;241m.\u001B[39mhistory[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mf1_score\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m      9\u001B[0m val_acc \u001B[38;5;241m=\u001B[39m history\u001B[38;5;241m.\u001B[39mhistory[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval_f1_score\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "File \u001B[1;32mc:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     62\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     63\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 64\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     65\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[0;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32mc:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\keras\\engine\\training.py:1216\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1209\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[0;32m   1210\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m   1211\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[0;32m   1212\u001B[0m     step_num\u001B[38;5;241m=\u001B[39mstep,\n\u001B[0;32m   1213\u001B[0m     batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[0;32m   1214\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m   1215\u001B[0m   callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[1;32m-> 1216\u001B[0m   tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1217\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[0;32m   1218\u001B[0m     context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[1;32mc:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32mc:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:910\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    907\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    909\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[1;32m--> 910\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    912\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[0;32m    913\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[1;32mc:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:942\u001B[0m, in \u001B[0;36mFunction._call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    939\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[0;32m    940\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[0;32m    941\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[1;32m--> 942\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_stateless_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# pylint: disable=not-callable\u001B[39;00m\n\u001B[0;32m    943\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateful_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    944\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[0;32m    945\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[0;32m    946\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[1;32mc:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3130\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   3127\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m   3128\u001B[0m   (graph_function,\n\u001B[0;32m   3129\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[1;32m-> 3130\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   3131\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mc:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1959\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1955\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[0;32m   1956\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[0;32m   1957\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[0;32m   1958\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[1;32m-> 1959\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1960\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcancellation_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcancellation_manager\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m   1961\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[0;32m   1962\u001B[0m     args,\n\u001B[0;32m   1963\u001B[0m     possible_gradient_type,\n\u001B[0;32m   1964\u001B[0m     executing_eagerly)\n\u001B[0;32m   1965\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[1;32mc:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:598\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    596\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _InterpolateFunctionError(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    597\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m cancellation_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 598\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    599\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    600\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_num_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    601\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    602\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    603\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    604\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    605\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[0;32m    606\u001B[0m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msignature\u001B[38;5;241m.\u001B[39mname),\n\u001B[0;32m    607\u001B[0m         num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_outputs,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    610\u001B[0m         ctx\u001B[38;5;241m=\u001B[39mctx,\n\u001B[0;32m    611\u001B[0m         cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_manager)\n",
      "File \u001B[1;32mc:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:58\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     56\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     57\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 58\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     59\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     60\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     61\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks= [callback],\n",
    "    validation_data =val_ds\n",
    ")\n",
    "\n",
    "acc = history.history['f1_score']\n",
    "val_acc = history.history['val_f1_score']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.plot(acc, label='Training Weighted-F1')\n",
    "plt.plot(val_acc, label='Validation Weighted-F1')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title(\"Training and Validation Weighted-F1\")\n",
    "plt.show()\n",
    "# 1epoch 내내 8프로여도 설계한대로 여서 30epoch에 0.85까지 달성한다는 그런 이유와 계획을 봐야할듯\n",
    "\n",
    "\"\"\"\n",
    "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
    "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
    "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
    "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
    "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
    "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
    "15287/15287 [==============================] - ETA: 0s - loss: 3.9956 - f1_score: 0.0804WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
    "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
    "15287/15287 [==============================] - 2651s 172ms/step - loss: 3.9956 - f1_score: 0.0804 - val_loss: 3.9584 - val_f1_score: 0.0682 - lr: 0.0020\n",
    "Epoch 2/30\n",
    " 1867/15287 [==>...........................] - ETA: 36:53 - loss: 3.9015 - f1_score: 0.0788\n",
    "\n",
    " 이것도 이런식의 정확도인데 ..\n",
    "\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.load_weights(checkpoint_path)\n",
    "val_weighted_f1 = model.evaluate(val_ds)[1]\n",
    "print(f\"val_weighted_f1: {val_weighted_f1}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inference"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_ds = DataGenerator(\n",
    "    X_test_txt.values,None,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    include_targets=False\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred_prob =[]\n",
    "\n",
    "for i in range(test_ds.__len__()):\n",
    "    pred_prob.append(model.predict(test_ds.__getitem__(i)))\n",
    "pred_prob = np.vstack(pred_prob)\n",
    "pred = np.argmax(pred_prob, axis=1)\n",
    "\n",
    "y_decoder = {value : key for key, value in y_encoder.items()}\n",
    "result = np.array([y_decoder[v] for v in pred])\n",
    "\n",
    "\n",
    "pd.Series(result).value_counts()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"input/sample_submission.csv\")\n",
    "submission['cat3'] = result\n",
    "submission.to_csv(f'{parser.description}.csv',index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}