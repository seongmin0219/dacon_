{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "pd.set_option(\"mode.chained_assignment\", None) # <=== 경고를 끈다"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "filename= '../data/train.csv'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(filename)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "filename = '../data/test.csv'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "data_test = pd.read_csv(filename)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "filename = '../data/meta/y_feature_spec_info.csv'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "data_threshold = pd.read_csv(filename)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# y feature data의 threashold에 따른 정상 / 비정상 label 부여\n",
    "def get_label(data_df):\n",
    "  label = []\n",
    "  for i in range(data_df.shape[0]):\n",
    "    is_anomaly = False\n",
    "    for idx in range(len(data_threshold)):\n",
    "      if data_df[data_threshold[\"Feature\"].iloc[idx]].iloc[i] < data_threshold[\"최소\"].iloc[idx]:\n",
    "        is_anomaly = True\n",
    "        break\n",
    "      elif data_df[data_threshold[\"Feature\"].iloc[idx]].iloc[i] > data_threshold[\"최대\"].iloc[idx]:\n",
    "        is_anomaly = True\n",
    "        break\n",
    "    if is_anomaly:\n",
    "      label.append(1)\n",
    "    else:\n",
    "      label.append(0)\n",
    "  return label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "   Feature    최소    최대\n0     Y_01   0.2   2.0\n1     Y_02   0.2   2.1\n2     Y_03   0.2   2.1\n3     Y_04   7.0  19.0\n4     Y_05  22.0  36.5\n5     Y_06 -19.2  19.0\n6     Y_07   2.4   4.0\n7     Y_08 -29.2 -24.0\n8     Y_09 -29.2 -24.0\n9     Y_10 -30.6 -20.0\n10    Y_11  19.6  26.6\n11    Y_12 -29.2 -24.0\n12    Y_13 -29.2 -24.0\n13    Y_14 -29.2 -24.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Feature</th>\n      <th>최소</th>\n      <th>최대</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Y_01</td>\n      <td>0.2</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Y_02</td>\n      <td>0.2</td>\n      <td>2.1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Y_03</td>\n      <td>0.2</td>\n      <td>2.1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Y_04</td>\n      <td>7.0</td>\n      <td>19.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Y_05</td>\n      <td>22.0</td>\n      <td>36.5</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Y_06</td>\n      <td>-19.2</td>\n      <td>19.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Y_07</td>\n      <td>2.4</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Y_08</td>\n      <td>-29.2</td>\n      <td>-24.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Y_09</td>\n      <td>-29.2</td>\n      <td>-24.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Y_10</td>\n      <td>-30.6</td>\n      <td>-20.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Y_11</td>\n      <td>19.6</td>\n      <td>26.6</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Y_12</td>\n      <td>-29.2</td>\n      <td>-24.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Y_13</td>\n      <td>-29.2</td>\n      <td>-24.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Y_14</td>\n      <td>-29.2</td>\n      <td>-24.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 최소 최대 값으로 이상치 부여\n",
    "data_threshold"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "  Feature    최소    최대\n0    Y_01   0.2   2.0\n1    Y_02   0.2   2.1\n2    Y_03   0.2   2.1\n3    Y_04   7.0  19.0\n4    Y_05  22.0  36.5",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Feature</th>\n      <th>최소</th>\n      <th>최대</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Y_01</td>\n      <td>0.2</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Y_02</td>\n      <td>0.2</td>\n      <td>2.1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Y_03</td>\n      <td>0.2</td>\n      <td>2.1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Y_04</td>\n      <td>7.0</td>\n      <td>19.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Y_05</td>\n      <td>22.0</td>\n      <td>36.5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_threshold.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "                ID    X_01     X_02   X_03  X_04     X_05    X_06   X_07  \\\n0      TRAIN_00001  70.544  103.320  67.47     1  101.892  74.983  29.45   \n1      TRAIN_00002  69.524  103.321  65.17     1  101.944  72.943  28.73   \n2      TRAIN_00003  72.583  103.320  64.07     1  103.153  72.943  28.81   \n3      TRAIN_00004  71.563  103.320  67.57     1  101.971  77.022  28.92   \n4      TRAIN_00005  69.524  103.320  63.57     1  101.981  70.904  29.68   \n...            ...     ...      ...    ...   ...      ...     ...    ...   \n39602  TRAIN_39603  66.465  103.320  62.27     1  103.150  66.825  30.20   \n39603  TRAIN_39604  66.465  103.321  62.77     1  102.021  66.825  29.21   \n39604  TRAIN_39605  68.504  103.320  64.67     1  103.144  68.864  29.96   \n39605  TRAIN_39606  66.465  103.320  63.67     1  102.025  67.845  30.30   \n39606  TRAIN_39607  66.465  103.320  65.67     1  102.004  69.884  30.16   \n\n         X_08    X_09  ...    Y_05    Y_06   Y_07    Y_08    Y_09    Y_10  \\\n0       62.38  245.71  ...  29.632  16.083  4.276 -25.381 -25.529 -22.769   \n1       61.23  233.61  ...  33.179  16.736  3.229 -26.619 -26.523 -22.574   \n2      105.77  272.20  ...  31.801  17.080  2.839 -26.238 -26.216 -22.169   \n3      115.21  255.36  ...  34.503  17.143  3.144 -25.426 -25.079 -21.765   \n4      103.38  241.46  ...  32.602  17.569  3.138 -25.376 -25.242 -21.072   \n...       ...     ...  ...     ...     ...    ...     ...     ...     ...   \n39602   77.83  298.05  ...  29.194  16.582  3.410 -26.486 -26.581 -22.772   \n39603  102.25  270.67  ...  29.859  15.659  3.406 -27.308 -27.203 -24.674   \n39604  102.61  198.07  ...  24.720  16.823  3.215 -26.502 -26.687 -22.577   \n39605  112.60  275.52  ...  26.412  15.757  4.216 -26.760 -26.634 -24.066   \n39606  112.90  276.06  ...  30.745  16.781  3.307 -26.054 -26.251 -23.257   \n\n         Y_11    Y_12    Y_13    Y_14  \n0      23.792 -25.470 -25.409 -25.304  \n1      24.691 -26.253 -26.497 -26.438  \n2      24.649 -26.285 -26.215 -26.370  \n3      24.913 -25.254 -25.021 -25.345  \n4      25.299 -25.072 -25.195 -24.974  \n...       ...     ...     ...     ...  \n39602  24.261 -26.491 -26.584 -26.580  \n39603  23.427 -27.250 -27.334 -27.325  \n39604  24.301 -26.388 -26.425 -26.601  \n39605  23.305 -26.536 -26.751 -26.635  \n39606  24.450 -26.224 -26.256 -26.093  \n\n[39607 rows x 71 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>X_01</th>\n      <th>X_02</th>\n      <th>X_03</th>\n      <th>X_04</th>\n      <th>X_05</th>\n      <th>X_06</th>\n      <th>X_07</th>\n      <th>X_08</th>\n      <th>X_09</th>\n      <th>...</th>\n      <th>Y_05</th>\n      <th>Y_06</th>\n      <th>Y_07</th>\n      <th>Y_08</th>\n      <th>Y_09</th>\n      <th>Y_10</th>\n      <th>Y_11</th>\n      <th>Y_12</th>\n      <th>Y_13</th>\n      <th>Y_14</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>TRAIN_00001</td>\n      <td>70.544</td>\n      <td>103.320</td>\n      <td>67.47</td>\n      <td>1</td>\n      <td>101.892</td>\n      <td>74.983</td>\n      <td>29.45</td>\n      <td>62.38</td>\n      <td>245.71</td>\n      <td>...</td>\n      <td>29.632</td>\n      <td>16.083</td>\n      <td>4.276</td>\n      <td>-25.381</td>\n      <td>-25.529</td>\n      <td>-22.769</td>\n      <td>23.792</td>\n      <td>-25.470</td>\n      <td>-25.409</td>\n      <td>-25.304</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>TRAIN_00002</td>\n      <td>69.524</td>\n      <td>103.321</td>\n      <td>65.17</td>\n      <td>1</td>\n      <td>101.944</td>\n      <td>72.943</td>\n      <td>28.73</td>\n      <td>61.23</td>\n      <td>233.61</td>\n      <td>...</td>\n      <td>33.179</td>\n      <td>16.736</td>\n      <td>3.229</td>\n      <td>-26.619</td>\n      <td>-26.523</td>\n      <td>-22.574</td>\n      <td>24.691</td>\n      <td>-26.253</td>\n      <td>-26.497</td>\n      <td>-26.438</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>TRAIN_00003</td>\n      <td>72.583</td>\n      <td>103.320</td>\n      <td>64.07</td>\n      <td>1</td>\n      <td>103.153</td>\n      <td>72.943</td>\n      <td>28.81</td>\n      <td>105.77</td>\n      <td>272.20</td>\n      <td>...</td>\n      <td>31.801</td>\n      <td>17.080</td>\n      <td>2.839</td>\n      <td>-26.238</td>\n      <td>-26.216</td>\n      <td>-22.169</td>\n      <td>24.649</td>\n      <td>-26.285</td>\n      <td>-26.215</td>\n      <td>-26.370</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>TRAIN_00004</td>\n      <td>71.563</td>\n      <td>103.320</td>\n      <td>67.57</td>\n      <td>1</td>\n      <td>101.971</td>\n      <td>77.022</td>\n      <td>28.92</td>\n      <td>115.21</td>\n      <td>255.36</td>\n      <td>...</td>\n      <td>34.503</td>\n      <td>17.143</td>\n      <td>3.144</td>\n      <td>-25.426</td>\n      <td>-25.079</td>\n      <td>-21.765</td>\n      <td>24.913</td>\n      <td>-25.254</td>\n      <td>-25.021</td>\n      <td>-25.345</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>TRAIN_00005</td>\n      <td>69.524</td>\n      <td>103.320</td>\n      <td>63.57</td>\n      <td>1</td>\n      <td>101.981</td>\n      <td>70.904</td>\n      <td>29.68</td>\n      <td>103.38</td>\n      <td>241.46</td>\n      <td>...</td>\n      <td>32.602</td>\n      <td>17.569</td>\n      <td>3.138</td>\n      <td>-25.376</td>\n      <td>-25.242</td>\n      <td>-21.072</td>\n      <td>25.299</td>\n      <td>-25.072</td>\n      <td>-25.195</td>\n      <td>-24.974</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>39602</th>\n      <td>TRAIN_39603</td>\n      <td>66.465</td>\n      <td>103.320</td>\n      <td>62.27</td>\n      <td>1</td>\n      <td>103.150</td>\n      <td>66.825</td>\n      <td>30.20</td>\n      <td>77.83</td>\n      <td>298.05</td>\n      <td>...</td>\n      <td>29.194</td>\n      <td>16.582</td>\n      <td>3.410</td>\n      <td>-26.486</td>\n      <td>-26.581</td>\n      <td>-22.772</td>\n      <td>24.261</td>\n      <td>-26.491</td>\n      <td>-26.584</td>\n      <td>-26.580</td>\n    </tr>\n    <tr>\n      <th>39603</th>\n      <td>TRAIN_39604</td>\n      <td>66.465</td>\n      <td>103.321</td>\n      <td>62.77</td>\n      <td>1</td>\n      <td>102.021</td>\n      <td>66.825</td>\n      <td>29.21</td>\n      <td>102.25</td>\n      <td>270.67</td>\n      <td>...</td>\n      <td>29.859</td>\n      <td>15.659</td>\n      <td>3.406</td>\n      <td>-27.308</td>\n      <td>-27.203</td>\n      <td>-24.674</td>\n      <td>23.427</td>\n      <td>-27.250</td>\n      <td>-27.334</td>\n      <td>-27.325</td>\n    </tr>\n    <tr>\n      <th>39604</th>\n      <td>TRAIN_39605</td>\n      <td>68.504</td>\n      <td>103.320</td>\n      <td>64.67</td>\n      <td>1</td>\n      <td>103.144</td>\n      <td>68.864</td>\n      <td>29.96</td>\n      <td>102.61</td>\n      <td>198.07</td>\n      <td>...</td>\n      <td>24.720</td>\n      <td>16.823</td>\n      <td>3.215</td>\n      <td>-26.502</td>\n      <td>-26.687</td>\n      <td>-22.577</td>\n      <td>24.301</td>\n      <td>-26.388</td>\n      <td>-26.425</td>\n      <td>-26.601</td>\n    </tr>\n    <tr>\n      <th>39605</th>\n      <td>TRAIN_39606</td>\n      <td>66.465</td>\n      <td>103.320</td>\n      <td>63.67</td>\n      <td>1</td>\n      <td>102.025</td>\n      <td>67.845</td>\n      <td>30.30</td>\n      <td>112.60</td>\n      <td>275.52</td>\n      <td>...</td>\n      <td>26.412</td>\n      <td>15.757</td>\n      <td>4.216</td>\n      <td>-26.760</td>\n      <td>-26.634</td>\n      <td>-24.066</td>\n      <td>23.305</td>\n      <td>-26.536</td>\n      <td>-26.751</td>\n      <td>-26.635</td>\n    </tr>\n    <tr>\n      <th>39606</th>\n      <td>TRAIN_39607</td>\n      <td>66.465</td>\n      <td>103.320</td>\n      <td>65.67</td>\n      <td>1</td>\n      <td>102.004</td>\n      <td>69.884</td>\n      <td>30.16</td>\n      <td>112.90</td>\n      <td>276.06</td>\n      <td>...</td>\n      <td>30.745</td>\n      <td>16.781</td>\n      <td>3.307</td>\n      <td>-26.054</td>\n      <td>-26.251</td>\n      <td>-23.257</td>\n      <td>24.450</td>\n      <td>-26.224</td>\n      <td>-26.256</td>\n      <td>-26.093</td>\n    </tr>\n  </tbody>\n</table>\n<p>39607 rows × 71 columns</p>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "data_train[\"label\"] = get_label(data_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "            ID    X_01     X_02   X_03  X_04     X_05    X_06   X_07    X_08  \\\n0  TRAIN_00001  70.544  103.320  67.47     1  101.892  74.983  29.45   62.38   \n1  TRAIN_00002  69.524  103.321  65.17     1  101.944  72.943  28.73   61.23   \n2  TRAIN_00003  72.583  103.320  64.07     1  103.153  72.943  28.81  105.77   \n3  TRAIN_00004  71.563  103.320  67.57     1  101.971  77.022  28.92  115.21   \n4  TRAIN_00005  69.524  103.320  63.57     1  101.981  70.904  29.68  103.38   \n\n     X_09  ...    Y_06   Y_07    Y_08    Y_09    Y_10    Y_11    Y_12    Y_13  \\\n0  245.71  ...  16.083  4.276 -25.381 -25.529 -22.769  23.792 -25.470 -25.409   \n1  233.61  ...  16.736  3.229 -26.619 -26.523 -22.574  24.691 -26.253 -26.497   \n2  272.20  ...  17.080  2.839 -26.238 -26.216 -22.169  24.649 -26.285 -26.215   \n3  255.36  ...  17.143  3.144 -25.426 -25.079 -21.765  24.913 -25.254 -25.021   \n4  241.46  ...  17.569  3.138 -25.376 -25.242 -21.072  25.299 -25.072 -25.195   \n\n     Y_14  label  \n0 -25.304      1  \n1 -26.438      0  \n2 -26.370      0  \n3 -25.345      0  \n4 -24.974      0  \n\n[5 rows x 72 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>X_01</th>\n      <th>X_02</th>\n      <th>X_03</th>\n      <th>X_04</th>\n      <th>X_05</th>\n      <th>X_06</th>\n      <th>X_07</th>\n      <th>X_08</th>\n      <th>X_09</th>\n      <th>...</th>\n      <th>Y_06</th>\n      <th>Y_07</th>\n      <th>Y_08</th>\n      <th>Y_09</th>\n      <th>Y_10</th>\n      <th>Y_11</th>\n      <th>Y_12</th>\n      <th>Y_13</th>\n      <th>Y_14</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>TRAIN_00001</td>\n      <td>70.544</td>\n      <td>103.320</td>\n      <td>67.47</td>\n      <td>1</td>\n      <td>101.892</td>\n      <td>74.983</td>\n      <td>29.45</td>\n      <td>62.38</td>\n      <td>245.71</td>\n      <td>...</td>\n      <td>16.083</td>\n      <td>4.276</td>\n      <td>-25.381</td>\n      <td>-25.529</td>\n      <td>-22.769</td>\n      <td>23.792</td>\n      <td>-25.470</td>\n      <td>-25.409</td>\n      <td>-25.304</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>TRAIN_00002</td>\n      <td>69.524</td>\n      <td>103.321</td>\n      <td>65.17</td>\n      <td>1</td>\n      <td>101.944</td>\n      <td>72.943</td>\n      <td>28.73</td>\n      <td>61.23</td>\n      <td>233.61</td>\n      <td>...</td>\n      <td>16.736</td>\n      <td>3.229</td>\n      <td>-26.619</td>\n      <td>-26.523</td>\n      <td>-22.574</td>\n      <td>24.691</td>\n      <td>-26.253</td>\n      <td>-26.497</td>\n      <td>-26.438</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>TRAIN_00003</td>\n      <td>72.583</td>\n      <td>103.320</td>\n      <td>64.07</td>\n      <td>1</td>\n      <td>103.153</td>\n      <td>72.943</td>\n      <td>28.81</td>\n      <td>105.77</td>\n      <td>272.20</td>\n      <td>...</td>\n      <td>17.080</td>\n      <td>2.839</td>\n      <td>-26.238</td>\n      <td>-26.216</td>\n      <td>-22.169</td>\n      <td>24.649</td>\n      <td>-26.285</td>\n      <td>-26.215</td>\n      <td>-26.370</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>TRAIN_00004</td>\n      <td>71.563</td>\n      <td>103.320</td>\n      <td>67.57</td>\n      <td>1</td>\n      <td>101.971</td>\n      <td>77.022</td>\n      <td>28.92</td>\n      <td>115.21</td>\n      <td>255.36</td>\n      <td>...</td>\n      <td>17.143</td>\n      <td>3.144</td>\n      <td>-25.426</td>\n      <td>-25.079</td>\n      <td>-21.765</td>\n      <td>24.913</td>\n      <td>-25.254</td>\n      <td>-25.021</td>\n      <td>-25.345</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>TRAIN_00005</td>\n      <td>69.524</td>\n      <td>103.320</td>\n      <td>63.57</td>\n      <td>1</td>\n      <td>101.981</td>\n      <td>70.904</td>\n      <td>29.68</td>\n      <td>103.38</td>\n      <td>241.46</td>\n      <td>...</td>\n      <td>17.569</td>\n      <td>3.138</td>\n      <td>-25.376</td>\n      <td>-25.242</td>\n      <td>-21.072</td>\n      <td>25.299</td>\n      <td>-25.072</td>\n      <td>-25.195</td>\n      <td>-24.974</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 72 columns</p>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "           ID    X_01     X_02   X_03  X_04     X_05    X_06   X_07    X_08  \\\n0  TEST_00001  68.504  103.321  76.67     1  101.867  73.963  30.51   63.57   \n1  TEST_00002  67.485  103.320  69.37     1  101.992  67.845  28.03  116.99   \n2  TEST_00003  69.524  103.320  68.97     1  101.884  77.022  29.65  205.68   \n3  TEST_00004  69.524  103.320  65.87     1  101.866  73.963  28.15  103.38   \n4  TEST_00005  73.603  103.321  66.67     1  101.891  74.983  29.92   71.20   \n\n     X_09  ...  X_47  X_48      X_49        X_50        X_51        X_52  \\\n0  239.80  ...     1     1  17227.63  138.130429  129.460682  141.506570   \n1  189.23  ...     1     1  17134.53  136.148839  128.266277  145.911745   \n2  214.93  ...     1     1  14860.83  120.447446  119.988804  132.099908   \n3  180.80  ...     1     1  15252.53  133.994695  125.069180  147.507669   \n4  231.93  ...     1     1  10752.23  137.918202  135.116192  138.600473   \n\n         X_53        X_54        X_55        X_56  \n0  133.427229  129.711498  133.138096  121.859684  \n1  131.196417  132.411480  133.629025  124.178623  \n2  120.450155  130.051708  128.252972  114.475628  \n3  123.142653  125.963665  139.666592  126.589253  \n4  127.173033  137.252712  134.411335  124.020016  \n\n[5 rows x 57 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>X_01</th>\n      <th>X_02</th>\n      <th>X_03</th>\n      <th>X_04</th>\n      <th>X_05</th>\n      <th>X_06</th>\n      <th>X_07</th>\n      <th>X_08</th>\n      <th>X_09</th>\n      <th>...</th>\n      <th>X_47</th>\n      <th>X_48</th>\n      <th>X_49</th>\n      <th>X_50</th>\n      <th>X_51</th>\n      <th>X_52</th>\n      <th>X_53</th>\n      <th>X_54</th>\n      <th>X_55</th>\n      <th>X_56</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>TEST_00001</td>\n      <td>68.504</td>\n      <td>103.321</td>\n      <td>76.67</td>\n      <td>1</td>\n      <td>101.867</td>\n      <td>73.963</td>\n      <td>30.51</td>\n      <td>63.57</td>\n      <td>239.80</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>17227.63</td>\n      <td>138.130429</td>\n      <td>129.460682</td>\n      <td>141.506570</td>\n      <td>133.427229</td>\n      <td>129.711498</td>\n      <td>133.138096</td>\n      <td>121.859684</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>TEST_00002</td>\n      <td>67.485</td>\n      <td>103.320</td>\n      <td>69.37</td>\n      <td>1</td>\n      <td>101.992</td>\n      <td>67.845</td>\n      <td>28.03</td>\n      <td>116.99</td>\n      <td>189.23</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>17134.53</td>\n      <td>136.148839</td>\n      <td>128.266277</td>\n      <td>145.911745</td>\n      <td>131.196417</td>\n      <td>132.411480</td>\n      <td>133.629025</td>\n      <td>124.178623</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>TEST_00003</td>\n      <td>69.524</td>\n      <td>103.320</td>\n      <td>68.97</td>\n      <td>1</td>\n      <td>101.884</td>\n      <td>77.022</td>\n      <td>29.65</td>\n      <td>205.68</td>\n      <td>214.93</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>14860.83</td>\n      <td>120.447446</td>\n      <td>119.988804</td>\n      <td>132.099908</td>\n      <td>120.450155</td>\n      <td>130.051708</td>\n      <td>128.252972</td>\n      <td>114.475628</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>TEST_00004</td>\n      <td>69.524</td>\n      <td>103.320</td>\n      <td>65.87</td>\n      <td>1</td>\n      <td>101.866</td>\n      <td>73.963</td>\n      <td>28.15</td>\n      <td>103.38</td>\n      <td>180.80</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>15252.53</td>\n      <td>133.994695</td>\n      <td>125.069180</td>\n      <td>147.507669</td>\n      <td>123.142653</td>\n      <td>125.963665</td>\n      <td>139.666592</td>\n      <td>126.589253</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>TEST_00005</td>\n      <td>73.603</td>\n      <td>103.321</td>\n      <td>66.67</td>\n      <td>1</td>\n      <td>101.891</td>\n      <td>74.983</td>\n      <td>29.92</td>\n      <td>71.20</td>\n      <td>231.93</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>10752.23</td>\n      <td>137.918202</td>\n      <td>135.116192</td>\n      <td>138.600473</td>\n      <td>127.173033</td>\n      <td>137.252712</td>\n      <td>134.411335</td>\n      <td>124.020016</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 57 columns</p>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 800x800 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = [0,0]\n",
    "\n",
    "for i in range(data_train.shape[0]):\n",
    "\n",
    "  if data_train[\"label\"].iloc[i] ==0:\n",
    "    result[0] += 1\n",
    "  else:\n",
    "    result[1] +=1\n",
    "\n",
    "\n",
    "\n",
    "labels = [\"non-anomaly\", \"anomaly\"]\n",
    "\n",
    "result = np.array(result)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "fig.set_facecolor(\"white\")\n",
    "\n",
    "\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "ax.pie(x = result, labels=labels, autopct= lambda p : '{:.2f}%'.format(p))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "X_drop_list = ['ID', \"label\"]\n",
    "for i in range(1, 15):\n",
    "  i = str(i)\n",
    "  if len(i) == 1:\n",
    "    i = '0'+i\n",
    "  X_drop_list.append(\"Y_\"+i)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "['ID',\n 'label',\n 'Y_01',\n 'Y_02',\n 'Y_03',\n 'Y_04',\n 'Y_05',\n 'Y_06',\n 'Y_07',\n 'Y_08',\n 'Y_09',\n 'Y_10',\n 'Y_11',\n 'Y_12',\n 'Y_13',\n 'Y_14']"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_drop_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "\n",
    "Y_drop_list = ['ID']\n",
    "for i in range(1, 57):\n",
    "  i = str(i)\n",
    "  if len(i) == 1:\n",
    "    i = '0'+i\n",
    "  Y_drop_list.append(\"X_\"+i)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "['ID',\n 'X_01',\n 'X_02',\n 'X_03',\n 'X_04',\n 'X_05',\n 'X_06',\n 'X_07',\n 'X_08',\n 'X_09',\n 'X_10',\n 'X_11',\n 'X_12',\n 'X_13',\n 'X_14',\n 'X_15',\n 'X_16',\n 'X_17',\n 'X_18',\n 'X_19',\n 'X_20',\n 'X_21',\n 'X_22',\n 'X_23',\n 'X_24',\n 'X_25',\n 'X_26',\n 'X_27',\n 'X_28',\n 'X_29',\n 'X_30',\n 'X_31',\n 'X_32',\n 'X_33',\n 'X_34',\n 'X_35',\n 'X_36',\n 'X_37',\n 'X_38',\n 'X_39',\n 'X_40',\n 'X_41',\n 'X_42',\n 'X_43',\n 'X_44',\n 'X_45',\n 'X_46',\n 'X_47',\n 'X_48',\n 'X_49',\n 'X_50',\n 'X_51',\n 'X_52',\n 'X_53',\n 'X_54',\n 'X_55',\n 'X_56']"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_drop_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "                ID    X_01     X_02   X_03  X_04     X_05    X_06   X_07  \\\n0      TRAIN_00001  70.544  103.320  67.47     1  101.892  74.983  29.45   \n1      TRAIN_00002  69.524  103.321  65.17     1  101.944  72.943  28.73   \n2      TRAIN_00003  72.583  103.320  64.07     1  103.153  72.943  28.81   \n3      TRAIN_00004  71.563  103.320  67.57     1  101.971  77.022  28.92   \n4      TRAIN_00005  69.524  103.320  63.57     1  101.981  70.904  29.68   \n...            ...     ...      ...    ...   ...      ...     ...    ...   \n39602  TRAIN_39603  66.465  103.320  62.27     1  103.150  66.825  30.20   \n39603  TRAIN_39604  66.465  103.321  62.77     1  102.021  66.825  29.21   \n39604  TRAIN_39605  68.504  103.320  64.67     1  103.144  68.864  29.96   \n39605  TRAIN_39606  66.465  103.320  63.67     1  102.025  67.845  30.30   \n39606  TRAIN_39607  66.465  103.320  65.67     1  102.004  69.884  30.16   \n\n         X_08    X_09  ...    Y_06   Y_07    Y_08    Y_09    Y_10    Y_11  \\\n0       62.38  245.71  ...  16.083  4.276 -25.381 -25.529 -22.769  23.792   \n1       61.23  233.61  ...  16.736  3.229 -26.619 -26.523 -22.574  24.691   \n2      105.77  272.20  ...  17.080  2.839 -26.238 -26.216 -22.169  24.649   \n3      115.21  255.36  ...  17.143  3.144 -25.426 -25.079 -21.765  24.913   \n4      103.38  241.46  ...  17.569  3.138 -25.376 -25.242 -21.072  25.299   \n...       ...     ...  ...     ...    ...     ...     ...     ...     ...   \n39602   77.83  298.05  ...  16.582  3.410 -26.486 -26.581 -22.772  24.261   \n39603  102.25  270.67  ...  15.659  3.406 -27.308 -27.203 -24.674  23.427   \n39604  102.61  198.07  ...  16.823  3.215 -26.502 -26.687 -22.577  24.301   \n39605  112.60  275.52  ...  15.757  4.216 -26.760 -26.634 -24.066  23.305   \n39606  112.90  276.06  ...  16.781  3.307 -26.054 -26.251 -23.257  24.450   \n\n         Y_12    Y_13    Y_14  label  \n0     -25.470 -25.409 -25.304      1  \n1     -26.253 -26.497 -26.438      0  \n2     -26.285 -26.215 -26.370      0  \n3     -25.254 -25.021 -25.345      0  \n4     -25.072 -25.195 -24.974      0  \n...       ...     ...     ...    ...  \n39602 -26.491 -26.584 -26.580      0  \n39603 -27.250 -27.334 -27.325      0  \n39604 -26.388 -26.425 -26.601      0  \n39605 -26.536 -26.751 -26.635      1  \n39606 -26.224 -26.256 -26.093      0  \n\n[39607 rows x 72 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>X_01</th>\n      <th>X_02</th>\n      <th>X_03</th>\n      <th>X_04</th>\n      <th>X_05</th>\n      <th>X_06</th>\n      <th>X_07</th>\n      <th>X_08</th>\n      <th>X_09</th>\n      <th>...</th>\n      <th>Y_06</th>\n      <th>Y_07</th>\n      <th>Y_08</th>\n      <th>Y_09</th>\n      <th>Y_10</th>\n      <th>Y_11</th>\n      <th>Y_12</th>\n      <th>Y_13</th>\n      <th>Y_14</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>TRAIN_00001</td>\n      <td>70.544</td>\n      <td>103.320</td>\n      <td>67.47</td>\n      <td>1</td>\n      <td>101.892</td>\n      <td>74.983</td>\n      <td>29.45</td>\n      <td>62.38</td>\n      <td>245.71</td>\n      <td>...</td>\n      <td>16.083</td>\n      <td>4.276</td>\n      <td>-25.381</td>\n      <td>-25.529</td>\n      <td>-22.769</td>\n      <td>23.792</td>\n      <td>-25.470</td>\n      <td>-25.409</td>\n      <td>-25.304</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>TRAIN_00002</td>\n      <td>69.524</td>\n      <td>103.321</td>\n      <td>65.17</td>\n      <td>1</td>\n      <td>101.944</td>\n      <td>72.943</td>\n      <td>28.73</td>\n      <td>61.23</td>\n      <td>233.61</td>\n      <td>...</td>\n      <td>16.736</td>\n      <td>3.229</td>\n      <td>-26.619</td>\n      <td>-26.523</td>\n      <td>-22.574</td>\n      <td>24.691</td>\n      <td>-26.253</td>\n      <td>-26.497</td>\n      <td>-26.438</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>TRAIN_00003</td>\n      <td>72.583</td>\n      <td>103.320</td>\n      <td>64.07</td>\n      <td>1</td>\n      <td>103.153</td>\n      <td>72.943</td>\n      <td>28.81</td>\n      <td>105.77</td>\n      <td>272.20</td>\n      <td>...</td>\n      <td>17.080</td>\n      <td>2.839</td>\n      <td>-26.238</td>\n      <td>-26.216</td>\n      <td>-22.169</td>\n      <td>24.649</td>\n      <td>-26.285</td>\n      <td>-26.215</td>\n      <td>-26.370</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>TRAIN_00004</td>\n      <td>71.563</td>\n      <td>103.320</td>\n      <td>67.57</td>\n      <td>1</td>\n      <td>101.971</td>\n      <td>77.022</td>\n      <td>28.92</td>\n      <td>115.21</td>\n      <td>255.36</td>\n      <td>...</td>\n      <td>17.143</td>\n      <td>3.144</td>\n      <td>-25.426</td>\n      <td>-25.079</td>\n      <td>-21.765</td>\n      <td>24.913</td>\n      <td>-25.254</td>\n      <td>-25.021</td>\n      <td>-25.345</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>TRAIN_00005</td>\n      <td>69.524</td>\n      <td>103.320</td>\n      <td>63.57</td>\n      <td>1</td>\n      <td>101.981</td>\n      <td>70.904</td>\n      <td>29.68</td>\n      <td>103.38</td>\n      <td>241.46</td>\n      <td>...</td>\n      <td>17.569</td>\n      <td>3.138</td>\n      <td>-25.376</td>\n      <td>-25.242</td>\n      <td>-21.072</td>\n      <td>25.299</td>\n      <td>-25.072</td>\n      <td>-25.195</td>\n      <td>-24.974</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>39602</th>\n      <td>TRAIN_39603</td>\n      <td>66.465</td>\n      <td>103.320</td>\n      <td>62.27</td>\n      <td>1</td>\n      <td>103.150</td>\n      <td>66.825</td>\n      <td>30.20</td>\n      <td>77.83</td>\n      <td>298.05</td>\n      <td>...</td>\n      <td>16.582</td>\n      <td>3.410</td>\n      <td>-26.486</td>\n      <td>-26.581</td>\n      <td>-22.772</td>\n      <td>24.261</td>\n      <td>-26.491</td>\n      <td>-26.584</td>\n      <td>-26.580</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>39603</th>\n      <td>TRAIN_39604</td>\n      <td>66.465</td>\n      <td>103.321</td>\n      <td>62.77</td>\n      <td>1</td>\n      <td>102.021</td>\n      <td>66.825</td>\n      <td>29.21</td>\n      <td>102.25</td>\n      <td>270.67</td>\n      <td>...</td>\n      <td>15.659</td>\n      <td>3.406</td>\n      <td>-27.308</td>\n      <td>-27.203</td>\n      <td>-24.674</td>\n      <td>23.427</td>\n      <td>-27.250</td>\n      <td>-27.334</td>\n      <td>-27.325</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>39604</th>\n      <td>TRAIN_39605</td>\n      <td>68.504</td>\n      <td>103.320</td>\n      <td>64.67</td>\n      <td>1</td>\n      <td>103.144</td>\n      <td>68.864</td>\n      <td>29.96</td>\n      <td>102.61</td>\n      <td>198.07</td>\n      <td>...</td>\n      <td>16.823</td>\n      <td>3.215</td>\n      <td>-26.502</td>\n      <td>-26.687</td>\n      <td>-22.577</td>\n      <td>24.301</td>\n      <td>-26.388</td>\n      <td>-26.425</td>\n      <td>-26.601</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>39605</th>\n      <td>TRAIN_39606</td>\n      <td>66.465</td>\n      <td>103.320</td>\n      <td>63.67</td>\n      <td>1</td>\n      <td>102.025</td>\n      <td>67.845</td>\n      <td>30.30</td>\n      <td>112.60</td>\n      <td>275.52</td>\n      <td>...</td>\n      <td>15.757</td>\n      <td>4.216</td>\n      <td>-26.760</td>\n      <td>-26.634</td>\n      <td>-24.066</td>\n      <td>23.305</td>\n      <td>-26.536</td>\n      <td>-26.751</td>\n      <td>-26.635</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>39606</th>\n      <td>TRAIN_39607</td>\n      <td>66.465</td>\n      <td>103.320</td>\n      <td>65.67</td>\n      <td>1</td>\n      <td>102.004</td>\n      <td>69.884</td>\n      <td>30.16</td>\n      <td>112.90</td>\n      <td>276.06</td>\n      <td>...</td>\n      <td>16.781</td>\n      <td>3.307</td>\n      <td>-26.054</td>\n      <td>-26.251</td>\n      <td>-23.257</td>\n      <td>24.450</td>\n      <td>-26.224</td>\n      <td>-26.256</td>\n      <td>-26.093</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>39607 rows × 72 columns</p>\n</div>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "data_train_X = data_train.drop(X_drop_list, axis = 1)\n",
    "data_train_y = data_train.drop(Y_drop_list, axis = 1)\n",
    "data_test = data_test.drop([\"ID\"], axis = 1)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "\n",
    "# 추가 필요없는 x feature drop\n",
    "drop_list = [\"X_04\", \"X_23\", \"X_47\", \"X_48\"]\n",
    "data_train_X = data_train_X.drop(drop_list, axis = 1)\n",
    "data_test = data_test.drop(drop_list, axis = 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['X_01', 'X_02', 'X_03', 'X_05', 'X_06', 'X_07', 'X_08', 'X_09', 'X_10',\n       'X_11', 'X_12', 'X_13', 'X_14', 'X_15', 'X_16', 'X_17', 'X_18', 'X_19',\n       'X_20', 'X_21', 'X_22', 'X_24', 'X_25', 'X_26', 'X_27', 'X_28', 'X_29',\n       'X_30', 'X_31', 'X_32', 'X_33', 'X_34', 'X_35', 'X_36', 'X_37', 'X_38',\n       'X_39', 'X_40', 'X_41', 'X_42', 'X_43', 'X_44', 'X_45', 'X_46', 'X_49',\n       'X_50', 'X_51', 'X_52', 'X_53', 'X_54', 'X_55', 'X_56'],\n      dtype='object')"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_X.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "def get_values(data_df, start_val, end_val, get_std = False):\n",
    "  diff = []\n",
    "  std = []\n",
    "  for i in range(data_df.shape[0]):\n",
    "    vals = []\n",
    "    for s in range(start_val, end_val + 1):\n",
    "      vals.append(data_df[\"X_\"+str(s)].iloc[i])\n",
    "    diff.append(max(vals) - min(vals))\n",
    "    if get_std:\n",
    "      std.append(np.std(vals))\n",
    "  return diff, std"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "def get_sum_values(data_df, val_list):\n",
    "  sums = []\n",
    "  for i in range(data_df.shape[0]):\n",
    "    vals = []\n",
    "    for s in val_list:\n",
    "      vals.append(data_df[\"X_\"+str(s)].iloc[i])\n",
    "    sums.append(sum(vals))\n",
    "  return sums"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### 무게 / 면적\n",
    "data_train_X[\"X_03/X_07\"] = data_train_X[\"X_03\"] / data_train_X[\"X_07\"]\n",
    "data_test[\"X_03/X_07\"] = data_test[\"X_03\"] / data_test[\"X_07\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "### 레이돔 치수 차이 ###\n",
    "diff, std = get_values(data_train_X, 41, 44)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "39607"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(diff)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "data_train_X[\"X_41~44-diff\"] = diff"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "         X_01     X_02   X_03     X_05    X_06   X_07    X_08    X_09  X_10  \\\n0      70.544  103.320  67.47  101.892  74.983  29.45   62.38  245.71   0.0   \n1      69.524  103.321  65.17  101.944  72.943  28.73   61.23  233.61   0.0   \n2      72.583  103.320  64.07  103.153  72.943  28.81  105.77  272.20   0.0   \n3      71.563  103.320  67.57  101.971  77.022  28.92  115.21  255.36   0.0   \n4      69.524  103.320  63.57  101.981  70.904  29.68  103.38  241.46   0.0   \n...       ...      ...    ...      ...     ...    ...     ...     ...   ...   \n39602  66.465  103.320  62.27  103.150  66.825  30.20   77.83  298.05   0.0   \n39603  66.465  103.321  62.77  102.021  66.825  29.21  102.25  270.67   0.0   \n39604  68.504  103.320  64.67  103.144  68.864  29.96  102.61  198.07   0.0   \n39605  66.465  103.320  63.67  102.025  67.845  30.30  112.60  275.52   0.0   \n39606  66.465  103.320  65.67  102.004  69.884  30.16  112.90  276.06   0.0   \n\n       X_11  ...  X_46      X_49        X_50        X_51        X_52  \\\n0       0.0  ...  1463   9706.03  137.043591  135.359219  147.837968   \n1       0.0  ...  1463  10423.43  133.736691  135.979817  149.924692   \n2       0.0  ...  1468  10948.53  132.805112  131.055355  146.814592   \n3       0.0  ...  1469  15007.03  134.138760  133.239422  139.720132   \n4       0.0  ...  1469  11051.03  142.728970  136.620022  134.853555   \n...     ...  ...   ...       ...         ...         ...         ...   \n39602   0.0  ...  1469  60630.73  129.965741  130.807148  133.481737   \n39603   0.0  ...  1458  60763.43  127.633885  120.158764  142.667802   \n39604   0.0  ...  1459   8813.33  132.501286  136.893025  134.419328   \n39605   0.0  ...  1469  62222.33  128.189679  121.495930  141.288011   \n39606   0.0  ...  1462  62172.23  135.096272  122.988476  142.019357   \n\n             X_53        X_54        X_55        X_56  X_41~44-diff  \n0      134.313475  125.605427  136.721425  125.028256          0.29  \n1      123.630583  127.893337  143.322659  124.877308          0.13  \n2      128.939070  127.012195  140.395688  122.238232          0.14  \n3      132.260824  130.723186  147.624829  134.875225          0.22  \n4      134.760252  125.647793  139.331105  123.272762          0.22  \n...           ...         ...         ...         ...           ...  \n39602  125.273130  121.780933  133.780110  129.029812          0.11  \n39603  122.465490  122.987209  143.090741  122.811413          0.12  \n39604  129.115431  130.920147  140.489232  119.166699          0.13  \n39605  130.141676  125.518825  136.603634  124.525929          0.11  \n39606  123.752157  130.648365  139.695370  136.714504          0.11  \n\n[39607 rows x 53 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X_01</th>\n      <th>X_02</th>\n      <th>X_03</th>\n      <th>X_05</th>\n      <th>X_06</th>\n      <th>X_07</th>\n      <th>X_08</th>\n      <th>X_09</th>\n      <th>X_10</th>\n      <th>X_11</th>\n      <th>...</th>\n      <th>X_46</th>\n      <th>X_49</th>\n      <th>X_50</th>\n      <th>X_51</th>\n      <th>X_52</th>\n      <th>X_53</th>\n      <th>X_54</th>\n      <th>X_55</th>\n      <th>X_56</th>\n      <th>X_41~44-diff</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>70.544</td>\n      <td>103.320</td>\n      <td>67.47</td>\n      <td>101.892</td>\n      <td>74.983</td>\n      <td>29.45</td>\n      <td>62.38</td>\n      <td>245.71</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1463</td>\n      <td>9706.03</td>\n      <td>137.043591</td>\n      <td>135.359219</td>\n      <td>147.837968</td>\n      <td>134.313475</td>\n      <td>125.605427</td>\n      <td>136.721425</td>\n      <td>125.028256</td>\n      <td>0.29</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>69.524</td>\n      <td>103.321</td>\n      <td>65.17</td>\n      <td>101.944</td>\n      <td>72.943</td>\n      <td>28.73</td>\n      <td>61.23</td>\n      <td>233.61</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1463</td>\n      <td>10423.43</td>\n      <td>133.736691</td>\n      <td>135.979817</td>\n      <td>149.924692</td>\n      <td>123.630583</td>\n      <td>127.893337</td>\n      <td>143.322659</td>\n      <td>124.877308</td>\n      <td>0.13</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>72.583</td>\n      <td>103.320</td>\n      <td>64.07</td>\n      <td>103.153</td>\n      <td>72.943</td>\n      <td>28.81</td>\n      <td>105.77</td>\n      <td>272.20</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1468</td>\n      <td>10948.53</td>\n      <td>132.805112</td>\n      <td>131.055355</td>\n      <td>146.814592</td>\n      <td>128.939070</td>\n      <td>127.012195</td>\n      <td>140.395688</td>\n      <td>122.238232</td>\n      <td>0.14</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>71.563</td>\n      <td>103.320</td>\n      <td>67.57</td>\n      <td>101.971</td>\n      <td>77.022</td>\n      <td>28.92</td>\n      <td>115.21</td>\n      <td>255.36</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1469</td>\n      <td>15007.03</td>\n      <td>134.138760</td>\n      <td>133.239422</td>\n      <td>139.720132</td>\n      <td>132.260824</td>\n      <td>130.723186</td>\n      <td>147.624829</td>\n      <td>134.875225</td>\n      <td>0.22</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>69.524</td>\n      <td>103.320</td>\n      <td>63.57</td>\n      <td>101.981</td>\n      <td>70.904</td>\n      <td>29.68</td>\n      <td>103.38</td>\n      <td>241.46</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1469</td>\n      <td>11051.03</td>\n      <td>142.728970</td>\n      <td>136.620022</td>\n      <td>134.853555</td>\n      <td>134.760252</td>\n      <td>125.647793</td>\n      <td>139.331105</td>\n      <td>123.272762</td>\n      <td>0.22</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>39602</th>\n      <td>66.465</td>\n      <td>103.320</td>\n      <td>62.27</td>\n      <td>103.150</td>\n      <td>66.825</td>\n      <td>30.20</td>\n      <td>77.83</td>\n      <td>298.05</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1469</td>\n      <td>60630.73</td>\n      <td>129.965741</td>\n      <td>130.807148</td>\n      <td>133.481737</td>\n      <td>125.273130</td>\n      <td>121.780933</td>\n      <td>133.780110</td>\n      <td>129.029812</td>\n      <td>0.11</td>\n    </tr>\n    <tr>\n      <th>39603</th>\n      <td>66.465</td>\n      <td>103.321</td>\n      <td>62.77</td>\n      <td>102.021</td>\n      <td>66.825</td>\n      <td>29.21</td>\n      <td>102.25</td>\n      <td>270.67</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1458</td>\n      <td>60763.43</td>\n      <td>127.633885</td>\n      <td>120.158764</td>\n      <td>142.667802</td>\n      <td>122.465490</td>\n      <td>122.987209</td>\n      <td>143.090741</td>\n      <td>122.811413</td>\n      <td>0.12</td>\n    </tr>\n    <tr>\n      <th>39604</th>\n      <td>68.504</td>\n      <td>103.320</td>\n      <td>64.67</td>\n      <td>103.144</td>\n      <td>68.864</td>\n      <td>29.96</td>\n      <td>102.61</td>\n      <td>198.07</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1459</td>\n      <td>8813.33</td>\n      <td>132.501286</td>\n      <td>136.893025</td>\n      <td>134.419328</td>\n      <td>129.115431</td>\n      <td>130.920147</td>\n      <td>140.489232</td>\n      <td>119.166699</td>\n      <td>0.13</td>\n    </tr>\n    <tr>\n      <th>39605</th>\n      <td>66.465</td>\n      <td>103.320</td>\n      <td>63.67</td>\n      <td>102.025</td>\n      <td>67.845</td>\n      <td>30.30</td>\n      <td>112.60</td>\n      <td>275.52</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1469</td>\n      <td>62222.33</td>\n      <td>128.189679</td>\n      <td>121.495930</td>\n      <td>141.288011</td>\n      <td>130.141676</td>\n      <td>125.518825</td>\n      <td>136.603634</td>\n      <td>124.525929</td>\n      <td>0.11</td>\n    </tr>\n    <tr>\n      <th>39606</th>\n      <td>66.465</td>\n      <td>103.320</td>\n      <td>65.67</td>\n      <td>102.004</td>\n      <td>69.884</td>\n      <td>30.16</td>\n      <td>112.90</td>\n      <td>276.06</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1462</td>\n      <td>62172.23</td>\n      <td>135.096272</td>\n      <td>122.988476</td>\n      <td>142.019357</td>\n      <td>123.752157</td>\n      <td>130.648365</td>\n      <td>139.695370</td>\n      <td>136.714504</td>\n      <td>0.11</td>\n    </tr>\n  </tbody>\n</table>\n<p>39607 rows × 53 columns</p>\n</div>"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_X"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "diff, std = get_values(data_test, 41, 44)\n",
    "data_test[\"X_41~44-diff\"] = diff"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "### 1~4 단계별 누름량 합산 ###\n",
    "sums = get_sum_values(data_train_X, [\"01\", \"02\", \"05\", \"06\"])\n",
    "data_train_X[\"X_1~6_push-sum\"] = sums\n",
    "sums = get_sum_values(data_test, [\"01\", \"02\", \"05\", \"06\"])\n",
    "data_test[\"X_1~6_push-sum\"] = sums"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 그냥 이정도의 feature 만 생성하고 모델 여러개 만들어서 ensemble 해서 결과제출\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "### 방열 재료 면적 합산 ###\n",
    "sums = get_sum_values(data_train_X, [\"07\", \"08\", \"09\"])\n",
    "data_train_X[\"X_7~9_area-sum\"] = sums\n",
    "sums = get_sum_values(data_test, [\"07\", \"08\", \"09\"])\n",
    "data_test[\"X_7~9_area-sum\"] = sums\n",
    "\n",
    "### 스크류 삽입 깊이가 재질과 관련?\n",
    "data_train_X[\"X_03/X_19~22\"] = data_train_X[\"X_03\"]/(data_train_X[\"X_19\"]+data_train_X[\"X_20\"]+data_train_X[\"X_21\"]+data_train_X[\"X_22\"])\n",
    "data_test[\"X_03/X_19~22\"] = data_test[\"X_03\"]/(data_test[\"X_19\"]+data_test[\"X_20\"]+data_test[\"X_21\"]+data_test[\"X_22\"])\n",
    "\n",
    "# 커넥터 위치 좌표와 커넥터핀 치수 관계\n",
    "data_train_X[\"X_12/X_24~25\"] = data_train_X[\"X_12\"] / ((data_train_X[\"X_24\"]+data_train_X[\"X_25\"])/2)\n",
    "data_test[\"X_12/X_24~25\"] = data_test[\"X_12\"] / ((data_test[\"X_24\"]+data_test[\"X_25\"])/2)\n",
    "\n",
    "#importance 높은 데이터 조합\n",
    "data_train_X[\"49_7_19_3_8\"] = data_train_X[\"X_49\"] / data_train_X[\"X_49\"].mean()+data_train_X[\"X_07\"] / data_train_X[\"X_07\"].mean()+data_train_X[\"X_19\"] / data_train_X[\"X_19\"].mean()+data_train_X[\"X_03\"] / data_train_X[\"X_03\"].mean()\n",
    "data_test[\"49_7_19_3_8\"] = data_test[\"X_49\"] / data_train_X[\"X_49\"].mean()+data_test[\"X_07\"] / data_train_X[\"X_07\"].mean()+data_test[\"X_19\"] / data_train_X[\"X_19\"].mean()+data_test[\"X_03\"] / data_train_X[\"X_03\"].mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "    Y_01   Y_02   Y_03    Y_04    Y_05    Y_06   Y_07    Y_08    Y_09    Y_10  \\\n0  2.056  1.456  1.680  10.502  29.632  16.083  4.276 -25.381 -25.529 -22.769   \n1  1.446  1.184  1.268  18.507  33.179  16.736  3.229 -26.619 -26.523 -22.574   \n2  1.251  0.665  0.782  14.082  31.801  17.080  2.839 -26.238 -26.216 -22.169   \n3  1.464  1.079  1.052  16.975  34.503  17.143  3.144 -25.426 -25.079 -21.765   \n4  0.983  0.646  0.689  15.047  32.602  17.569  3.138 -25.376 -25.242 -21.072   \n\n     Y_11    Y_12    Y_13    Y_14  label  \n0  23.792 -25.470 -25.409 -25.304      1  \n1  24.691 -26.253 -26.497 -26.438      0  \n2  24.649 -26.285 -26.215 -26.370      0  \n3  24.913 -25.254 -25.021 -25.345      0  \n4  25.299 -25.072 -25.195 -24.974      0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Y_01</th>\n      <th>Y_02</th>\n      <th>Y_03</th>\n      <th>Y_04</th>\n      <th>Y_05</th>\n      <th>Y_06</th>\n      <th>Y_07</th>\n      <th>Y_08</th>\n      <th>Y_09</th>\n      <th>Y_10</th>\n      <th>Y_11</th>\n      <th>Y_12</th>\n      <th>Y_13</th>\n      <th>Y_14</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2.056</td>\n      <td>1.456</td>\n      <td>1.680</td>\n      <td>10.502</td>\n      <td>29.632</td>\n      <td>16.083</td>\n      <td>4.276</td>\n      <td>-25.381</td>\n      <td>-25.529</td>\n      <td>-22.769</td>\n      <td>23.792</td>\n      <td>-25.470</td>\n      <td>-25.409</td>\n      <td>-25.304</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.446</td>\n      <td>1.184</td>\n      <td>1.268</td>\n      <td>18.507</td>\n      <td>33.179</td>\n      <td>16.736</td>\n      <td>3.229</td>\n      <td>-26.619</td>\n      <td>-26.523</td>\n      <td>-22.574</td>\n      <td>24.691</td>\n      <td>-26.253</td>\n      <td>-26.497</td>\n      <td>-26.438</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.251</td>\n      <td>0.665</td>\n      <td>0.782</td>\n      <td>14.082</td>\n      <td>31.801</td>\n      <td>17.080</td>\n      <td>2.839</td>\n      <td>-26.238</td>\n      <td>-26.216</td>\n      <td>-22.169</td>\n      <td>24.649</td>\n      <td>-26.285</td>\n      <td>-26.215</td>\n      <td>-26.370</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.464</td>\n      <td>1.079</td>\n      <td>1.052</td>\n      <td>16.975</td>\n      <td>34.503</td>\n      <td>17.143</td>\n      <td>3.144</td>\n      <td>-25.426</td>\n      <td>-25.079</td>\n      <td>-21.765</td>\n      <td>24.913</td>\n      <td>-25.254</td>\n      <td>-25.021</td>\n      <td>-25.345</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.983</td>\n      <td>0.646</td>\n      <td>0.689</td>\n      <td>15.047</td>\n      <td>32.602</td>\n      <td>17.569</td>\n      <td>3.138</td>\n      <td>-25.376</td>\n      <td>-25.242</td>\n      <td>-21.072</td>\n      <td>25.299</td>\n      <td>-25.072</td>\n      <td>-25.195</td>\n      <td>-24.974</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_y.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\requests\\__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.8) or chardet (5.0.0)/charset_normalizer (2.0.11) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "# 평가산식\n",
    "def lg_nrmse(gt, preds):\n",
    "    # 각 Y Feature별 NRMSE 총합\n",
    "    # Y_01 ~ Y_08 까지 20% 가중치 부여\n",
    "    all_nrmse = []\n",
    "    for idx in range(14): # ignore 'ID'\n",
    "        rmse = mean_squared_error(gt[:,idx], preds[:,idx], squared=False)\n",
    "        nrmse = rmse/np.mean(np.abs(gt[:,idx]))\n",
    "        all_nrmse.append(nrmse)\n",
    "    score = 1.2 * np.sum(all_nrmse[:7]) + 1.0 * np.sum(all_nrmse[7:14])\n",
    "    return score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (1.0.6)\n",
      "Requirement already satisfied: scipy in c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from catboost) (1.7.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from catboost) (3.5.1)\n",
      "Requirement already satisfied: pandas>=0.24.0 in c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from catboost) (1.4.0)\n",
      "Requirement already satisfied: plotly in c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from catboost) (5.10.0)\n",
      "Requirement already satisfied: graphviz in c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from catboost) (0.20.1)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from catboost) (1.22.1)\n",
      "Requirement already satisfied: six in c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pandas>=0.24.0->catboost) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib->catboost) (9.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib->catboost) (3.0.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib->catboost) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib->catboost) (4.29.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib->catboost) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from plotly->catboost) (8.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm==2.2.3\n",
      "  Downloading lightgbm-2.2.3-py2.py3-none-win_amd64.whl (515 kB)\n",
      "     ------------------------------------- 515.9/515.9 kB 31.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy in c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from lightgbm==2.2.3) (1.7.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from lightgbm==2.2.3) (1.22.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from lightgbm==2.2.3) (1.0.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn->lightgbm==2.2.3) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn->lightgbm==2.2.3) (3.1.0)\n",
      "Installing collected packages: lightgbm\n",
      "  Attempting uninstall: lightgbm\n",
      "    Found existing installation: lightgbm 3.3.2\n",
      "    Uninstalling lightgbm-3.3.2:\n",
      "      Successfully uninstalled lightgbm-3.3.2\n",
      "Successfully installed lightgbm-2.2.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -illow (c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "#lightgbm-3.3.2\n",
    "!pip install lightgbm==2.2.3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost==1.3.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out. (read timeout=15)\")': /packages/62/ff/e0c9ffb5c46ee6166bb03b4f4eacc515d34a3aab38dec4d731a54328fc85/xgboost-1.3.2-py3-none-win_amd64.whl\n",
      "  WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out. (read timeout=15)\")': /packages/62/ff/e0c9ffb5c46ee6166bb03b4f4eacc515d34a3aab38dec4d731a54328fc85/xgboost-1.3.2-py3-none-win_amd64.whl\n",
      "  WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out. (read timeout=15)\")': /packages/62/ff/e0c9ffb5c46ee6166bb03b4f4eacc515d34a3aab38dec4d731a54328fc85/xgboost-1.3.2-py3-none-win_amd64.whl\n",
      "  WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out. (read timeout=15)\")': /packages/62/ff/e0c9ffb5c46ee6166bb03b4f4eacc515d34a3aab38dec4d731a54328fc85/xgboost-1.3.2-py3-none-win_amd64.whl\n",
      "  WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out. (read timeout=15)\")': /packages/62/ff/e0c9ffb5c46ee6166bb03b4f4eacc515d34a3aab38dec4d731a54328fc85/xgboost-1.3.2-py3-none-win_amd64.whl\n",
      "ERROR: Could not install packages due to an OSError: HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Max retries exceeded with url: /packages/62/ff/e0c9ffb5c46ee6166bb03b4f4eacc515d34a3aab38dec4d731a54328fc85/xgboost-1.3.2-py3-none-win_amd64.whl (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out. (read timeout=15)\"))\n",
      "\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost==1.2\n",
      "  Downloading xgboost-1.2.0-py3-none-win_amd64.whl (86.5 MB)\n",
      "     --------------------------------------- 86.5/86.5 MB 31.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from xgboost==1.2) (1.22.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from xgboost==1.2) (1.7.3)\n",
      "Installing collected packages: xgboost\n",
      "  Attempting uninstall: xgboost\n",
      "    Found existing installation: xgboost 0.90\n",
      "    Uninstalling xgboost-0.90:\n",
      "      Successfully uninstalled xgboost-0.90\n",
      "Successfully installed xgboost-1.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -illow (c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "#origin xgboost 1.3.2\n",
    "!pip install xgboost==0.9.0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# https://koreapy.tistory.com/941\n",
    "# multioutputregressor 에 특정 알고리즘을 넣고 그리드서치하는법까지\n",
    "from sklearn.utils.validation import _check_fit_params\n",
    "from sklearn.base import is_classifier\n",
    "from sklearn.utils.fixes import delayed\n",
    "from joblib import Parallel\n",
    "from sklearn.multioutput import _fit_estimator\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import lightgbm\n",
    "\n",
    "class MyMultiOutputRegressor_LGBM(MultiOutputRegressor):\n",
    "\n",
    "    def fit(self, X, y, sample_weight=None, **fit_params):\n",
    "        \"\"\" Fit the model to data.\n",
    "        Fit a separate model for each output variable.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
    "            Data.\n",
    "        y : {array-like, sparse matrix} of shape (n_samples, n_outputs)\n",
    "            Multi-output targets. An indicator matrix turns on multilabel\n",
    "            estimation.\n",
    "        sample_weight : array-like of shape (n_samples,), default=None\n",
    "            Sample weights. If None, then samples are equally weighted.\n",
    "            Only supported if the underlying regressor supports sample\n",
    "            weights.\n",
    "        **fit_params : dict of string -> object\n",
    "            Parameters passed to the ``estimator.fit`` method of each step.\n",
    "            .. versionadded:: 0.23\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "        \"\"\"\n",
    "\n",
    "        if not hasattr(self.estimator, \"fit\"):\n",
    "            raise ValueError(\"The base estimator should implement\"\n",
    "                             \" a fit method\")\n",
    "\n",
    "        X, y = self._validate_data(X, y,\n",
    "                                   force_all_finite=False,\n",
    "                                   multi_output=True, accept_sparse=True)\n",
    "\n",
    "        if is_classifier(self):\n",
    "            check_classification_targets(y)\n",
    "\n",
    "        if y.ndim == 1:\n",
    "            raise ValueError(\"y must have at least two dimensions for \"\n",
    "                             \"multi-output regression but has only one.\")\n",
    "\n",
    "        if (sample_weight is not None and\n",
    "                not has_fit_parameter(self.estimator, 'sample_weight')):\n",
    "            raise ValueError(\"Underlying estimator does not support\"\n",
    "                             \" sample weights.\")\n",
    "\n",
    "        lambda_y = lambda i: '0'+str(i+1) if i<9 else str(i+1)\n",
    "\n",
    "        fit_params_validated = _check_fit_params(X, fit_params)\n",
    "        [(X_test, Y_test)] = fit_params_validated.pop('eval_set')\n",
    "        self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n",
    "            delayed(_fit_estimator)(\n",
    "                self.estimator, X, y[:, i], sample_weight,\n",
    "                **fit_params_validated,\n",
    "                eval_set=[(X_test, Y_test[:, i])],\n",
    "                eval_names=\"Y_\" + lambda_y(i),\n",
    "                verbose=-1,\n",
    "                callbacks=[lightgbm.early_stopping(200)])\n",
    "            for i in range(y.shape[1]))\n",
    "        return self\n",
    "\n",
    "    # model save\n",
    "    def save(self, path):\n",
    "        for chain_idx, estimator in enumerate(self.estimators_):\n",
    "            save_path = '{}_{}.txt'.format(path, chain_idx)\n",
    "            estimator.booster_.save_model(save_path)\n",
    "\n",
    "    # model load\n",
    "    def load(self, path):\n",
    "        for chain_idx, estimator in enumerate(self.estimators_):\n",
    "            save_path = '{}_{}.txt'.format(path, chain_idx)\n",
    "            self.estimators_[chain_idx] = lightgbm.Booster(save_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.utils.validation import _check_fit_params\n",
    "from sklearn.base import is_classifier\n",
    "from sklearn.utils.fixes import delayed\n",
    "from joblib import Parallel\n",
    "from sklearn.multioutput import _fit_estimator\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import xgboost\n",
    "import pickle\n",
    "\n",
    "class MyMultiOutputRegressor_XGB(MultiOutputRegressor):\n",
    "\n",
    "    def fit(self, X, y, sample_weight=None, **fit_params):\n",
    "        \"\"\" Fit the model to data.\n",
    "        Fit a separate model for each output variable.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
    "            Data.\n",
    "        y : {array-like, sparse matrix} of shape (n_samples, n_outputs)\n",
    "            Multi-output targets. An indicator matrix turns on multilabel\n",
    "            estimation.\n",
    "        sample_weight : array-like of shape (n_samples,), default=None\n",
    "            Sample weights. If None, then samples are equally weighted.\n",
    "            Only supported if the underlying regressor supports sample\n",
    "            weights.\n",
    "        **fit_params : dict of string -> object\n",
    "            Parameters passed to the ``estimator.fit`` method of each step.\n",
    "            .. versionadded:: 0.23\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "        \"\"\"\n",
    "\n",
    "        if not hasattr(self.estimator, \"fit\"):\n",
    "            raise ValueError(\"The base estimator should implement\"\n",
    "                             \" a fit method\")\n",
    "\n",
    "        X, y = self._validate_data(X, y,\n",
    "                                   force_all_finite=False,\n",
    "                                   multi_output=True, accept_sparse=True)\n",
    "\n",
    "        if is_classifier(self):\n",
    "            check_classification_targets(y)\n",
    "\n",
    "        if y.ndim == 1:\n",
    "            raise ValueError(\"y must have at least two dimensions for \"\n",
    "                             \"multi-output regression but has only one.\")\n",
    "\n",
    "        if (sample_weight is not None and\n",
    "                not has_fit_parameter(self.estimator, 'sample_weight')):\n",
    "            raise ValueError(\"Underlying estimator does not support\"\n",
    "                             \" sample weights.\")\n",
    "\n",
    "        fit_params_validated = _check_fit_params(X, fit_params)\n",
    "        [(X_test, Y_test)] = fit_params_validated.pop('eval_set')\n",
    "        self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n",
    "            delayed(_fit_estimator)(\n",
    "                self.estimator, X, y[:, i],\n",
    "                eval_set=[(X_test, Y_test[:, i])],\n",
    "                early_stopping_rounds=100,\n",
    "                #eval_metric = [\"rmse\"],\n",
    "                verbose=3000)\n",
    "\n",
    "            for i in range(y.shape[1]))\n",
    "        return self\n",
    "\n",
    "    # model save\n",
    "    def save(self, path):\n",
    "        for chain_idx, estimator in enumerate(self.estimators_):\n",
    "            save_path = '{}_{}.dat'.format(path, chain_idx)\n",
    "            pickle.dump(estimator, open(save_path, \"wb\"))\n",
    "\n",
    "    # model load\n",
    "    def load(self, path):\n",
    "        for chain_idx, estimator in enumerate(self.estimators_):\n",
    "            save_path = '{}_{}.dat'.format(path, chain_idx)\n",
    "            model = pickle.load(open(save_path, \"rb\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}