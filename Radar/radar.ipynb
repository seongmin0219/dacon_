{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "train =  pd.read_csv(\"./data/train.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "                ID    X_01     X_02   X_03  X_04     X_05    X_06   X_07  \\\n0      TRAIN_00001  70.544  103.320  67.47     1  101.892  74.983  29.45   \n1      TRAIN_00002  69.524  103.321  65.17     1  101.944  72.943  28.73   \n2      TRAIN_00003  72.583  103.320  64.07     1  103.153  72.943  28.81   \n3      TRAIN_00004  71.563  103.320  67.57     1  101.971  77.022  28.92   \n4      TRAIN_00005  69.524  103.320  63.57     1  101.981  70.904  29.68   \n...            ...     ...      ...    ...   ...      ...     ...    ...   \n39602  TRAIN_39603  66.465  103.320  62.27     1  103.150  66.825  30.20   \n39603  TRAIN_39604  66.465  103.321  62.77     1  102.021  66.825  29.21   \n39604  TRAIN_39605  68.504  103.320  64.67     1  103.144  68.864  29.96   \n39605  TRAIN_39606  66.465  103.320  63.67     1  102.025  67.845  30.30   \n39606  TRAIN_39607  66.465  103.320  65.67     1  102.004  69.884  30.16   \n\n         X_08    X_09  ...    Y_05    Y_06   Y_07    Y_08    Y_09    Y_10  \\\n0       62.38  245.71  ...  29.632  16.083  4.276 -25.381 -25.529 -22.769   \n1       61.23  233.61  ...  33.179  16.736  3.229 -26.619 -26.523 -22.574   \n2      105.77  272.20  ...  31.801  17.080  2.839 -26.238 -26.216 -22.169   \n3      115.21  255.36  ...  34.503  17.143  3.144 -25.426 -25.079 -21.765   \n4      103.38  241.46  ...  32.602  17.569  3.138 -25.376 -25.242 -21.072   \n...       ...     ...  ...     ...     ...    ...     ...     ...     ...   \n39602   77.83  298.05  ...  29.194  16.582  3.410 -26.486 -26.581 -22.772   \n39603  102.25  270.67  ...  29.859  15.659  3.406 -27.308 -27.203 -24.674   \n39604  102.61  198.07  ...  24.720  16.823  3.215 -26.502 -26.687 -22.577   \n39605  112.60  275.52  ...  26.412  15.757  4.216 -26.760 -26.634 -24.066   \n39606  112.90  276.06  ...  30.745  16.781  3.307 -26.054 -26.251 -23.257   \n\n         Y_11    Y_12    Y_13    Y_14  \n0      23.792 -25.470 -25.409 -25.304  \n1      24.691 -26.253 -26.497 -26.438  \n2      24.649 -26.285 -26.215 -26.370  \n3      24.913 -25.254 -25.021 -25.345  \n4      25.299 -25.072 -25.195 -24.974  \n...       ...     ...     ...     ...  \n39602  24.261 -26.491 -26.584 -26.580  \n39603  23.427 -27.250 -27.334 -27.325  \n39604  24.301 -26.388 -26.425 -26.601  \n39605  23.305 -26.536 -26.751 -26.635  \n39606  24.450 -26.224 -26.256 -26.093  \n\n[39607 rows x 71 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>X_01</th>\n      <th>X_02</th>\n      <th>X_03</th>\n      <th>X_04</th>\n      <th>X_05</th>\n      <th>X_06</th>\n      <th>X_07</th>\n      <th>X_08</th>\n      <th>X_09</th>\n      <th>...</th>\n      <th>Y_05</th>\n      <th>Y_06</th>\n      <th>Y_07</th>\n      <th>Y_08</th>\n      <th>Y_09</th>\n      <th>Y_10</th>\n      <th>Y_11</th>\n      <th>Y_12</th>\n      <th>Y_13</th>\n      <th>Y_14</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>TRAIN_00001</td>\n      <td>70.544</td>\n      <td>103.320</td>\n      <td>67.47</td>\n      <td>1</td>\n      <td>101.892</td>\n      <td>74.983</td>\n      <td>29.45</td>\n      <td>62.38</td>\n      <td>245.71</td>\n      <td>...</td>\n      <td>29.632</td>\n      <td>16.083</td>\n      <td>4.276</td>\n      <td>-25.381</td>\n      <td>-25.529</td>\n      <td>-22.769</td>\n      <td>23.792</td>\n      <td>-25.470</td>\n      <td>-25.409</td>\n      <td>-25.304</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>TRAIN_00002</td>\n      <td>69.524</td>\n      <td>103.321</td>\n      <td>65.17</td>\n      <td>1</td>\n      <td>101.944</td>\n      <td>72.943</td>\n      <td>28.73</td>\n      <td>61.23</td>\n      <td>233.61</td>\n      <td>...</td>\n      <td>33.179</td>\n      <td>16.736</td>\n      <td>3.229</td>\n      <td>-26.619</td>\n      <td>-26.523</td>\n      <td>-22.574</td>\n      <td>24.691</td>\n      <td>-26.253</td>\n      <td>-26.497</td>\n      <td>-26.438</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>TRAIN_00003</td>\n      <td>72.583</td>\n      <td>103.320</td>\n      <td>64.07</td>\n      <td>1</td>\n      <td>103.153</td>\n      <td>72.943</td>\n      <td>28.81</td>\n      <td>105.77</td>\n      <td>272.20</td>\n      <td>...</td>\n      <td>31.801</td>\n      <td>17.080</td>\n      <td>2.839</td>\n      <td>-26.238</td>\n      <td>-26.216</td>\n      <td>-22.169</td>\n      <td>24.649</td>\n      <td>-26.285</td>\n      <td>-26.215</td>\n      <td>-26.370</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>TRAIN_00004</td>\n      <td>71.563</td>\n      <td>103.320</td>\n      <td>67.57</td>\n      <td>1</td>\n      <td>101.971</td>\n      <td>77.022</td>\n      <td>28.92</td>\n      <td>115.21</td>\n      <td>255.36</td>\n      <td>...</td>\n      <td>34.503</td>\n      <td>17.143</td>\n      <td>3.144</td>\n      <td>-25.426</td>\n      <td>-25.079</td>\n      <td>-21.765</td>\n      <td>24.913</td>\n      <td>-25.254</td>\n      <td>-25.021</td>\n      <td>-25.345</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>TRAIN_00005</td>\n      <td>69.524</td>\n      <td>103.320</td>\n      <td>63.57</td>\n      <td>1</td>\n      <td>101.981</td>\n      <td>70.904</td>\n      <td>29.68</td>\n      <td>103.38</td>\n      <td>241.46</td>\n      <td>...</td>\n      <td>32.602</td>\n      <td>17.569</td>\n      <td>3.138</td>\n      <td>-25.376</td>\n      <td>-25.242</td>\n      <td>-21.072</td>\n      <td>25.299</td>\n      <td>-25.072</td>\n      <td>-25.195</td>\n      <td>-24.974</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>39602</th>\n      <td>TRAIN_39603</td>\n      <td>66.465</td>\n      <td>103.320</td>\n      <td>62.27</td>\n      <td>1</td>\n      <td>103.150</td>\n      <td>66.825</td>\n      <td>30.20</td>\n      <td>77.83</td>\n      <td>298.05</td>\n      <td>...</td>\n      <td>29.194</td>\n      <td>16.582</td>\n      <td>3.410</td>\n      <td>-26.486</td>\n      <td>-26.581</td>\n      <td>-22.772</td>\n      <td>24.261</td>\n      <td>-26.491</td>\n      <td>-26.584</td>\n      <td>-26.580</td>\n    </tr>\n    <tr>\n      <th>39603</th>\n      <td>TRAIN_39604</td>\n      <td>66.465</td>\n      <td>103.321</td>\n      <td>62.77</td>\n      <td>1</td>\n      <td>102.021</td>\n      <td>66.825</td>\n      <td>29.21</td>\n      <td>102.25</td>\n      <td>270.67</td>\n      <td>...</td>\n      <td>29.859</td>\n      <td>15.659</td>\n      <td>3.406</td>\n      <td>-27.308</td>\n      <td>-27.203</td>\n      <td>-24.674</td>\n      <td>23.427</td>\n      <td>-27.250</td>\n      <td>-27.334</td>\n      <td>-27.325</td>\n    </tr>\n    <tr>\n      <th>39604</th>\n      <td>TRAIN_39605</td>\n      <td>68.504</td>\n      <td>103.320</td>\n      <td>64.67</td>\n      <td>1</td>\n      <td>103.144</td>\n      <td>68.864</td>\n      <td>29.96</td>\n      <td>102.61</td>\n      <td>198.07</td>\n      <td>...</td>\n      <td>24.720</td>\n      <td>16.823</td>\n      <td>3.215</td>\n      <td>-26.502</td>\n      <td>-26.687</td>\n      <td>-22.577</td>\n      <td>24.301</td>\n      <td>-26.388</td>\n      <td>-26.425</td>\n      <td>-26.601</td>\n    </tr>\n    <tr>\n      <th>39605</th>\n      <td>TRAIN_39606</td>\n      <td>66.465</td>\n      <td>103.320</td>\n      <td>63.67</td>\n      <td>1</td>\n      <td>102.025</td>\n      <td>67.845</td>\n      <td>30.30</td>\n      <td>112.60</td>\n      <td>275.52</td>\n      <td>...</td>\n      <td>26.412</td>\n      <td>15.757</td>\n      <td>4.216</td>\n      <td>-26.760</td>\n      <td>-26.634</td>\n      <td>-24.066</td>\n      <td>23.305</td>\n      <td>-26.536</td>\n      <td>-26.751</td>\n      <td>-26.635</td>\n    </tr>\n    <tr>\n      <th>39606</th>\n      <td>TRAIN_39607</td>\n      <td>66.465</td>\n      <td>103.320</td>\n      <td>65.67</td>\n      <td>1</td>\n      <td>102.004</td>\n      <td>69.884</td>\n      <td>30.16</td>\n      <td>112.90</td>\n      <td>276.06</td>\n      <td>...</td>\n      <td>30.745</td>\n      <td>16.781</td>\n      <td>3.307</td>\n      <td>-26.054</td>\n      <td>-26.251</td>\n      <td>-23.257</td>\n      <td>24.450</td>\n      <td>-26.224</td>\n      <td>-26.256</td>\n      <td>-26.093</td>\n    </tr>\n  </tbody>\n</table>\n<p>39607 rows × 71 columns</p>\n</div>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "x_col  =[col for col in train.columns if 'X' in col]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "['X_01',\n 'X_02',\n 'X_03',\n 'X_04',\n 'X_05',\n 'X_06',\n 'X_07',\n 'X_08',\n 'X_09',\n 'X_10',\n 'X_11',\n 'X_12',\n 'X_13',\n 'X_14',\n 'X_15',\n 'X_16',\n 'X_17',\n 'X_18',\n 'X_19',\n 'X_20',\n 'X_21',\n 'X_22',\n 'X_23',\n 'X_24',\n 'X_25',\n 'X_26',\n 'X_27',\n 'X_28',\n 'X_29',\n 'X_30',\n 'X_31',\n 'X_32',\n 'X_33',\n 'X_34',\n 'X_35',\n 'X_36',\n 'X_37',\n 'X_38',\n 'X_39',\n 'X_40',\n 'X_41',\n 'X_42',\n 'X_43',\n 'X_44',\n 'X_45',\n 'X_46',\n 'X_47',\n 'X_48',\n 'X_49',\n 'X_50',\n 'X_51',\n 'X_52',\n 'X_53',\n 'X_54',\n 'X_55',\n 'X_56']"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_col"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "x_train = train[x_col]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "68.41203966470574"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train['X_01'].mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "\n",
    "# 평균값과의 차이"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-34-dc8bfe833515>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x_train['x_01_diff'] = x_train['X_01'] - x_train['X_01'].mean()#%%\n"
     ]
    }
   ],
   "source": [
    "x_train['x_01_diff'] = x_train['X_01'] - x_train['X_01'].mean()#%%"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "x_train\n",
    "import seaborn as sns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "1    39607\nName: X_04, dtype: int64"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train['X_04'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Could not interpret input 'X_04'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-37-7370bdc33c44>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0msns\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mboxplot\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx_train\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'x_01_diff'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mhue\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'X_04'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\seaborn\\_decorators.py\u001B[0m in \u001B[0;36minner_f\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     44\u001B[0m             )\n\u001B[0;32m     45\u001B[0m         \u001B[0mkwargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m{\u001B[0m\u001B[0mk\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0marg\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mk\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0marg\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mzip\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msig\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mparameters\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 46\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     47\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0minner_f\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     48\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\seaborn\\categorical.py\u001B[0m in \u001B[0;36mboxplot\u001B[1;34m(x, y, hue, data, order, hue_order, orient, color, palette, saturation, width, dodge, fliersize, linewidth, whis, ax, **kwargs)\u001B[0m\n\u001B[0;32m   2238\u001B[0m ):\n\u001B[0;32m   2239\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2240\u001B[1;33m     plotter = _BoxPlotter(x, y, hue, data, order, hue_order,\n\u001B[0m\u001B[0;32m   2241\u001B[0m                           \u001B[0morient\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcolor\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpalette\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msaturation\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2242\u001B[0m                           width, dodge, fliersize, linewidth)\n",
      "\u001B[1;32mc:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\seaborn\\categorical.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, x, y, hue, data, order, hue_order, orient, color, palette, saturation, width, dodge, fliersize, linewidth)\u001B[0m\n\u001B[0;32m    404\u001B[0m                  width, dodge, fliersize, linewidth):\n\u001B[0;32m    405\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 406\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mestablish_variables\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mhue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0morient\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0morder\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mhue_order\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    407\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mestablish_colors\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcolor\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpalette\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msaturation\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    408\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\seaborn\\categorical.py\u001B[0m in \u001B[0;36mestablish_variables\u001B[1;34m(self, x, y, hue, data, orient, order, hue_order, units)\u001B[0m\n\u001B[0;32m    151\u001B[0m                 \u001B[1;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvar\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstr\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    152\u001B[0m                     \u001B[0merr\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m\"Could not interpret input '{}'\"\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvar\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 153\u001B[1;33m                     \u001B[1;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0merr\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    154\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    155\u001B[0m             \u001B[1;31m# Figure out the plotting orientation\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: Could not interpret input 'X_04'"
     ]
    }
   ],
   "source": [
    "sns.boxplot(x_train['x_01_diff'],hue='X_04')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 1차검사는 모두 통과했으므로 버린다\n",
    "# train['X_04'].value_counts()\n",
    "\n",
    "x_train = x_train.drop('X_04',axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "가설 1 누름량이 너무 크거나 너무 적으면 불량 날 확률이 증가할 것이다\n",
    "가설 2 통과여부에따라 다를 것이다"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "너무 크거나 너무 적은 것의 통과여부나 아웃라이어를 제거한다 ? 그러면 아웃라이어 데이터를 예측 못하는 게 아닌가"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "# 2차검사 통과도 모두 통과했으므로 버린다\n",
    "x_train['X_23'].value_counts()\n",
    "x_train = x_train.drop('X_23',axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "1    39607\nName: X_47, dtype: int64"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train['X_47'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "x_train['X_48'].value_counts()\n",
    "x_train = x_train.drop(['X_47','X_48'],axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "         X_01     X_02   X_03  X_04     X_05    X_06   X_07    X_08    X_09  \\\n0      70.544  103.320  67.47     1  101.892  74.983  29.45   62.38  245.71   \n1      69.524  103.321  65.17     1  101.944  72.943  28.73   61.23  233.61   \n2      72.583  103.320  64.07     1  103.153  72.943  28.81  105.77  272.20   \n3      71.563  103.320  67.57     1  101.971  77.022  28.92  115.21  255.36   \n4      69.524  103.320  63.57     1  101.981  70.904  29.68  103.38  241.46   \n...       ...      ...    ...   ...      ...     ...    ...     ...     ...   \n39602  66.465  103.320  62.27     1  103.150  66.825  30.20   77.83  298.05   \n39603  66.465  103.321  62.77     1  102.021  66.825  29.21  102.25  270.67   \n39604  68.504  103.320  64.67     1  103.144  68.864  29.96  102.61  198.07   \n39605  66.465  103.320  63.67     1  102.025  67.845  30.30  112.60  275.52   \n39606  66.465  103.320  65.67     1  102.004  69.884  30.16  112.90  276.06   \n\n       X_10  ...  X_46      X_49        X_50        X_51        X_52  \\\n0       0.0  ...  1463   9706.03  137.043591  135.359219  147.837968   \n1       0.0  ...  1463  10423.43  133.736691  135.979817  149.924692   \n2       0.0  ...  1468  10948.53  132.805112  131.055355  146.814592   \n3       0.0  ...  1469  15007.03  134.138760  133.239422  139.720132   \n4       0.0  ...  1469  11051.03  142.728970  136.620022  134.853555   \n...     ...  ...   ...       ...         ...         ...         ...   \n39602   0.0  ...  1469  60630.73  129.965741  130.807148  133.481737   \n39603   0.0  ...  1458  60763.43  127.633885  120.158764  142.667802   \n39604   0.0  ...  1459   8813.33  132.501286  136.893025  134.419328   \n39605   0.0  ...  1469  62222.33  128.189679  121.495930  141.288011   \n39606   0.0  ...  1462  62172.23  135.096272  122.988476  142.019357   \n\n             X_53        X_54        X_55        X_56  x_01_diff  \n0      134.313475  125.605427  136.721425  125.028256    2.13196  \n1      123.630583  127.893337  143.322659  124.877308    1.11196  \n2      128.939070  127.012195  140.395688  122.238232    4.17096  \n3      132.260824  130.723186  147.624829  134.875225    3.15096  \n4      134.760252  125.647793  139.331105  123.272762    1.11196  \n...           ...         ...         ...         ...        ...  \n39602  125.273130  121.780933  133.780110  129.029812   -1.94704  \n39603  122.465490  122.987209  143.090741  122.811413   -1.94704  \n39604  129.115431  130.920147  140.489232  119.166699    0.09196  \n39605  130.141676  125.518825  136.603634  124.525929   -1.94704  \n39606  123.752157  130.648365  139.695370  136.714504   -1.94704  \n\n[39607 rows x 54 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X_01</th>\n      <th>X_02</th>\n      <th>X_03</th>\n      <th>X_04</th>\n      <th>X_05</th>\n      <th>X_06</th>\n      <th>X_07</th>\n      <th>X_08</th>\n      <th>X_09</th>\n      <th>X_10</th>\n      <th>...</th>\n      <th>X_46</th>\n      <th>X_49</th>\n      <th>X_50</th>\n      <th>X_51</th>\n      <th>X_52</th>\n      <th>X_53</th>\n      <th>X_54</th>\n      <th>X_55</th>\n      <th>X_56</th>\n      <th>x_01_diff</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>70.544</td>\n      <td>103.320</td>\n      <td>67.47</td>\n      <td>1</td>\n      <td>101.892</td>\n      <td>74.983</td>\n      <td>29.45</td>\n      <td>62.38</td>\n      <td>245.71</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1463</td>\n      <td>9706.03</td>\n      <td>137.043591</td>\n      <td>135.359219</td>\n      <td>147.837968</td>\n      <td>134.313475</td>\n      <td>125.605427</td>\n      <td>136.721425</td>\n      <td>125.028256</td>\n      <td>2.13196</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>69.524</td>\n      <td>103.321</td>\n      <td>65.17</td>\n      <td>1</td>\n      <td>101.944</td>\n      <td>72.943</td>\n      <td>28.73</td>\n      <td>61.23</td>\n      <td>233.61</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1463</td>\n      <td>10423.43</td>\n      <td>133.736691</td>\n      <td>135.979817</td>\n      <td>149.924692</td>\n      <td>123.630583</td>\n      <td>127.893337</td>\n      <td>143.322659</td>\n      <td>124.877308</td>\n      <td>1.11196</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>72.583</td>\n      <td>103.320</td>\n      <td>64.07</td>\n      <td>1</td>\n      <td>103.153</td>\n      <td>72.943</td>\n      <td>28.81</td>\n      <td>105.77</td>\n      <td>272.20</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1468</td>\n      <td>10948.53</td>\n      <td>132.805112</td>\n      <td>131.055355</td>\n      <td>146.814592</td>\n      <td>128.939070</td>\n      <td>127.012195</td>\n      <td>140.395688</td>\n      <td>122.238232</td>\n      <td>4.17096</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>71.563</td>\n      <td>103.320</td>\n      <td>67.57</td>\n      <td>1</td>\n      <td>101.971</td>\n      <td>77.022</td>\n      <td>28.92</td>\n      <td>115.21</td>\n      <td>255.36</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1469</td>\n      <td>15007.03</td>\n      <td>134.138760</td>\n      <td>133.239422</td>\n      <td>139.720132</td>\n      <td>132.260824</td>\n      <td>130.723186</td>\n      <td>147.624829</td>\n      <td>134.875225</td>\n      <td>3.15096</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>69.524</td>\n      <td>103.320</td>\n      <td>63.57</td>\n      <td>1</td>\n      <td>101.981</td>\n      <td>70.904</td>\n      <td>29.68</td>\n      <td>103.38</td>\n      <td>241.46</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1469</td>\n      <td>11051.03</td>\n      <td>142.728970</td>\n      <td>136.620022</td>\n      <td>134.853555</td>\n      <td>134.760252</td>\n      <td>125.647793</td>\n      <td>139.331105</td>\n      <td>123.272762</td>\n      <td>1.11196</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>39602</th>\n      <td>66.465</td>\n      <td>103.320</td>\n      <td>62.27</td>\n      <td>1</td>\n      <td>103.150</td>\n      <td>66.825</td>\n      <td>30.20</td>\n      <td>77.83</td>\n      <td>298.05</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1469</td>\n      <td>60630.73</td>\n      <td>129.965741</td>\n      <td>130.807148</td>\n      <td>133.481737</td>\n      <td>125.273130</td>\n      <td>121.780933</td>\n      <td>133.780110</td>\n      <td>129.029812</td>\n      <td>-1.94704</td>\n    </tr>\n    <tr>\n      <th>39603</th>\n      <td>66.465</td>\n      <td>103.321</td>\n      <td>62.77</td>\n      <td>1</td>\n      <td>102.021</td>\n      <td>66.825</td>\n      <td>29.21</td>\n      <td>102.25</td>\n      <td>270.67</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1458</td>\n      <td>60763.43</td>\n      <td>127.633885</td>\n      <td>120.158764</td>\n      <td>142.667802</td>\n      <td>122.465490</td>\n      <td>122.987209</td>\n      <td>143.090741</td>\n      <td>122.811413</td>\n      <td>-1.94704</td>\n    </tr>\n    <tr>\n      <th>39604</th>\n      <td>68.504</td>\n      <td>103.320</td>\n      <td>64.67</td>\n      <td>1</td>\n      <td>103.144</td>\n      <td>68.864</td>\n      <td>29.96</td>\n      <td>102.61</td>\n      <td>198.07</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1459</td>\n      <td>8813.33</td>\n      <td>132.501286</td>\n      <td>136.893025</td>\n      <td>134.419328</td>\n      <td>129.115431</td>\n      <td>130.920147</td>\n      <td>140.489232</td>\n      <td>119.166699</td>\n      <td>0.09196</td>\n    </tr>\n    <tr>\n      <th>39605</th>\n      <td>66.465</td>\n      <td>103.320</td>\n      <td>63.67</td>\n      <td>1</td>\n      <td>102.025</td>\n      <td>67.845</td>\n      <td>30.30</td>\n      <td>112.60</td>\n      <td>275.52</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1469</td>\n      <td>62222.33</td>\n      <td>128.189679</td>\n      <td>121.495930</td>\n      <td>141.288011</td>\n      <td>130.141676</td>\n      <td>125.518825</td>\n      <td>136.603634</td>\n      <td>124.525929</td>\n      <td>-1.94704</td>\n    </tr>\n    <tr>\n      <th>39606</th>\n      <td>66.465</td>\n      <td>103.320</td>\n      <td>65.67</td>\n      <td>1</td>\n      <td>102.004</td>\n      <td>69.884</td>\n      <td>30.16</td>\n      <td>112.90</td>\n      <td>276.06</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1462</td>\n      <td>62172.23</td>\n      <td>135.096272</td>\n      <td>122.988476</td>\n      <td>142.019357</td>\n      <td>123.752157</td>\n      <td>130.648365</td>\n      <td>139.695370</td>\n      <td>136.714504</td>\n      <td>-1.94704</td>\n    </tr>\n  </tbody>\n</table>\n<p>39607 rows × 54 columns</p>\n</div>"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "y_col = [col for col in train.columns if 'Y' in col]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "y_train = train[y_col]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "        Y_01   Y_02   Y_03    Y_04    Y_05    Y_06   Y_07    Y_08    Y_09  \\\n0      2.056  1.456  1.680  10.502  29.632  16.083  4.276 -25.381 -25.529   \n1      1.446  1.184  1.268  18.507  33.179  16.736  3.229 -26.619 -26.523   \n2      1.251  0.665  0.782  14.082  31.801  17.080  2.839 -26.238 -26.216   \n3      1.464  1.079  1.052  16.975  34.503  17.143  3.144 -25.426 -25.079   \n4      0.983  0.646  0.689  15.047  32.602  17.569  3.138 -25.376 -25.242   \n...      ...    ...    ...     ...     ...     ...    ...     ...     ...   \n39602  1.382  1.215  1.263  10.874  29.194  16.582  3.410 -26.486 -26.581   \n39603  1.482  0.606  1.083   8.759  29.859  15.659  3.406 -27.308 -27.203   \n39604  1.117  1.154  0.993  13.159  24.720  16.823  3.215 -26.502 -26.687   \n39605  0.895  0.187  0.477   9.123  26.412  15.757  4.216 -26.760 -26.634   \n39606  1.147  0.348  0.852  10.421  30.745  16.781  3.307 -26.054 -26.251   \n\n         Y_10    Y_11    Y_12    Y_13    Y_14  \n0     -22.769  23.792 -25.470 -25.409 -25.304  \n1     -22.574  24.691 -26.253 -26.497 -26.438  \n2     -22.169  24.649 -26.285 -26.215 -26.370  \n3     -21.765  24.913 -25.254 -25.021 -25.345  \n4     -21.072  25.299 -25.072 -25.195 -24.974  \n...       ...     ...     ...     ...     ...  \n39602 -22.772  24.261 -26.491 -26.584 -26.580  \n39603 -24.674  23.427 -27.250 -27.334 -27.325  \n39604 -22.577  24.301 -26.388 -26.425 -26.601  \n39605 -24.066  23.305 -26.536 -26.751 -26.635  \n39606 -23.257  24.450 -26.224 -26.256 -26.093  \n\n[39607 rows x 14 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Y_01</th>\n      <th>Y_02</th>\n      <th>Y_03</th>\n      <th>Y_04</th>\n      <th>Y_05</th>\n      <th>Y_06</th>\n      <th>Y_07</th>\n      <th>Y_08</th>\n      <th>Y_09</th>\n      <th>Y_10</th>\n      <th>Y_11</th>\n      <th>Y_12</th>\n      <th>Y_13</th>\n      <th>Y_14</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2.056</td>\n      <td>1.456</td>\n      <td>1.680</td>\n      <td>10.502</td>\n      <td>29.632</td>\n      <td>16.083</td>\n      <td>4.276</td>\n      <td>-25.381</td>\n      <td>-25.529</td>\n      <td>-22.769</td>\n      <td>23.792</td>\n      <td>-25.470</td>\n      <td>-25.409</td>\n      <td>-25.304</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.446</td>\n      <td>1.184</td>\n      <td>1.268</td>\n      <td>18.507</td>\n      <td>33.179</td>\n      <td>16.736</td>\n      <td>3.229</td>\n      <td>-26.619</td>\n      <td>-26.523</td>\n      <td>-22.574</td>\n      <td>24.691</td>\n      <td>-26.253</td>\n      <td>-26.497</td>\n      <td>-26.438</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.251</td>\n      <td>0.665</td>\n      <td>0.782</td>\n      <td>14.082</td>\n      <td>31.801</td>\n      <td>17.080</td>\n      <td>2.839</td>\n      <td>-26.238</td>\n      <td>-26.216</td>\n      <td>-22.169</td>\n      <td>24.649</td>\n      <td>-26.285</td>\n      <td>-26.215</td>\n      <td>-26.370</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.464</td>\n      <td>1.079</td>\n      <td>1.052</td>\n      <td>16.975</td>\n      <td>34.503</td>\n      <td>17.143</td>\n      <td>3.144</td>\n      <td>-25.426</td>\n      <td>-25.079</td>\n      <td>-21.765</td>\n      <td>24.913</td>\n      <td>-25.254</td>\n      <td>-25.021</td>\n      <td>-25.345</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.983</td>\n      <td>0.646</td>\n      <td>0.689</td>\n      <td>15.047</td>\n      <td>32.602</td>\n      <td>17.569</td>\n      <td>3.138</td>\n      <td>-25.376</td>\n      <td>-25.242</td>\n      <td>-21.072</td>\n      <td>25.299</td>\n      <td>-25.072</td>\n      <td>-25.195</td>\n      <td>-24.974</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>39602</th>\n      <td>1.382</td>\n      <td>1.215</td>\n      <td>1.263</td>\n      <td>10.874</td>\n      <td>29.194</td>\n      <td>16.582</td>\n      <td>3.410</td>\n      <td>-26.486</td>\n      <td>-26.581</td>\n      <td>-22.772</td>\n      <td>24.261</td>\n      <td>-26.491</td>\n      <td>-26.584</td>\n      <td>-26.580</td>\n    </tr>\n    <tr>\n      <th>39603</th>\n      <td>1.482</td>\n      <td>0.606</td>\n      <td>1.083</td>\n      <td>8.759</td>\n      <td>29.859</td>\n      <td>15.659</td>\n      <td>3.406</td>\n      <td>-27.308</td>\n      <td>-27.203</td>\n      <td>-24.674</td>\n      <td>23.427</td>\n      <td>-27.250</td>\n      <td>-27.334</td>\n      <td>-27.325</td>\n    </tr>\n    <tr>\n      <th>39604</th>\n      <td>1.117</td>\n      <td>1.154</td>\n      <td>0.993</td>\n      <td>13.159</td>\n      <td>24.720</td>\n      <td>16.823</td>\n      <td>3.215</td>\n      <td>-26.502</td>\n      <td>-26.687</td>\n      <td>-22.577</td>\n      <td>24.301</td>\n      <td>-26.388</td>\n      <td>-26.425</td>\n      <td>-26.601</td>\n    </tr>\n    <tr>\n      <th>39605</th>\n      <td>0.895</td>\n      <td>0.187</td>\n      <td>0.477</td>\n      <td>9.123</td>\n      <td>26.412</td>\n      <td>15.757</td>\n      <td>4.216</td>\n      <td>-26.760</td>\n      <td>-26.634</td>\n      <td>-24.066</td>\n      <td>23.305</td>\n      <td>-26.536</td>\n      <td>-26.751</td>\n      <td>-26.635</td>\n    </tr>\n    <tr>\n      <th>39606</th>\n      <td>1.147</td>\n      <td>0.348</td>\n      <td>0.852</td>\n      <td>10.421</td>\n      <td>30.745</td>\n      <td>16.781</td>\n      <td>3.307</td>\n      <td>-26.054</td>\n      <td>-26.251</td>\n      <td>-23.257</td>\n      <td>24.450</td>\n      <td>-26.224</td>\n      <td>-26.256</td>\n      <td>-26.093</td>\n    </tr>\n  </tbody>\n</table>\n<p>39607 rows × 14 columns</p>\n</div>"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 안테나 gain 평균이 높은 index들의 특징\n",
    "y_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "count    39607.000000\nmean         1.353814\nstd          0.356223\nmin          0.017000\n25%          1.127500\n50%          1.349000\n75%          1.576000\nmax          4.409000\nName: Y_01, dtype: float64"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train['Y_01'].describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "# mean         1.353814\n",
    "# std          0.356223\n",
    "# min          0.017000\n",
    "# 25%          1.127500\n",
    "# 50%          1.349000\n",
    "# 75%          1.576000\n",
    "# max          4.409000"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "0.20271697499899233"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train.Y_01 >= 1.576000]['X_01'].mean() - train[train.Y_01 <= 1.127500]['X_01'].mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "0        16.083\n1        16.736\n2        17.080\n3        17.143\n4        17.569\n          ...  \n39602    16.582\n39603    15.659\n39604    16.823\n39605    15.757\n39606    16.781\nName: Y_06, Length: 39607, dtype: float64"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Y_06']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "안테나 gain 평균이 잘나오도록, 신호대 잡음비도 적도록"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# xgbregressor 가 성능 좋다고 discussion 에서"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-49-0696000b91e4>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  File \u001B[1;32m\"<ipython-input-49-0696000b91e4>\"\u001B[1;36m, line \u001B[1;32m3\u001B[0m\n\u001B[1;33m    NR로도 알려진 '신호 대 잡음비'는 영상 데이터가 노이즈와 얼마나 구별되는지를 나타냅니다.\u001B[0m\n\u001B[1;37m         ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# 어떤 기준치를 어떤 값이 초과했는지 여부를 feature로 추가 ?\n",
    "#\n",
    "NR로도 알려진 '신호 대 잡음비'는 영상 데이터가 노이즈와 얼마나 구별되는지를 나타냅니다.\n",
    "즉, 숫자가 높을수록 이미지의 노이즈와 관련하여 영상에 더 많은 대비 및 선명도가 나타납니다."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\"\"\"\n",
    "전자기학에서 안테나의 전력 이득 또는 단순히 이득은 안테나의\n",
    "지향성과 전기 효율을 결합한 **핵심 성능 수치**이다.\n",
    "송신 안테나에서 이득은 안테나가\n",
    "입력 전력을 지정된 방향으로 진행하는\n",
    "전파로 얼마나 잘 변환 하는지를 나타낸다.\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_01 : 0.20271697499899233\n",
      "X_02 : -7.254917093746371e-06\n",
      "X_03 : 0.1259507677711582\n",
      "X_04 : 0.0\n",
      "X_05 : -0.008807696023922063\n",
      "X_06 : 0.2603884545102204\n",
      "X_07 : -0.4276050317814608\n",
      "X_08 : 2.8579926871403245\n",
      "\n",
      "\n",
      "X_08 : 2.8579926871403245\n",
      "X_08=============\n",
      "=====X_08 describe start =====\n",
      "count    39607.000000\n",
      "mean       164.449320\n",
      "std        220.402444\n",
      "min         38.460000\n",
      "25%        105.990000\n",
      "50%        115.040000\n",
      "75%        132.620000\n",
      "max       2387.440000\n",
      "Name: X_08, dtype: float64\n",
      "=====X_08 describe  end=====\n",
      "diff :2.8579926871403245 \n",
      "표준 편차 : 220.40244354747472\n",
      "\n",
      "X_09 : 2.8122422657661446\n",
      "\n",
      "\n",
      "X_09 : 2.8122422657661446\n",
      "X_09=============\n",
      "=====X_09 describe start =====\n",
      "count    39607.000000\n",
      "mean       225.397470\n",
      "std         66.734725\n",
      "min         37.580000\n",
      "25%        188.540000\n",
      "50%        234.450000\n",
      "75%        263.960000\n",
      "max        637.490000\n",
      "Name: X_09, dtype: float64\n",
      "=====X_09 describe  end=====\n",
      "diff :2.8122422657661446 \n",
      "표준 편차 : 66.73472479951303\n",
      "\n",
      "X_10 : 0.0026084675082468133\n",
      "X_11 : 0.0004433161689873799\n",
      "X_12 : 0.0019333033646047326\n",
      "X_13 : 0.003723234446237317\n",
      "X_14 : -0.004750037920768335\n",
      "X_15 : -0.0033993444252526928\n",
      "X_16 : -0.004334612176444708\n",
      "X_17 : -0.0003991951042596753\n",
      "X_18 : -0.005524404513563397\n",
      "X_19 : 3.644242664080366e-06\n",
      "X_20 : 0.01843488447089925\n",
      "X_21 : 0.0022303307772553183\n",
      "X_22 : 0.022277351312343985\n",
      "X_23 : 0.0\n",
      "X_24 : 0.0024281604242188948\n",
      "X_25 : -0.0012367191011484202\n",
      "X_26 : 0.0027561930693353887\n",
      "X_27 : -0.0011759076025401605\n",
      "X_28 : 0.0034135028369259857\n",
      "X_29 : 0.001802001076422144\n",
      "X_30 : 0.0012237641356305229\n",
      "X_31 : -0.004931729375136973\n",
      "X_32 : 0.0001414346532098154\n",
      "X_33 : -0.007947246561010424\n",
      "X_34 : -0.00033318984969987753\n",
      "X_35 : 0.000431476987433399\n",
      "X_36 : -0.0009107212167300816\n",
      "X_37 : -9.046229417108975e-05\n",
      "X_38 : 0.03341613718259495\n",
      "X_39 : 0.03788948674528214\n",
      "X_40 : 0.0323198672731273\n",
      "X_41 : 0.0004128585961566955\n",
      "X_42 : -0.003532373689210999\n",
      "X_43 : 0.002011312841855073\n",
      "X_44 : 0.0001624497553613935\n",
      "X_45 : 0.0037001521045982033\n",
      "X_46 : -0.15164570040133185\n",
      "X_47 : 0.0\n",
      "X_48 : 0.0\n",
      "X_49 : 875.2736033977835\n",
      "\n",
      "\n",
      "X_49 : 875.2736033977835\n",
      "X_49=============\n",
      "=====X_49 describe start =====\n",
      "count     39607.000000\n",
      "mean      16676.913639\n",
      "std        8584.427420\n",
      "min        3341.830000\n",
      "25%       13093.930000\n",
      "50%       15273.330000\n",
      "75%       17560.180000\n",
      "max      114563.630000\n",
      "Name: X_49, dtype: float64\n",
      "=====X_49 describe  end=====\n",
      "diff :875.2736033977835 \n",
      "표준 편차 : 8584.427419558513\n",
      "\n",
      "X_50 : 0.5373103376572317\n",
      "X_51 : 0.9405200243136278\n",
      "X_52 : 0.9001978659938743\n",
      "X_53 : 0.6473177916085717\n",
      "X_54 : 0.4668584336233863\n",
      "X_55 : 0.5297406194605401\n",
      "X_56 : 0.578453062408812\n"
     ]
    }
   ],
   "source": [
    "for col in x_col:\n",
    "    diff =  train[train.Y_01 >= 1.576000][col].mean() - train[train.Y_01 <= 1.127500][col].mean()\n",
    "\n",
    "\n",
    "    print(f\"{col} : {diff}\")\n",
    "    if abs(diff) > 1:\n",
    "        print(f\"\\n\\n{col} : {diff}\")\n",
    "        print(f\"{col}=============\")\n",
    "        describe = x_train[col].describe()\n",
    "        print(f\"====={col} describe start =====\")\n",
    "        print(describe)\n",
    "        print(f\"====={col} describe  end=====\")\n",
    "        print(f\"diff :{diff} \")\n",
    "        print(f\"표준 편차 : {describe.loc['std']}\\n\")\n",
    "# 그 절댓값이 1이상 차이나면서 표준편차는 원래 그렇게 차이 나지 않는 것들은\n",
    "# 영향을 미치는건지 체크해볼만 하다"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "count    39607.000000\nmean        13.621191\nstd          2.686632\nmin         -0.331000\n25%         11.822000\n50%         13.837000\n75%         15.626000\nmax         98.794000\nName: Y_04, dtype: float64"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train.Y_04.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "# 표준편차를 봤을 때 확실히 잡음비\n",
    "signal_to_noise25 = train.Y_04.describe()['25%']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "signal_to_noise75 = train.Y_04.describe()['75%']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "68.21073696969697"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "68.21073696969697"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "x_train.loc[train[train.Y_04 <signal_to_noise25].index]['X_01'].mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68.54857981410386\n",
      "68.21073696969697\n",
      "103.32016649828245\n",
      "103.32016989898986\n",
      "68.8481369973732\n",
      "68.76180808080807\n",
      "1.0\n",
      "1.0\n",
      "102.36247312588401\n",
      "102.3067615151515\n",
      "70.68353182461104\n",
      "70.47767545454546\n",
      "29.459306930693067\n",
      "29.445826262626262\n",
      "160.42942109517077\n",
      "169.20473636363639\n",
      "224.11781572034755\n",
      "224.12082424242422\n",
      "0.0028086482117599515\n",
      "0.003050505050505051\n",
      "0.000434431198221863\n",
      "0.0003333333333333333\n",
      "4.373559304910082\n",
      "4.372462626262626\n",
      "0.1451778136997373\n",
      "0.14316161616161616\n",
      "13.370502121640737\n",
      "13.372905050505052\n",
      "13.38187613659325\n",
      "13.380960606060608\n",
      "13.46180036370984\n",
      "13.466025252525252\n",
      "13.513305718326936\n",
      "13.512536363636364\n",
      "13.448616892301475\n",
      "13.450158585858587\n",
      "3.250207112547989\n",
      "3.2294939393939393\n",
      "3.19338351182057\n",
      "3.175374747474747\n",
      "3.1831491210345524\n",
      "3.1635545454545455\n",
      "3.242091331582138\n",
      "3.2244636363636365\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'X_23'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[1;32mc:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001B[0m in \u001B[0;36mget_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3079\u001B[0m             \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3080\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcasted_key\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3081\u001B[0m             \u001B[1;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'X_23'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-73-7c3ebc445b41>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;31m#\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mcol\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mx_col\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 5\u001B[1;33m     \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx_train\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mloc\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mtrain\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mtrain\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mY_04\u001B[0m \u001B[1;33m>\u001B[0m \u001B[0msignal_to_noise75\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mindex\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mcol\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmean\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      6\u001B[0m     \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx_train\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mloc\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mtrain\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mtrain\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mY_04\u001B[0m \u001B[1;33m<\u001B[0m \u001B[0msignal_to_noise25\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mindex\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mcol\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmean\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\frame.py\u001B[0m in \u001B[0;36m__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3022\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnlevels\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3023\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_getitem_multilevel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3024\u001B[1;33m             \u001B[0mindexer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3025\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mis_integer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mindexer\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3026\u001B[0m                 \u001B[0mindexer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mindexer\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001B[0m in \u001B[0;36mget_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3080\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcasted_key\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3081\u001B[0m             \u001B[1;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3082\u001B[1;33m                 \u001B[1;32mraise\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3083\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3084\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mtolerance\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'X_23'"
     ]
    }
   ],
   "source": [
    "#|%%#\n",
    "# y 와의 상관관계가 높은 것을 가중치를 줘서 모델이 불량 판별을 잘 할 수 있도록 도움을 준다\n",
    "#\n",
    "for col in x_col:\n",
    "    print(x_train.loc[train[train.Y_04 > signal_to_noise75].index][col].mean())\n",
    "    print(x_train.loc[train[train.Y_04 < signal_to_noise25].index][col].mean())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "data": {
      "text/plain": "         X_01     X_02   X_03  X_04     X_05    X_06   X_07    X_08    X_09  \\\n1      69.524  103.321  65.17     1  101.944  72.943  28.73   61.23  233.61   \n3      71.563  103.320  67.57     1  101.971  77.022  28.92  115.21  255.36   \n7      69.524  103.320  65.47     1  101.968  73.963  29.77   71.41  238.27   \n9      71.563  103.320  68.97     1  101.990  77.022  28.97   66.88  228.22   \n12     71.563  103.320  71.27     1  101.910  76.002  26.29   98.60  162.44   \n...       ...      ...    ...   ...      ...     ...    ...     ...     ...   \n39591  65.445  103.320  60.87     1  103.158  65.805  30.17  117.38  301.95   \n39594  66.465  103.321  63.67     1  102.030  67.845  32.44  104.27  190.16   \n39597  67.485  103.320  62.77     1  103.154  67.845  30.07  104.72  200.87   \n39598  69.524  103.320  62.87     1  103.141  69.884  32.68  105.51  283.36   \n39599  66.465  103.320  61.37     1  103.141  66.825  30.25  114.36  217.60   \n\n       X_10  ...  X_46      X_49        X_50        X_51        X_52  \\\n1       0.0  ...  1463  10423.43  133.736691  135.979817  149.924692   \n3       0.0  ...  1469  15007.03  134.138760  133.239422  139.720132   \n7       0.0  ...  1469  11907.13  133.099217  128.041348  134.704309   \n9       0.0  ...  1469  12461.23  133.556149  123.122143  141.628915   \n12      0.0  ...  1469  16017.63  140.558987  131.504597  141.168291   \n...     ...  ...   ...       ...         ...         ...         ...   \n39591   0.0  ...  1469  12153.73  131.688885  126.387119  137.046136   \n39594   0.0  ...  1469  62124.53  131.585042  126.252285  142.529459   \n39597   0.0  ...  1469  61933.83  130.192944  131.285206  138.202150   \n39598   0.0  ...  1469  61820.13  128.443806  121.708950  136.029749   \n39599   0.0  ...  1469  60355.63  121.881017  124.793759  138.613680   \n\n             X_53        X_54        X_55        X_56  x_01_diff  \n1      123.630583  127.893337  143.322659  124.877308    1.11196  \n3      132.260824  130.723186  147.624829  134.875225    3.15096  \n7      132.670759  128.802929  138.067112  127.587498    1.11196  \n9      123.268843  130.163105  131.452740  114.120251    3.15096  \n12     135.963270  135.482075  130.598690  133.943936    3.15096  \n...           ...         ...         ...         ...        ...  \n39591  128.359434  124.751148  138.445736  129.369831   -2.96704  \n39594  119.373373  118.957546  140.975918  133.306156   -1.94704  \n39597  129.136084  129.970180  133.089329  124.429569   -0.92704  \n39598  128.027021  125.687443  145.721791  134.551464    1.11196  \n39599  119.412733  125.072208  137.186520  127.534672   -1.94704  \n\n[9898 rows x 54 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X_01</th>\n      <th>X_02</th>\n      <th>X_03</th>\n      <th>X_04</th>\n      <th>X_05</th>\n      <th>X_06</th>\n      <th>X_07</th>\n      <th>X_08</th>\n      <th>X_09</th>\n      <th>X_10</th>\n      <th>...</th>\n      <th>X_46</th>\n      <th>X_49</th>\n      <th>X_50</th>\n      <th>X_51</th>\n      <th>X_52</th>\n      <th>X_53</th>\n      <th>X_54</th>\n      <th>X_55</th>\n      <th>X_56</th>\n      <th>x_01_diff</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>69.524</td>\n      <td>103.321</td>\n      <td>65.17</td>\n      <td>1</td>\n      <td>101.944</td>\n      <td>72.943</td>\n      <td>28.73</td>\n      <td>61.23</td>\n      <td>233.61</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1463</td>\n      <td>10423.43</td>\n      <td>133.736691</td>\n      <td>135.979817</td>\n      <td>149.924692</td>\n      <td>123.630583</td>\n      <td>127.893337</td>\n      <td>143.322659</td>\n      <td>124.877308</td>\n      <td>1.11196</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>71.563</td>\n      <td>103.320</td>\n      <td>67.57</td>\n      <td>1</td>\n      <td>101.971</td>\n      <td>77.022</td>\n      <td>28.92</td>\n      <td>115.21</td>\n      <td>255.36</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1469</td>\n      <td>15007.03</td>\n      <td>134.138760</td>\n      <td>133.239422</td>\n      <td>139.720132</td>\n      <td>132.260824</td>\n      <td>130.723186</td>\n      <td>147.624829</td>\n      <td>134.875225</td>\n      <td>3.15096</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>69.524</td>\n      <td>103.320</td>\n      <td>65.47</td>\n      <td>1</td>\n      <td>101.968</td>\n      <td>73.963</td>\n      <td>29.77</td>\n      <td>71.41</td>\n      <td>238.27</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1469</td>\n      <td>11907.13</td>\n      <td>133.099217</td>\n      <td>128.041348</td>\n      <td>134.704309</td>\n      <td>132.670759</td>\n      <td>128.802929</td>\n      <td>138.067112</td>\n      <td>127.587498</td>\n      <td>1.11196</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>71.563</td>\n      <td>103.320</td>\n      <td>68.97</td>\n      <td>1</td>\n      <td>101.990</td>\n      <td>77.022</td>\n      <td>28.97</td>\n      <td>66.88</td>\n      <td>228.22</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1469</td>\n      <td>12461.23</td>\n      <td>133.556149</td>\n      <td>123.122143</td>\n      <td>141.628915</td>\n      <td>123.268843</td>\n      <td>130.163105</td>\n      <td>131.452740</td>\n      <td>114.120251</td>\n      <td>3.15096</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>71.563</td>\n      <td>103.320</td>\n      <td>71.27</td>\n      <td>1</td>\n      <td>101.910</td>\n      <td>76.002</td>\n      <td>26.29</td>\n      <td>98.60</td>\n      <td>162.44</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1469</td>\n      <td>16017.63</td>\n      <td>140.558987</td>\n      <td>131.504597</td>\n      <td>141.168291</td>\n      <td>135.963270</td>\n      <td>135.482075</td>\n      <td>130.598690</td>\n      <td>133.943936</td>\n      <td>3.15096</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>39591</th>\n      <td>65.445</td>\n      <td>103.320</td>\n      <td>60.87</td>\n      <td>1</td>\n      <td>103.158</td>\n      <td>65.805</td>\n      <td>30.17</td>\n      <td>117.38</td>\n      <td>301.95</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1469</td>\n      <td>12153.73</td>\n      <td>131.688885</td>\n      <td>126.387119</td>\n      <td>137.046136</td>\n      <td>128.359434</td>\n      <td>124.751148</td>\n      <td>138.445736</td>\n      <td>129.369831</td>\n      <td>-2.96704</td>\n    </tr>\n    <tr>\n      <th>39594</th>\n      <td>66.465</td>\n      <td>103.321</td>\n      <td>63.67</td>\n      <td>1</td>\n      <td>102.030</td>\n      <td>67.845</td>\n      <td>32.44</td>\n      <td>104.27</td>\n      <td>190.16</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1469</td>\n      <td>62124.53</td>\n      <td>131.585042</td>\n      <td>126.252285</td>\n      <td>142.529459</td>\n      <td>119.373373</td>\n      <td>118.957546</td>\n      <td>140.975918</td>\n      <td>133.306156</td>\n      <td>-1.94704</td>\n    </tr>\n    <tr>\n      <th>39597</th>\n      <td>67.485</td>\n      <td>103.320</td>\n      <td>62.77</td>\n      <td>1</td>\n      <td>103.154</td>\n      <td>67.845</td>\n      <td>30.07</td>\n      <td>104.72</td>\n      <td>200.87</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1469</td>\n      <td>61933.83</td>\n      <td>130.192944</td>\n      <td>131.285206</td>\n      <td>138.202150</td>\n      <td>129.136084</td>\n      <td>129.970180</td>\n      <td>133.089329</td>\n      <td>124.429569</td>\n      <td>-0.92704</td>\n    </tr>\n    <tr>\n      <th>39598</th>\n      <td>69.524</td>\n      <td>103.320</td>\n      <td>62.87</td>\n      <td>1</td>\n      <td>103.141</td>\n      <td>69.884</td>\n      <td>32.68</td>\n      <td>105.51</td>\n      <td>283.36</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1469</td>\n      <td>61820.13</td>\n      <td>128.443806</td>\n      <td>121.708950</td>\n      <td>136.029749</td>\n      <td>128.027021</td>\n      <td>125.687443</td>\n      <td>145.721791</td>\n      <td>134.551464</td>\n      <td>1.11196</td>\n    </tr>\n    <tr>\n      <th>39599</th>\n      <td>66.465</td>\n      <td>103.320</td>\n      <td>61.37</td>\n      <td>1</td>\n      <td>103.141</td>\n      <td>66.825</td>\n      <td>30.25</td>\n      <td>114.36</td>\n      <td>217.60</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1469</td>\n      <td>60355.63</td>\n      <td>121.881017</td>\n      <td>124.793759</td>\n      <td>138.613680</td>\n      <td>119.412733</td>\n      <td>125.072208</td>\n      <td>137.186520</td>\n      <td>127.534672</td>\n      <td>-1.94704</td>\n    </tr>\n  </tbody>\n</table>\n<p>9898 rows × 54 columns</p>\n</div>"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.loc[train[train.Y_04 > signal_to_noise75].index]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "data": {
      "text/plain": "         X_01     X_02   X_03  X_04     X_05    X_06   X_07    X_08    X_09  \\\n0      70.544  103.320  67.47     1  101.892  74.983  29.45   62.38  245.71   \n5      69.524  103.320  62.77     1  101.899  69.884  27.90   64.97  241.85   \n13     71.563  103.320  68.77     1  101.957  77.022  29.19   65.61  226.13   \n14     68.504  103.320  66.07     1  101.902  72.943  28.14   69.78  239.63   \n37     74.623  103.320  66.67     1  103.141  74.983  29.16  115.51  226.91   \n...       ...      ...    ...   ...      ...     ...    ...     ...     ...   \n39600  65.445  103.321  61.17     1  103.126  65.805  28.89  103.08  254.48   \n39602  66.465  103.320  62.27     1  103.150  66.825  30.20   77.83  298.05   \n39603  66.465  103.321  62.77     1  102.021  66.825  29.21  102.25  270.67   \n39605  66.465  103.320  63.67     1  102.025  67.845  30.30  112.60  275.52   \n39606  66.465  103.320  65.67     1  102.004  69.884  30.16  112.90  276.06   \n\n       X_10  ...  X_46      X_49        X_50        X_51        X_52  \\\n0       0.0  ...  1463   9706.03  137.043591  135.359219  147.837968   \n5       0.0  ...  1469   9514.23  137.649365  124.373890  145.751970   \n13      0.0  ...  1469  13529.73  138.896565  131.893040  146.084222   \n14      0.0  ...  1469  11288.63  133.464757  131.049343  149.105867   \n37      0.0  ...  1469  15057.83  138.375005  132.812855  138.719919   \n...     ...  ...   ...       ...         ...         ...         ...   \n39600   0.0  ...  1467   9088.83  130.619817  115.842388  142.236215   \n39602   0.0  ...  1469  60630.73  129.965741  130.807148  133.481737   \n39603   0.0  ...  1458  60763.43  127.633885  120.158764  142.667802   \n39605   0.0  ...  1469  62222.33  128.189679  121.495930  141.288011   \n39606   0.0  ...  1462  62172.23  135.096272  122.988476  142.019357   \n\n             X_53        X_54        X_55        X_56  x_01_diff  \n0      134.313475  125.605427  136.721425  125.028256    2.13196  \n5      121.860937  127.081180  139.840405  123.946308    1.11196  \n13     124.647261  133.378628  133.070508  127.483059    3.15096  \n14     130.468000  135.834301  141.178227  126.327862    0.09196  \n37     128.634657  121.402332  130.233479  116.770359    6.21096  \n...           ...         ...         ...         ...        ...  \n39600  124.657179  116.541210  130.743496  128.014553   -2.96704  \n39602  125.273130  121.780933  133.780110  129.029812   -1.94704  \n39603  122.465490  122.987209  143.090741  122.811413   -1.94704  \n39605  130.141676  125.518825  136.603634  124.525929   -1.94704  \n39606  123.752157  130.648365  139.695370  136.714504   -1.94704  \n\n[9900 rows x 54 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X_01</th>\n      <th>X_02</th>\n      <th>X_03</th>\n      <th>X_04</th>\n      <th>X_05</th>\n      <th>X_06</th>\n      <th>X_07</th>\n      <th>X_08</th>\n      <th>X_09</th>\n      <th>X_10</th>\n      <th>...</th>\n      <th>X_46</th>\n      <th>X_49</th>\n      <th>X_50</th>\n      <th>X_51</th>\n      <th>X_52</th>\n      <th>X_53</th>\n      <th>X_54</th>\n      <th>X_55</th>\n      <th>X_56</th>\n      <th>x_01_diff</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>70.544</td>\n      <td>103.320</td>\n      <td>67.47</td>\n      <td>1</td>\n      <td>101.892</td>\n      <td>74.983</td>\n      <td>29.45</td>\n      <td>62.38</td>\n      <td>245.71</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1463</td>\n      <td>9706.03</td>\n      <td>137.043591</td>\n      <td>135.359219</td>\n      <td>147.837968</td>\n      <td>134.313475</td>\n      <td>125.605427</td>\n      <td>136.721425</td>\n      <td>125.028256</td>\n      <td>2.13196</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>69.524</td>\n      <td>103.320</td>\n      <td>62.77</td>\n      <td>1</td>\n      <td>101.899</td>\n      <td>69.884</td>\n      <td>27.90</td>\n      <td>64.97</td>\n      <td>241.85</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1469</td>\n      <td>9514.23</td>\n      <td>137.649365</td>\n      <td>124.373890</td>\n      <td>145.751970</td>\n      <td>121.860937</td>\n      <td>127.081180</td>\n      <td>139.840405</td>\n      <td>123.946308</td>\n      <td>1.11196</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>71.563</td>\n      <td>103.320</td>\n      <td>68.77</td>\n      <td>1</td>\n      <td>101.957</td>\n      <td>77.022</td>\n      <td>29.19</td>\n      <td>65.61</td>\n      <td>226.13</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1469</td>\n      <td>13529.73</td>\n      <td>138.896565</td>\n      <td>131.893040</td>\n      <td>146.084222</td>\n      <td>124.647261</td>\n      <td>133.378628</td>\n      <td>133.070508</td>\n      <td>127.483059</td>\n      <td>3.15096</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>68.504</td>\n      <td>103.320</td>\n      <td>66.07</td>\n      <td>1</td>\n      <td>101.902</td>\n      <td>72.943</td>\n      <td>28.14</td>\n      <td>69.78</td>\n      <td>239.63</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1469</td>\n      <td>11288.63</td>\n      <td>133.464757</td>\n      <td>131.049343</td>\n      <td>149.105867</td>\n      <td>130.468000</td>\n      <td>135.834301</td>\n      <td>141.178227</td>\n      <td>126.327862</td>\n      <td>0.09196</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>74.623</td>\n      <td>103.320</td>\n      <td>66.67</td>\n      <td>1</td>\n      <td>103.141</td>\n      <td>74.983</td>\n      <td>29.16</td>\n      <td>115.51</td>\n      <td>226.91</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1469</td>\n      <td>15057.83</td>\n      <td>138.375005</td>\n      <td>132.812855</td>\n      <td>138.719919</td>\n      <td>128.634657</td>\n      <td>121.402332</td>\n      <td>130.233479</td>\n      <td>116.770359</td>\n      <td>6.21096</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>39600</th>\n      <td>65.445</td>\n      <td>103.321</td>\n      <td>61.17</td>\n      <td>1</td>\n      <td>103.126</td>\n      <td>65.805</td>\n      <td>28.89</td>\n      <td>103.08</td>\n      <td>254.48</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1467</td>\n      <td>9088.83</td>\n      <td>130.619817</td>\n      <td>115.842388</td>\n      <td>142.236215</td>\n      <td>124.657179</td>\n      <td>116.541210</td>\n      <td>130.743496</td>\n      <td>128.014553</td>\n      <td>-2.96704</td>\n    </tr>\n    <tr>\n      <th>39602</th>\n      <td>66.465</td>\n      <td>103.320</td>\n      <td>62.27</td>\n      <td>1</td>\n      <td>103.150</td>\n      <td>66.825</td>\n      <td>30.20</td>\n      <td>77.83</td>\n      <td>298.05</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1469</td>\n      <td>60630.73</td>\n      <td>129.965741</td>\n      <td>130.807148</td>\n      <td>133.481737</td>\n      <td>125.273130</td>\n      <td>121.780933</td>\n      <td>133.780110</td>\n      <td>129.029812</td>\n      <td>-1.94704</td>\n    </tr>\n    <tr>\n      <th>39603</th>\n      <td>66.465</td>\n      <td>103.321</td>\n      <td>62.77</td>\n      <td>1</td>\n      <td>102.021</td>\n      <td>66.825</td>\n      <td>29.21</td>\n      <td>102.25</td>\n      <td>270.67</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1458</td>\n      <td>60763.43</td>\n      <td>127.633885</td>\n      <td>120.158764</td>\n      <td>142.667802</td>\n      <td>122.465490</td>\n      <td>122.987209</td>\n      <td>143.090741</td>\n      <td>122.811413</td>\n      <td>-1.94704</td>\n    </tr>\n    <tr>\n      <th>39605</th>\n      <td>66.465</td>\n      <td>103.320</td>\n      <td>63.67</td>\n      <td>1</td>\n      <td>102.025</td>\n      <td>67.845</td>\n      <td>30.30</td>\n      <td>112.60</td>\n      <td>275.52</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1469</td>\n      <td>62222.33</td>\n      <td>128.189679</td>\n      <td>121.495930</td>\n      <td>141.288011</td>\n      <td>130.141676</td>\n      <td>125.518825</td>\n      <td>136.603634</td>\n      <td>124.525929</td>\n      <td>-1.94704</td>\n    </tr>\n    <tr>\n      <th>39606</th>\n      <td>66.465</td>\n      <td>103.320</td>\n      <td>65.67</td>\n      <td>1</td>\n      <td>102.004</td>\n      <td>69.884</td>\n      <td>30.16</td>\n      <td>112.90</td>\n      <td>276.06</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1462</td>\n      <td>62172.23</td>\n      <td>135.096272</td>\n      <td>122.988476</td>\n      <td>142.019357</td>\n      <td>123.752157</td>\n      <td>130.648365</td>\n      <td>139.695370</td>\n      <td>136.714504</td>\n      <td>-1.94704</td>\n    </tr>\n  </tbody>\n</table>\n<p>9900 rows × 54 columns</p>\n</div>"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.loc[train[train.Y_04 <signal_to_noise25].index]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for col in x_col:\n",
    "    diff =  train[train.Y_01 >= 1.576000][col].mean() - train[train.Y_01 <= 1.127500][col].mean()\n",
    "\n",
    "\n",
    "    print(f\"{col} : {diff}\")\n",
    "    if abs(diff) > 1:\n",
    "        print(f\"\\n\\n{col} : {diff}\")\n",
    "        print(f\"{col}=============\")\n",
    "        describe = x_train[col].describe()\n",
    "        print(f\"====={col} describe start =====\")\n",
    "        print(describe)\n",
    "        print(f\"====={col} describe  end=====\")\n",
    "        print(f\"diff :{diff} \")\n",
    "        print(f\"표준 편차 : {describe.loc['std']}\\n\")\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "15.626"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Y_04.describe()['75%']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_08,방열 재료 2 면적\n",
    "X_09,방열 재료 3 면적\n",
    "X_19,1번 스크류 삽입 깊이\n",
    "X_37,스크류 체결 시 분당 회전수 4\n",
    "X_49,Cal 투입 전 대기 시간"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "data": {
      "text/plain": "count    39607.000000\nmean         1.353814\nstd          0.356223\nmin          0.017000\n25%          1.127500\n50%          1.349000\n75%          1.576000\nmax          4.409000\nName: Y_01, dtype: float64"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train['Y_01'].describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "data": {
      "text/plain": "18"
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train[y_train.Y_01 > 3])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "data": {
      "text/plain": "Int64Index([  764,   881,  2699,  3013,  3201,  5053,  5256,  5331,  5420,\n             5498,  6378,  6387,  7089,  9259, 18805, 28998, 30921, 35293],\n           dtype='int64')"
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[y_train.Y_01 > 3].index"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [
    {
     "data": {
      "text/plain": "Int64Index([    4,    13,    15,    19,    20,    23,    28,    29,    37,\n               42,\n            ...\n            39575, 39577, 39579, 39581, 39587, 39595, 39596, 39599, 39600,\n            39605],\n           dtype='int64', length=5825)"
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[y_train.Y_01 < 1].index"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "data": {
      "text/plain": "69.75066666666667"
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 안테나 평균값이 높은게 더 높긴 하다 누름량이 높다고 표현해야할지 적정치라 표현해야할지\n",
    "# 적정하다는값을 추가 ? 아니면 안전범위내의 mean값을 추가해야하나\n",
    "\n",
    "x_train.iloc[y_train[y_train.Y_01 > 3].index]['X_01'].mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "data": {
      "text/plain": "68.23101939914163"
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.iloc[y_train[y_train.Y_01 < 1].index]['X_01'].mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "표준편차에 비해 25% 75% 평균값의 차가 크게 차이나는것은\n",
    "그 값에 의해 차이가 많이 나는 것으로 판단?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 표준편차의 1/10 정도 차이나면 많이 나는건가\n",
    "# 표준편차 1/100 , 1/30 정도 차이난다 25%분위 수와 75%분위수의 x값의차이는"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# y_01의 25%와 75%의 x_01 평균값은 크게 차이 안나는 듯하다"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "count    39607.000000\nmean        68.412040\nstd          2.655983\nmin         56.268000\n25%         66.465000\n50%         68.504000\n75%         69.524000\nmax         84.820000\nName: X_01, dtype: float64"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train['X_01'].describe()\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "68.4763243270491"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 1차 검사 통과 여부에 대한 box plot 생성"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.boxplot(x_train['X_01'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 평균 값과의 차이? 최대값과 최소값 중위값과의 차이?\n",
    "x_train['X_01'].mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "count    39607.000000\nmean        68.412040\nstd          2.655983\nmin         56.268000\n25%         66.465000\n50%         68.504000\n75%         69.524000\nmax         84.820000\nName: X_01, dtype: float64"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 평균값은 68\n",
    "# 50%중위값은 68"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train['X_01'].describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# lr과 optimizer에서 cv 많이 감소"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import optim\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.nn.modules.container import Sequential\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import gc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor, Pool"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "CatBoostRegressor()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rf.feature_importances_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    # dataPath = \"antenna performance prediction for autonomous driving sensors/data\"\n",
    "    dataPath = \"./data\"\n",
    "    trainPath  =  dataPath + \"/train.csv\"\n",
    "    testPath = dataPath + \"/test.csv\"\n",
    "    submission = dataPath + \"/sample_submission.csv\"\n",
    "    outPath = dataPath + \"processed/\"\n",
    "    weightsavePath = dataPath + \"/weights/\"\n",
    "    device = \"cuda\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0\n",
      "train_loss : 279.8328380584717\n",
      "val_loss : 34.23830795288086\n",
      "\n",
      "\n",
      "epoch : 1\n",
      "train_loss : 169.94713401794434\n",
      "val_loss : 8.563149452209473\n",
      "\n",
      "\n",
      "epoch : 2\n",
      "train_loss : 42.75021004676819\n",
      "val_loss : 3.8723329305648804\n",
      "\n",
      "\n",
      "epoch : 3\n",
      "train_loss : 29.15989661216736\n",
      "val_loss : 3.4878796339035034\n",
      "\n",
      "\n",
      "epoch : 4\n",
      "train_loss : 25.713956832885742\n",
      "val_loss : 3.108052968978882\n",
      "\n",
      "\n",
      "epoch : 5\n",
      "train_loss : 24.48136842250824\n",
      "val_loss : 3.000280737876892\n",
      "\n",
      "\n",
      "epoch : 6\n",
      "train_loss : 23.80814516544342\n",
      "val_loss : 2.9214420318603516\n",
      "\n",
      "\n",
      "epoch : 7\n",
      "train_loss : 23.247479796409607\n",
      "val_loss : 2.861372232437134\n",
      "\n",
      "\n",
      "epoch : 8\n",
      "train_loss : 22.671159386634827\n",
      "val_loss : 2.786076068878174\n",
      "\n",
      "\n",
      "epoch : 9\n",
      "train_loss : 22.18509590625763\n",
      "val_loss : 2.7478753328323364\n",
      "\n",
      "\n",
      "epoch : 10\n",
      "train_loss : 21.740960240364075\n",
      "val_loss : 2.690439224243164\n",
      "\n",
      "\n",
      "epoch : 11\n",
      "train_loss : 21.337950468063354\n",
      "val_loss : 2.6429004669189453\n",
      "\n",
      "\n",
      "epoch : 12\n",
      "train_loss : 21.00510334968567\n",
      "val_loss : 2.6065871715545654\n",
      "\n",
      "\n",
      "epoch : 13\n",
      "train_loss : 20.728145837783813\n",
      "val_loss : 2.612262487411499\n",
      "\n",
      "\n",
      "epoch : 14\n",
      "train_loss : 20.447295784950256\n",
      "val_loss : 2.5070111751556396\n",
      "\n",
      "\n",
      "epoch : 15\n",
      "train_loss : 20.03479564189911\n",
      "val_loss : 2.4884283542633057\n",
      "\n",
      "\n",
      "epoch : 16\n",
      "train_loss : 19.73350477218628\n",
      "val_loss : 2.423592686653137\n",
      "\n",
      "\n",
      "epoch : 17\n",
      "train_loss : 19.45547580718994\n",
      "val_loss : 2.413702368736267\n",
      "\n",
      "\n",
      "epoch : 18\n",
      "train_loss : 19.224675059318542\n",
      "val_loss : 2.4044439792633057\n",
      "\n",
      "\n",
      "epoch : 19\n",
      "train_loss : 19.106075882911682\n",
      "val_loss : 2.3941515684127808\n",
      "\n",
      "\n",
      "epoch : 20\n",
      "train_loss : 19.024295687675476\n",
      "val_loss : 2.3737235069274902\n",
      "\n",
      "\n",
      "epoch : 21\n",
      "train_loss : 19.033466935157776\n",
      "val_loss : 2.3819661140441895\n",
      "\n",
      "\n",
      "epoch : 22\n",
      "train_loss : 18.756068468093872\n",
      "val_loss : 2.361328125\n",
      "\n",
      "\n",
      "epoch : 23\n",
      "train_loss : 18.399446606636047\n",
      "val_loss : 2.3108410835266113\n",
      "\n",
      "\n",
      "epoch : 24\n",
      "train_loss : 18.446015119552612\n",
      "val_loss : 2.240838646888733\n",
      "\n",
      "\n",
      "epoch : 25\n",
      "train_loss : 18.582037568092346\n",
      "val_loss : 2.217293858528137\n",
      "\n",
      "\n",
      "epoch : 26\n",
      "train_loss : 18.43839704990387\n",
      "val_loss : 2.2125078439712524\n",
      "\n",
      "\n",
      "epoch : 27\n",
      "train_loss : 18.220507264137268\n",
      "val_loss : 2.3071682453155518\n",
      "\n",
      "\n",
      "epoch : 28\n",
      "train_loss : 17.97237539291382\n",
      "val_loss : 2.1959978342056274\n",
      "\n",
      "\n",
      "epoch : 29\n",
      "train_loss : 17.595445156097412\n",
      "val_loss : 2.163354754447937\n",
      "\n",
      "\n",
      "epoch : 30\n",
      "train_loss : 17.459585905075073\n",
      "val_loss : 2.1878989934921265\n",
      "\n",
      "\n",
      "epoch : 31\n",
      "train_loss : 17.431023478507996\n",
      "val_loss : 2.2651443481445312\n",
      "\n",
      "\n",
      "epoch : 32\n",
      "train_loss : 17.760658740997314\n",
      "val_loss : 2.2185405492782593\n",
      "\n",
      "\n",
      "epoch : 33\n",
      "train_loss : 17.299089431762695\n",
      "val_loss : 2.1365151405334473\n",
      "\n",
      "\n",
      "epoch : 34\n",
      "train_loss : 17.052443027496338\n",
      "val_loss : 2.1080676317214966\n",
      "\n",
      "\n",
      "epoch : 35\n",
      "train_loss : 17.129599690437317\n",
      "val_loss : 2.2041993141174316\n",
      "\n",
      "\n",
      "epoch : 36\n",
      "train_loss : 17.034140706062317\n",
      "val_loss : 2.1169763803482056\n",
      "\n",
      "\n",
      "epoch : 37\n",
      "train_loss : 17.17692005634308\n",
      "val_loss : 2.0724077224731445\n",
      "\n",
      "\n",
      "epoch : 38\n",
      "train_loss : 16.90295100212097\n",
      "val_loss : 2.1462035179138184\n",
      "\n",
      "\n",
      "epoch : 39\n",
      "train_loss : 16.761141061782837\n",
      "val_loss : 2.0763087272644043\n",
      "\n",
      "\n",
      "epoch : 40\n",
      "train_loss : 16.772096276283264\n",
      "val_loss : 2.168886423110962\n",
      "\n",
      "\n",
      "epoch : 41\n",
      "train_loss : 16.93600368499756\n",
      "val_loss : 2.0589005947113037\n",
      "\n",
      "\n",
      "epoch : 42\n",
      "train_loss : 16.63062870502472\n",
      "val_loss : 2.2769017219543457\n",
      "\n",
      "\n",
      "epoch : 43\n",
      "train_loss : 16.899970412254333\n",
      "val_loss : 2.088724970817566\n",
      "\n",
      "\n",
      "epoch : 44\n",
      "train_loss : 16.56496000289917\n",
      "val_loss : 2.0326435565948486\n",
      "\n",
      "\n",
      "epoch : 45\n",
      "train_loss : 16.277737140655518\n",
      "val_loss : 2.0284061431884766\n",
      "\n",
      "\n",
      "epoch : 46\n",
      "train_loss : 16.405536890029907\n",
      "val_loss : 2.036571502685547\n",
      "\n",
      "\n",
      "epoch : 47\n",
      "train_loss : 16.21806001663208\n",
      "val_loss : 2.0861247777938843\n",
      "\n",
      "\n",
      "epoch : 48\n",
      "train_loss : 16.60383629798889\n",
      "val_loss : 2.0710597038269043\n",
      "\n",
      "\n",
      "epoch : 49\n",
      "train_loss : 16.335236251354218\n",
      "val_loss : 1.987125039100647\n",
      "\n",
      "\n",
      "epoch : 50\n",
      "train_loss : 16.180079221725464\n",
      "val_loss : 2.0038678646087646\n",
      "\n",
      "\n",
      "epoch : 51\n",
      "train_loss : 16.404134511947632\n",
      "val_loss : 2.0448715686798096\n",
      "\n",
      "\n",
      "epoch : 52\n",
      "train_loss : 16.139748752117157\n",
      "val_loss : 2.01703280210495\n",
      "\n",
      "\n",
      "epoch : 53\n",
      "train_loss : 15.983365416526794\n",
      "val_loss : 1.9697993993759155\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at ..\\caffe2\\serialize\\inline_container.cc:300] . unexpected pos 117904192 vs 117904080",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "\u001B[1;32mc:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\serialization.py\u001B[0m in \u001B[0;36msave\u001B[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001B[0m\n\u001B[0;32m    378\u001B[0m             \u001B[1;32mwith\u001B[0m \u001B[0m_open_zipfile_writer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mopened_file\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mopened_zipfile\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 379\u001B[1;33m                 \u001B[0m_save\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mopened_zipfile\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpickle_module\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpickle_protocol\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    380\u001B[0m                 \u001B[1;32mreturn\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\serialization.py\u001B[0m in \u001B[0;36m_save\u001B[1;34m(obj, zip_file, pickle_module, pickle_protocol)\u001B[0m\n\u001B[0;32m    498\u001B[0m         \u001B[0mnum_bytes\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mstorage\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mstorage\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0melement_size\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 499\u001B[1;33m         \u001B[0mzip_file\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwrite_record\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstorage\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata_ptr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnum_bytes\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    500\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mOSError\u001B[0m: [Errno 28] No space left on device",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-13-24359defb12b>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m    120\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    121\u001B[0m         \u001B[1;31m# gc.collect()\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 122\u001B[1;33m         \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msave\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstate_dict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mCFG\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mweightsavePath\u001B[0m\u001B[1;33m+\u001B[0m\u001B[1;34mf'{epoch}_neuralnet.pt'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    123\u001B[0m         \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"\\n\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    124\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\serialization.py\u001B[0m in \u001B[0;36msave\u001B[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001B[0m\n\u001B[0;32m    378\u001B[0m             \u001B[1;32mwith\u001B[0m \u001B[0m_open_zipfile_writer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mopened_file\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mopened_zipfile\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    379\u001B[0m                 \u001B[0m_save\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mopened_zipfile\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpickle_module\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpickle_protocol\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 380\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    381\u001B[0m         \u001B[0m_legacy_save\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mopened_file\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpickle_module\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpickle_protocol\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    382\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\data\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\serialization.py\u001B[0m in \u001B[0;36m__exit__\u001B[1;34m(self, *args)\u001B[0m\n\u001B[0;32m    257\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    258\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__exit__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 259\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfile_like\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwrite_end_of_file\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    260\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbuffer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mflush\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    261\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: [enforce fail at ..\\caffe2\\serialize\\inline_container.cc:300] . unexpected pos 117904192 vs 117904080"
     ]
    }
   ],
   "source": [
    "def seed_everything(random_seed):\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
    "    torch.backends.cudnn.deterministic =True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    random.seed(random_seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "\n",
    "\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(56, 512)\n",
    "        self.layer1 = self.make_layers(512,num_repeat=300)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc5 = nn.Linear(512,14)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer1(x)\n",
    "        x = nn.Dropout(0.2)(x)\n",
    "        x = self.fc5(x)\n",
    "        return  x\n",
    "\n",
    "    def make_layers(self,value, num_repeat):\n",
    "        layers = []\n",
    "        for _ in range(num_repeat):\n",
    "            layers.append(nn.Linear(value,value))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "        return nn.Sequential(*layers)\n",
    "def numpy_to_tensor(variable):\n",
    "    x = variable.values\n",
    "    x = np.array(x, dtype=np.float32)\n",
    "    x = torch.from_numpy(x)\n",
    "    return x\n",
    "\n",
    "def pandas_to_tensor(variable):\n",
    "    return torch.tensor(variable.values)\n",
    "\n",
    "def train_one_epoch(model, train_batch, criterion , optimizer, train_X, train_Y,device):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for i in range(train_batch):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "        input = train_X[start:end].to(device, dtype=torch.float)\n",
    "        label = train_Y[start:end].to(device , dtype=torch.float)\n",
    "\n",
    "        input, label = input.to(device), label.to(device)\n",
    "        outputs = model(input).squeeze()\n",
    "        loss = criterion(outputs, label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    print(f\"train_loss : {train_loss}\")\n",
    "\n",
    "def val_one_epoch(model, val_batch , criterion,val_X, val_Y, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        for i in range(val_batch):\n",
    "            start =  i * batch_size\n",
    "            end = start +batch_size\n",
    "            input = val_X[start:end].to(device, dtype=torch.float)\n",
    "            label = val_Y[start:end].to(device, dtype=torch.float)\n",
    "\n",
    "            input, label = input.to(device), label.to(device)\n",
    "            outputs = model(input).squeeze()\n",
    "            loss = criterion(outputs, label)\n",
    "            val_loss += loss.item()\n",
    "        print(f\"val_loss : {val_loss}\")\n",
    "\n",
    "\n",
    "\n",
    "def datapreparation(train_df):\n",
    "    # shuffle\n",
    "    valset_ratio = 0.15\n",
    "    train_df = train_df.sample(frac=1)\n",
    "\n",
    "    train_df_X = train_df.filter(regex=\"X\")\n",
    "    train_df_Y = train_df.filter(regex=\"Y\")\n",
    "\n",
    "    valset_num = round(len(train_df_Y)* valset_ratio)\n",
    "\n",
    "    val_df_X = pandas_to_tensor(train_df_X.iloc[:valset_num])\n",
    "    val_df_Y = pandas_to_tensor(train_df_Y.iloc[:valset_num])\n",
    "    train_df_X = pandas_to_tensor(train_df_X.iloc[valset_num:])\n",
    "    train_df_Y = pandas_to_tensor(train_df_Y.iloc[valset_num:])\n",
    "\n",
    "    return train_df_X, train_df_Y ,  val_df_X , val_df_Y\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    seed_everything(42)\n",
    "    train_df = pd.read_csv(CFG.trainPath)\n",
    "    train_df_X, train_df_Y, val_df_X , val_df_Y = datapreparation(train_df)\n",
    "\n",
    "    model = NeuralNet()\n",
    "    model = model.to(CFG.device)\n",
    "    optimizer = optim.Adam(model.parameters(),lr=3e-4)\n",
    "    criterion = nn.L1Loss().cuda()\n",
    "\n",
    "    num_epochs = 300\n",
    "    batch_size = 2048\n",
    "\n",
    "    train_batch = len(train_df_X) // batch_size\n",
    "    val_batch = len(val_df_X) // batch_size\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"epoch : {epoch}\")\n",
    "        train_one_epoch(model, train_batch, criterion, optimizer, train_df_X, train_df_Y, CFG.device)\n",
    "        val_one_epoch(model, val_batch, criterion, val_df_X, val_df_Y, CFG.device)\n",
    "\n",
    "        # gc.collect()\n",
    "        torch.save(model.state_dict(), CFG.weightsavePath+f'{epoch}_neuralnet.pt')\n",
    "        print(\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "- baseline -\n",
    "\n",
    "\n",
    "epoch : 0\n",
    "train_loss : 279.8328380584717\n",
    "val_loss : 34.23830795288086\n",
    "\n",
    "\n",
    "epoch : 1\n",
    "train_loss : 169.94713401794434\n",
    "val_loss : 8.563149452209473\n",
    "\n",
    "\n",
    "epoch : 2\n",
    "train_loss : 42.75021004676819\n",
    "val_loss : 3.8723329305648804\n",
    "\n",
    "\n",
    "epoch : 3\n",
    "train_loss : 29.15989661216736\n",
    "val_loss : 3.4878796339035034\n",
    "\n",
    "\n",
    "epoch : 4\n",
    "train_loss : 25.713956832885742\n",
    "val_loss : 3.108052968978882\n",
    "\n",
    "\n",
    "epoch : 5\n",
    "train_loss : 24.48136842250824\n",
    "val_loss : 3.000280737876892\n",
    "\n",
    "\n",
    "epoch : 6\n",
    "train_loss : 23.80814516544342\n",
    "val_loss : 2.9214420318603516\n",
    "\n",
    "\n",
    "epoch : 7\n",
    "train_loss : 23.247479796409607\n",
    "val_loss : 2.861372232437134\n",
    "\n",
    "\n",
    "epoch : 8\n",
    "train_loss : 22.671159386634827\n",
    "val_loss : 2.786076068878174\n",
    "\n",
    "\n",
    "epoch : 9\n",
    "train_loss : 22.18509590625763\n",
    "val_loss : 2.7478753328323364\n",
    "\n",
    "\n",
    "epoch : 10\n",
    "train_loss : 21.740960240364075\n",
    "val_loss : 2.690439224243164\n",
    "\n",
    "\n",
    "epoch : 11\n",
    "train_loss : 21.337950468063354\n",
    "val_loss : 2.6429004669189453\n",
    "\n",
    "\n",
    "epoch : 12\n",
    "train_loss : 21.00510334968567\n",
    "val_loss : 2.6065871715545654\n",
    "\n",
    "\n",
    "epoch : 13\n",
    "train_loss : 20.728145837783813\n",
    "val_loss : 2.612262487411499\n",
    "\n",
    "\n",
    "epoch : 14\n",
    "train_loss : 20.447295784950256\n",
    "val_loss : 2.5070111751556396\n",
    "\n",
    "\n",
    "epoch : 15\n",
    "train_loss : 20.03479564189911\n",
    "val_loss : 2.4884283542633057\n",
    "\n",
    "\n",
    "epoch : 16\n",
    "train_loss : 19.73350477218628\n",
    "val_loss : 2.423592686653137\n",
    "\n",
    "\n",
    "epoch : 17\n",
    "train_loss : 19.45547580718994\n",
    "val_loss : 2.413702368736267\n",
    "\n",
    "\n",
    "epoch : 18\n",
    "train_loss : 19.224675059318542\n",
    "val_loss : 2.4044439792633057\n",
    "\n",
    "\n",
    "epoch : 19\n",
    "train_loss : 19.106075882911682\n",
    "val_loss : 2.3941515684127808\n",
    "\n",
    "\n",
    "epoch : 20\n",
    "train_loss : 19.024295687675476\n",
    "val_loss : 2.3737235069274902\n",
    "\n",
    "\n",
    "epoch : 21\n",
    "train_loss : 19.033466935157776\n",
    "val_loss : 2.3819661140441895\n",
    "\n",
    "\n",
    "epoch : 22\n",
    "train_loss : 18.756068468093872\n",
    "val_loss : 2.361328125\n",
    "\n",
    "\n",
    "epoch : 23\n",
    "train_loss : 18.399446606636047\n",
    "val_loss : 2.3108410835266113\n",
    "\n",
    "\n",
    "epoch : 24\n",
    "train_loss : 18.446015119552612\n",
    "val_loss : 2.240838646888733\n",
    "\n",
    "\n",
    "epoch : 25\n",
    "train_loss : 18.582037568092346\n",
    "val_loss : 2.217293858528137\n",
    "\n",
    "\n",
    "epoch : 26\n",
    "train_loss : 18.43839704990387\n",
    "val_loss : 2.2125078439712524\n",
    "\n",
    "\n",
    "epoch : 27\n",
    "train_loss : 18.220507264137268\n",
    "val_loss : 2.3071682453155518\n",
    "\n",
    "\n",
    "epoch : 28\n",
    "train_loss : 17.97237539291382\n",
    "val_loss : 2.1959978342056274\n",
    "\n",
    "\n",
    "epoch : 29\n",
    "train_loss : 17.595445156097412\n",
    "val_loss : 2.163354754447937\n",
    "\n",
    "\n",
    "epoch : 30\n",
    "train_loss : 17.459585905075073\n",
    "val_loss : 2.1878989934921265\n",
    "\n",
    "\n",
    "epoch : 31\n",
    "train_loss : 17.431023478507996\n",
    "val_loss : 2.2651443481445312\n",
    "\n",
    "\n",
    "epoch : 32\n",
    "train_loss : 17.760658740997314\n",
    "val_loss : 2.2185405492782593\n",
    "\n",
    "\n",
    "epoch : 33\n",
    "train_loss : 17.299089431762695\n",
    "val_loss : 2.1365151405334473\n",
    "\n",
    "\n",
    "epoch : 34\n",
    "train_loss : 17.052443027496338\n",
    "val_loss : 2.1080676317214966\n",
    "\n",
    "\n",
    "epoch : 35\n",
    "train_loss : 17.129599690437317\n",
    "val_loss : 2.2041993141174316\n",
    "\n",
    "\n",
    "epoch : 36\n",
    "train_loss : 17.034140706062317\n",
    "val_loss : 2.1169763803482056\n",
    "\n",
    "\n",
    "epoch : 37\n",
    "train_loss : 17.17692005634308\n",
    "val_loss : 2.0724077224731445\n",
    "\n",
    "\n",
    "epoch : 38\n",
    "train_loss : 16.90295100212097\n",
    "val_loss : 2.1462035179138184\n",
    "\n",
    "\n",
    "epoch : 39\n",
    "train_loss : 16.761141061782837\n",
    "val_loss : 2.0763087272644043\n",
    "\n",
    "\n",
    "epoch : 40\n",
    "train_loss : 16.772096276283264\n",
    "val_loss : 2.168886423110962\n",
    "\n",
    "\n",
    "epoch : 41\n",
    "train_loss : 16.93600368499756\n",
    "val_loss : 2.0589005947113037\n",
    "\n",
    "\n",
    "epoch : 42\n",
    "train_loss : 16.63062870502472\n",
    "val_loss : 2.2769017219543457\n",
    "\n",
    "\n",
    "epoch : 43\n",
    "train_loss : 16.899970412254333\n",
    "val_loss : 2.088724970817566\n",
    "\n",
    "\n",
    "epoch : 44\n",
    "train_loss : 16.56496000289917\n",
    "val_loss : 2.0326435565948486\n",
    "\n",
    "\n",
    "epoch : 45\n",
    "train_loss : 16.277737140655518\n",
    "val_loss : 2.0284061431884766\n",
    "\n",
    "\n",
    "epoch : 46\n",
    "train_loss : 16.405536890029907\n",
    "val_loss : 2.036571502685547\n",
    "\n",
    "\n",
    "epoch : 47\n",
    "train_loss : 16.21806001663208\n",
    "val_loss : 2.0861247777938843\n",
    "\n",
    "\n",
    "epoch : 48\n",
    "train_loss : 16.60383629798889\n",
    "val_loss : 2.0710597038269043\n",
    "\n",
    "\n",
    "epoch : 49\n",
    "train_loss : 16.335236251354218\n",
    "val_loss : 1.987125039100647\n",
    "\n",
    "\n",
    "epoch : 50\n",
    "train_loss : 16.180079221725464\n",
    "val_loss : 2.0038678646087646\n",
    "\n",
    "\n",
    "epoch : 51\n",
    "train_loss : 16.404134511947632\n",
    "val_loss : 2.0448715686798096\n",
    "\n",
    "\n",
    "epoch : 52\n",
    "train_loss : 16.139748752117157\n",
    "val_loss : 2.01703280210495\n",
    "\n",
    "\n",
    "epoch : 53\n",
    "train_loss : 15.983365416526794\n",
    "val_loss : 1.9697993993759155\n",
    "\n",
    "\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "송승훈\n",
    "2022.08.05 09:21\n",
    "관계있어보이는 변수끼리 조합해보고 있는데 확실히 성능이 오르긴 합니다.\n",
    "어떤 의미가 있는지는 모르겠네요"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 주식 데이터 볼떄처럼 생각읋해보면\n",
    "\n",
    "방열 재료1의 무게가 ~~이고 방열재료3 의무게가 ~~~일때 불량일 가능성이 높다 이런 것을 찾아내야함\n",
    "-> 찾아내는 과정\n",
    "우선 두개가 연관성이 있을까?\n",
    "\n",
    "우선 정답값을 찾아내는 모델을 설계할때\n",
    "트리기반모델이라면\n",
    "\n",
    "재료1의무게가 ~~이고 재료3의무게가 ~~일 떄 불량 이다라는 트리가 생성될것\n",
    "그 이전에 시각화를 해서\n",
    "데이터를 많이 들여다보고 할줄ㅇ라아야한다"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 그럼 그런걸 어떻게 찾아내지?\n",
    "\n",
    "#예상을 좀 해봐야지\n",
    "\n",
    "# 피쳐를 추출해서 만들어내야겠따라는생각을하니 아예 아무생각이 안들진안흔다"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "체결시 단계별 누름량이 어느 선을 초과하면 가중치를 주거나 해야할 수도있고"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# 역시여러개 하면서 하나의 분야의 insight가 다른 분야에(여기에) 도움을준다 는 내 가설이 맞을 듯하다\n",
    "# 주식ㅈㅔ이터 관찰하면서 특징을 어느정도 발견해냈거든  그런식으로 하는거구나 하고\n",
    "\n",
    "\n",
    "가설 ->\n",
    "스크류삽입깊이12가 34와의 차이를 그려보고\n",
    "\n",
    "그차이 작을 수록 불량이 나지 않을 확율이 있찌않을가?\n",
    "# 스크류삽입은 pcb 가 뭔진아니까 영향을 미칠지 안미칠지 공부해보거나\n",
    "그러면 feature를 그 차이를 feature로 추가하고 학습해보고 모델이 상승하는지 보는것이다\n",
    "그리고 어떤 피쳐를 추가하고 조합한 경우에 (코딩테스트 미로탈출처럼\n",
    "어떤 경우의수인지 체크하고 그것을 실험했느지 체크하는 방식도사용하면서)\n",
    "모델이 상승하는지 ,"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "피쳐들의 조합에 따라 모델성능이달라진다는것은\n",
    "그 조합 피쳐들이 모두 유의미하거나 서로의 상관관계로 인해 예측에 유의미한 영향을 준다는것을의미할것이다"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ㅇ#%%\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}